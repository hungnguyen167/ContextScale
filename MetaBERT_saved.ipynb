{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhx963taNlDB"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k3dCezyXmXQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUoQrEYCXmXQ",
        "outputId": "e3e70df8-5711-46aa-b4cc-ede6cdb653f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (1.12.1+cu116)\n",
            "Requirement already satisfied: torchvision in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (0.13.1+cu116)\n",
            "Requirement already satisfied: torchaudio in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (0.12.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from torch) (4.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from torchvision) (9.2.0)\n",
            "Requirement already satisfied: numpy in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from torchvision) (1.23.1)\n",
            "Requirement already satisfied: requests in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from torchvision) (2.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->torchvision) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: transformers==4.21.2 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (4.21.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (0.9.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (21.3)\n",
            "Requirement already satisfied: filelock in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (2022.8.17)\n",
            "Requirement already satisfied: requests in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (2.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (1.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from transformers==4.21.2) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (4.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from packaging>=20.0->transformers==4.21.2) (3.0.9)\n",
            "Requirement already satisfied: colorama in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from tqdm>=4.27->transformers==4.21.2) (0.4.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->transformers==4.21.2) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->transformers==4.21.2) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->transformers==4.21.2) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests->transformers==4.21.2) (3.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.96 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (0.1.96)\n",
            "Requirement already satisfied: numpy in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (1.23.1)\n",
            "Requirement already satisfied: requests in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (2.28.1)\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "     -------------------------------------- 410.5/410.5 kB 2.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests) (2.0.4)\n",
            "Collecting gdown>=4.0.0\n",
            "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: pandas>=1.2.0 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from nlpaug) (1.4.4)\n",
            "Requirement already satisfied: tqdm in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.64.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.11.1)\n",
            "Requirement already satisfied: six in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: filelock in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2022.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.3.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from requests) (1.7.1)\n",
            "Requirement already satisfied: colorama in c:\\anaconda3\\envs\\bargaining_space\\lib\\site-packages (from tqdm->gdown>=4.0.0->nlpaug) (0.4.5)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (pyproject.toml): started\n",
            "  Building wheel for gdown (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=e1b4b55e6c082c672c6a7d982c445e4c55706116cd89e9c14078a068a588eb14\n",
            "  Stored in directory: c:\\users\\hung\\appdata\\local\\pip\\cache\\wheels\\b8\\79\\f0\\b523d25d96b0bbb12bb024b97940d08c4fcd498a00070c8d82\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown, nlpaug\n",
            "Successfully installed gdown-4.5.1 nlpaug-1.1.11\n"
          ]
        }
      ],
      "source": [
        "## Install required packages\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install transformers==4.21.2\n",
        "!pip install sentencepiece==0.1.96\n",
        "!pip install numpy requests nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dPi54JU9XmXR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support, classification_report\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertForSequenceClassification, BertTokenizerFast, BertModel\n",
        "from torch.utils.data import DataLoader\n",
        "from utils import functions, models, dataset    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mDclkfIWZcwv",
        "outputId": "769a0b89-1e46-4b79-c424-cb6022cd4971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NVIDIA GeForce GTX 1060 6GB'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "torch.cuda.get_device_name(device=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULX0gK7mg6d3",
        "outputId": "bdbd3c77-e5c0-46f3-cb41-c78bdbbbd4ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## If using on Google Colab, run this cell\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b41aechYXmXT"
      },
      "source": [
        "## Load data and clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qB4dt7BNuojT"
      },
      "outputs": [],
      "source": [
        "cap_deu = pd.read_csv(os.path.join(\"shared_data\", \"CAP\",\"cap_data_cleaned.csv\"), encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l7_4NCOH-geX",
        "outputId": "5b212469-6302-435e-8b21-ebf574ca2642"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>election_year</th>\n",
              "      <th>party_name</th>\n",
              "      <th>party_id</th>\n",
              "      <th>manifesto_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>cap_topic</th>\n",
              "      <th>cap_subtopic</th>\n",
              "      <th>header</th>\n",
              "      <th>junk</th>\n",
              "      <th>eu_dummy</th>\n",
              "      <th>sentence_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Für ein freies Deutschland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Wählerinnen und Wähler!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>3</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Am 14. August entscheidet XX darüber, wie ein ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heute ist unser land geteilt.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>2099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Swjetrussland hat seine Besatzungszone separiert.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  election_year party_name  party_id  manifesto_id  sentence_id  \\\n",
              "0           1           1949        SPD         1         19491            1   \n",
              "1           2           1949        SPD         1         19491            2   \n",
              "2           3           1949        SPD         1         19491            3   \n",
              "3           4           1949        SPD         1         19491            4   \n",
              "4           5           1949        SPD         1         19491            5   \n",
              "\n",
              "   cap_topic  cap_subtopic  header  junk  eu_dummy  \\\n",
              "0         99            99       1     0         0   \n",
              "1         99            99       0     0         0   \n",
              "2         99            99       0     0         0   \n",
              "3         20          2099       0     0         0   \n",
              "4         20          2099       0     0         0   \n",
              "\n",
              "                                       sentence_text  \n",
              "0                         Für ein freies Deutschland  \n",
              "1                            Wählerinnen und Wähler!  \n",
              "2  Am 14. August entscheidet XX darüber, wie ein ...  \n",
              "3                      Heute ist unser land geteilt.  \n",
              "4  Swjetrussland hat seine Besatzungszone separiert.  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cap_deu.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "VKVBeLm294hG",
        "outputId": "20527b20-fc8d-465b-930b-5c5ac97edebd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>election_year</th>\n",
              "      <th>party_name</th>\n",
              "      <th>party_id</th>\n",
              "      <th>manifesto_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>cap_subtopic</th>\n",
              "      <th>header</th>\n",
              "      <th>junk</th>\n",
              "      <th>eu_dummy</th>\n",
              "      <th>sentence_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cap_topic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "      <td>7127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "      <td>4673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "      <td>5808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "      <td>3586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "      <td>781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "      <td>1148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Unnamed: 0  election_year  party_name  party_id  manifesto_id  \\\n",
              "cap_topic                                                                  \n",
              "0                   2              2           2         2             2   \n",
              "1                7127           7127        7127      7127          7127   \n",
              "2                5094           5094        5094      5094          5094   \n",
              "3                3014           3014        3014      3014          3014   \n",
              "4                1658           1658        1658      1658          1658   \n",
              "5                4673           4673        4673      4673          4673   \n",
              "6                4213           4213        4213      4213          4213   \n",
              "7                3461           3461        3461      3461          3461   \n",
              "8                2329           2329        2329      2329          2329   \n",
              "9                1621           1621        1621      1621          1621   \n",
              "10               2139           2139        2139      2139          2139   \n",
              "12               3912           3912        3912      3912          3912   \n",
              "13               5808           5808        5808      5808          5808   \n",
              "14               2278           2278        2278      2278          2278   \n",
              "15               3586           3586        3586      3586          3586   \n",
              "16               2789           2789        2789      2789          2789   \n",
              "17               2002           2002        2002      2002          2002   \n",
              "18                781            781         781       781           781   \n",
              "19               6360           6360        6360      6360          6360   \n",
              "20               3907           3907        3907      3907          3907   \n",
              "21                208            208         208       208           208   \n",
              "23               1148           1148        1148      1148          1148   \n",
              "25                  1              1           1         1             1   \n",
              "61                  1              1           1         1             1   \n",
              "99               7078           7078        7078      7078          7078   \n",
              "\n",
              "           sentence_id  cap_subtopic  header  junk  eu_dummy  sentence_text  \n",
              "cap_topic                                                                    \n",
              "0                    2             2       2     2         2              2  \n",
              "1                 7127          7127    7127  7127      7127           7127  \n",
              "2                 5094          5094    5094  5094      5094           5094  \n",
              "3                 3014          3014    3014  3014      3014           3014  \n",
              "4                 1658          1658    1658  1658      1658           1658  \n",
              "5                 4673          4673    4673  4673      4673           4673  \n",
              "6                 4213          4213    4213  4213      4213           4213  \n",
              "7                 3461          3461    3461  3461      3461           3461  \n",
              "8                 2329          2329    2329  2329      2329           2329  \n",
              "9                 1621          1621    1621  1621      1621           1621  \n",
              "10                2139          2139    2139  2139      2139           2139  \n",
              "12                3912          3912    3912  3912      3912           3912  \n",
              "13                5808          5808    5808  5808      5808           5808  \n",
              "14                2278          2278    2278  2278      2278           2278  \n",
              "15                3586          3586    3586  3586      3586           3586  \n",
              "16                2789          2789    2789  2789      2789           2789  \n",
              "17                2002          2002    2002  2002      2002           2002  \n",
              "18                 781           781     781   781       781            781  \n",
              "19                6360          6360    6360  6360      6360           6360  \n",
              "20                3907          3907    3907  3907      3907           3907  \n",
              "21                 208           208     208   208       208            208  \n",
              "23                1148          1148    1148  1148      1148           1148  \n",
              "25                   1             1       1     1         1              1  \n",
              "61                   1             1       1     1         1              1  \n",
              "99                7078          7078    7078  7078      7078           7078  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cap_deu.groupby('cap_topic').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA5BvsxlvnTc",
        "outputId": "dc20cfb6-203d-4f7f-b086-66dcfbb1f5ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 73830 entries, 0 to 75189\n",
            "Data columns (total 12 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   Unnamed: 0     73830 non-null  int64 \n",
            " 1   election_year  73830 non-null  int64 \n",
            " 2   party_name     73830 non-null  object\n",
            " 3   party_id       73830 non-null  int64 \n",
            " 4   manifesto_id   73830 non-null  int64 \n",
            " 5   sentence_id    73830 non-null  int64 \n",
            " 6   cap_topic      73830 non-null  int64 \n",
            " 7   cap_subtopic   73830 non-null  int64 \n",
            " 8   header         73830 non-null  int64 \n",
            " 9   junk           73830 non-null  int64 \n",
            " 10  eu_dummy       73830 non-null  int64 \n",
            " 11  sentence_text  73830 non-null  object\n",
            "dtypes: int64(10), object(2)\n",
            "memory usage: 7.3+ MB\n"
          ]
        }
      ],
      "source": [
        "## Remove rows with topic = 0,21,23,25,61 because of too few data points\n",
        "cap_deu = cap_deu[~cap_deu.cap_topic.isin([0,21,23,25,61])]\n",
        "cap_deu.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BdGSrS6eXmXV"
      },
      "outputs": [],
      "source": [
        "cap_deu['cap_topic_new'] = cap_deu['cap_topic'].apply(functions.recode_topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "FpSThcOCVKJ_",
        "outputId": "a0acca21-acd7-42e6-8566-29651ed9ae56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>election_year</th>\n",
              "      <th>party_name</th>\n",
              "      <th>party_id</th>\n",
              "      <th>manifesto_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>cap_topic</th>\n",
              "      <th>cap_subtopic</th>\n",
              "      <th>header</th>\n",
              "      <th>junk</th>\n",
              "      <th>eu_dummy</th>\n",
              "      <th>sentence_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cap_topic_new</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "      <td>11494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "      <td>5094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "      <td>3014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "      <td>1658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "      <td>10481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "      <td>4213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "      <td>3461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "      <td>2329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "      <td>1621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "      <td>2139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "      <td>3912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "      <td>2278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "      <td>2789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "      <td>2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "      <td>6360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "      <td>3907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "      <td>7078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Unnamed: 0  election_year  party_name  party_id  manifesto_id  \\\n",
              "cap_topic_new                                                                  \n",
              "0                   11494          11494       11494     11494         11494   \n",
              "1                    5094           5094        5094      5094          5094   \n",
              "2                    3014           3014        3014      3014          3014   \n",
              "3                    1658           1658        1658      1658          1658   \n",
              "4                   10481          10481       10481     10481         10481   \n",
              "5                    4213           4213        4213      4213          4213   \n",
              "6                    3461           3461        3461      3461          3461   \n",
              "7                    2329           2329        2329      2329          2329   \n",
              "8                    1621           1621        1621      1621          1621   \n",
              "9                    2139           2139        2139      2139          2139   \n",
              "10                   3912           3912        3912      3912          3912   \n",
              "11                   2278           2278        2278      2278          2278   \n",
              "12                   2789           2789        2789      2789          2789   \n",
              "13                   2002           2002        2002      2002          2002   \n",
              "14                   6360           6360        6360      6360          6360   \n",
              "15                   3907           3907        3907      3907          3907   \n",
              "16                   7078           7078        7078      7078          7078   \n",
              "\n",
              "               sentence_id  cap_topic  cap_subtopic  header   junk  eu_dummy  \\\n",
              "cap_topic_new                                                                  \n",
              "0                    11494      11494         11494   11494  11494     11494   \n",
              "1                     5094       5094          5094    5094   5094      5094   \n",
              "2                     3014       3014          3014    3014   3014      3014   \n",
              "3                     1658       1658          1658    1658   1658      1658   \n",
              "4                    10481      10481         10481   10481  10481     10481   \n",
              "5                     4213       4213          4213    4213   4213      4213   \n",
              "6                     3461       3461          3461    3461   3461      3461   \n",
              "7                     2329       2329          2329    2329   2329      2329   \n",
              "8                     1621       1621          1621    1621   1621      1621   \n",
              "9                     2139       2139          2139    2139   2139      2139   \n",
              "10                    3912       3912          3912    3912   3912      3912   \n",
              "11                    2278       2278          2278    2278   2278      2278   \n",
              "12                    2789       2789          2789    2789   2789      2789   \n",
              "13                    2002       2002          2002    2002   2002      2002   \n",
              "14                    6360       6360          6360    6360   6360      6360   \n",
              "15                    3907       3907          3907    3907   3907      3907   \n",
              "16                    7078       7078          7078    7078   7078      7078   \n",
              "\n",
              "               sentence_text  \n",
              "cap_topic_new                 \n",
              "0                      11494  \n",
              "1                       5094  \n",
              "2                       3014  \n",
              "3                       1658  \n",
              "4                      10481  \n",
              "5                       4213  \n",
              "6                       3461  \n",
              "7                       2329  \n",
              "8                       1621  \n",
              "9                       2139  \n",
              "10                      3912  \n",
              "11                      2278  \n",
              "12                      2789  \n",
              "13                      2002  \n",
              "14                      6360  \n",
              "15                      3907  \n",
              "16                      7078  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cap_deu.groupby('cap_topic_new').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz7C9twbvh6L"
      },
      "source": [
        "## Adding metadata and speakers' background to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NHr-JUZHzU7B"
      },
      "outputs": [],
      "source": [
        "## Sentence length\n",
        "cap_deu.loc[:, 'length'] = cap_deu.sentence_text.str.split().str.len() ## sentence length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvaoD683XmXc",
        "outputId": "c1d5ae1c-72ba-4193-da97-0f4cb8304318"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'CDU', 'Die Linke', 'FDP', 'Grünen', 'PDS', 'SPD'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(cap_deu.party_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_i2c9PktXmXd"
      },
      "outputs": [],
      "source": [
        "cap_deu['party'] = cap_deu['party_name'].apply(functions.party_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G8lUp3xXmXc",
        "outputId": "b78f41c7-93a6-415e-a9d9-900c09398005"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'CDU/CSU', 'FDP', 'GRUENEN', 'PDS/DIE LINKE', 'SPD'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(cap_deu.party)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xv37B044oMFd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "arr_party = np.reshape(np.array(cap_deu['party']), (-1,1))\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_party_name = encoder.fit(arr_party).categories_[0].tolist()\n",
        "encoded_party_data = encoder.fit_transform(arr_party)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1VO1BRMivOgn"
      },
      "outputs": [],
      "source": [
        "df_toappend_1 = pd.DataFrame(encoded_party_data, columns = encoded_party_name)\n",
        "cap_deu =  pd.concat([cap_deu.reset_index(drop=True),df_toappend_1.reset_index(drop=True)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "B935_9ESVIZu",
        "outputId": "5a65e6d3-5711-42b3-9989-c59b33d9c333"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>election_year</th>\n",
              "      <th>party_name</th>\n",
              "      <th>party_id</th>\n",
              "      <th>manifesto_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>cap_topic</th>\n",
              "      <th>cap_subtopic</th>\n",
              "      <th>header</th>\n",
              "      <th>junk</th>\n",
              "      <th>eu_dummy</th>\n",
              "      <th>sentence_text</th>\n",
              "      <th>cap_topic_new</th>\n",
              "      <th>length</th>\n",
              "      <th>party</th>\n",
              "      <th>CDU/CSU</th>\n",
              "      <th>FDP</th>\n",
              "      <th>GRUENEN</th>\n",
              "      <th>PDS/DIE LINKE</th>\n",
              "      <th>SPD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Für ein freies Deutschland</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Wählerinnen und Wähler!</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>3</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Am 14. August entscheidet XX darüber, wie ein ...</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Heute ist unser land geteilt.</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>2099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Swjetrussland hat seine Besatzungszone separiert.</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  election_year party_name  party_id  manifesto_id  sentence_id  \\\n",
              "0           1           1949        SPD         1         19491            1   \n",
              "1           2           1949        SPD         1         19491            2   \n",
              "2           3           1949        SPD         1         19491            3   \n",
              "3           4           1949        SPD         1         19491            4   \n",
              "4           5           1949        SPD         1         19491            5   \n",
              "\n",
              "   cap_topic  cap_subtopic  header  junk  eu_dummy  \\\n",
              "0         99            99       1     0         0   \n",
              "1         99            99       0     0         0   \n",
              "2         99            99       0     0         0   \n",
              "3         20          2099       0     0         0   \n",
              "4         20          2099       0     0         0   \n",
              "\n",
              "                                       sentence_text  cap_topic_new  length  \\\n",
              "0                         Für ein freies Deutschland             16       4   \n",
              "1                            Wählerinnen und Wähler!             16       3   \n",
              "2  Am 14. August entscheidet XX darüber, wie ein ...             16      17   \n",
              "3                      Heute ist unser land geteilt.             15       5   \n",
              "4  Swjetrussland hat seine Besatzungszone separiert.             15       5   \n",
              "\n",
              "  party  CDU/CSU  FDP  GRUENEN  PDS/DIE LINKE  SPD  \n",
              "0   SPD      0.0  0.0      0.0            0.0  1.0  \n",
              "1   SPD      0.0  0.0      0.0            0.0  1.0  \n",
              "2   SPD      0.0  0.0      0.0            0.0  1.0  \n",
              "3   SPD      0.0  0.0      0.0            0.0  1.0  \n",
              "4   SPD      0.0  0.0      0.0            0.0  1.0  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cap_deu.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cHZoFUqBXmXd"
      },
      "outputs": [],
      "source": [
        "cap_deu['gov_last'] = cap_deu.apply(lambda x: functions.gov_last(x['party'], x['election_year']), axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCLYsKo1XmXd",
        "outputId": "690894ed-ec54-43d5-882d-27966eaa158c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(cap_deu.loc[(cap_deu.election_year == 1972) & (cap_deu.party == 'CDU/CSU'), 'gov_last'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tHVnrBh8XmXe"
      },
      "outputs": [],
      "source": [
        "cap_deu['opp_last'] = cap_deu.apply(lambda x: functions.opp_last(x['party'], x['election_year']), axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QBDS0umLXmXe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(cap_deu.loc[(cap_deu.election_year == 1972) & (cap_deu.party == 'CDU/CSU'), 'opp_last'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "755Wylh10hXn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "arr_years = np.reshape(np.array(cap_deu['election_year']), (-1,1))\n",
        "encoder = OrdinalEncoder()\n",
        "encoded_year_data = encoder.fit_transform(arr_years)\n",
        "cap_deu['year_recoded'] = encoded_year_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2eupn-u__5yl"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "arr_senlen = np.reshape(np.array(cap_deu['length']),(-1,1))\n",
        "encoder = StandardScaler()\n",
        "encoded_senlen = encoder.fit_transform(arr_senlen)\n",
        "cap_deu['length_recoded'] = encoded_senlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_mf5P-Xdgj_",
        "outputId": "b049c0d4-e18e-4498-a573-a1d55763b6e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(set(cap_deu['year_recoded']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEetLpxWXmXe"
      },
      "source": [
        "## Create datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FfrSikjVBqFC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>election_year</th>\n",
              "      <th>party_name</th>\n",
              "      <th>party_id</th>\n",
              "      <th>manifesto_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>cap_topic</th>\n",
              "      <th>cap_subtopic</th>\n",
              "      <th>header</th>\n",
              "      <th>junk</th>\n",
              "      <th>...</th>\n",
              "      <th>party</th>\n",
              "      <th>CDU/CSU</th>\n",
              "      <th>FDP</th>\n",
              "      <th>GRUENEN</th>\n",
              "      <th>PDS/DIE LINKE</th>\n",
              "      <th>SPD</th>\n",
              "      <th>gov_last</th>\n",
              "      <th>opp_last</th>\n",
              "      <th>year_recoded</th>\n",
              "      <th>length_recoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.311245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.426313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>3</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.196177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1949</td>\n",
              "      <td>SPD</td>\n",
              "      <td>1</td>\n",
              "      <td>19491</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>2099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>SPD</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.196177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  election_year party_name  party_id  manifesto_id  sentence_id  \\\n",
              "0           1           1949        SPD         1         19491            1   \n",
              "1           2           1949        SPD         1         19491            2   \n",
              "2           3           1949        SPD         1         19491            3   \n",
              "3           4           1949        SPD         1         19491            4   \n",
              "4           5           1949        SPD         1         19491            5   \n",
              "\n",
              "   cap_topic  cap_subtopic  header  junk  ...  party CDU/CSU  FDP  GRUENEN  \\\n",
              "0         99            99       1     0  ...    SPD     0.0  0.0      0.0   \n",
              "1         99            99       0     0  ...    SPD     0.0  0.0      0.0   \n",
              "2         99            99       0     0  ...    SPD     0.0  0.0      0.0   \n",
              "3         20          2099       0     0  ...    SPD     0.0  0.0      0.0   \n",
              "4         20          2099       0     0  ...    SPD     0.0  0.0      0.0   \n",
              "\n",
              "  PDS/DIE LINKE  SPD  gov_last  opp_last  year_recoded  length_recoded  \n",
              "0           0.0  1.0         0         0           0.0       -1.311245  \n",
              "1           0.0  1.0         0         0           0.0       -1.426313  \n",
              "2           0.0  1.0         0         0           0.0        0.184644  \n",
              "3           0.0  1.0         0         0           0.0       -1.196177  \n",
              "4           0.0  1.0         0         0           0.0       -1.196177  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cap_deu.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QBIDNezXXmXf"
      },
      "outputs": [],
      "source": [
        "bert_model = 'deepset/gbert-base'\n",
        "tokenizer = BertTokenizerFast.from_pretrained(bert_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IGPWv2zaXmXf"
      },
      "outputs": [],
      "source": [
        "df_train_new, df_test_new = train_test_split(cap_deu, test_size=0.2, random_state=1234, stratify = cap_deu['cap_topic_new'])\n",
        "df_train_new, df_eval_new = train_test_split(df_train_new, test_size=0.3, random_state=1234, stratify = df_train_new['cap_topic_new'])\n",
        "df_train, df_test = train_test_split(cap_deu, test_size=0.2, random_state=1234, stratify = cap_deu['cap_topic'])\n",
        "df_train, df_eval = train_test_split(df_train, test_size=0.3, random_state=1234, stratify = df_train['cap_topic'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qqQoXunHXmXg"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.reset_index()\n",
        "df_test = df_test.reset_index()\n",
        "df_eval = df_eval.reset_index()\n",
        "df_train_new = df_train_new.reset_index()\n",
        "df_test_new = df_test_new.reset_index()\n",
        "df_eval_new = df_eval_new.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>election_year</th>\n",
              "      <th>party_name</th>\n",
              "      <th>party_id</th>\n",
              "      <th>manifesto_id</th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>cap_topic</th>\n",
              "      <th>cap_subtopic</th>\n",
              "      <th>header</th>\n",
              "      <th>...</th>\n",
              "      <th>party</th>\n",
              "      <th>CDU/CSU</th>\n",
              "      <th>FDP</th>\n",
              "      <th>GRUENEN</th>\n",
              "      <th>PDS/DIE LINKE</th>\n",
              "      <th>SPD</th>\n",
              "      <th>gov_last</th>\n",
              "      <th>opp_last</th>\n",
              "      <th>year_recoded</th>\n",
              "      <th>length_recoded</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cap_topic_new</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>...</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "      <td>6437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>...</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "      <td>2852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>...</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "      <td>1688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>...</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>...</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "      <td>5869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>...</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "      <td>2360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>...</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "      <td>1938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>...</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "      <td>1304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>...</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "      <td>908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>...</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "      <td>1198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>...</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "      <td>2191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>...</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "      <td>1275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>...</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "      <td>1562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>...</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>...</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "      <td>3562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>...</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "      <td>2188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>...</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "      <td>3963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               index  Unnamed: 0  election_year  party_name  party_id  \\\n",
              "cap_topic_new                                                           \n",
              "0               6437        6437           6437        6437      6437   \n",
              "1               2852        2852           2852        2852      2852   \n",
              "2               1688        1688           1688        1688      1688   \n",
              "3                928         928            928         928       928   \n",
              "4               5869        5869           5869        5869      5869   \n",
              "5               2360        2360           2360        2360      2360   \n",
              "6               1938        1938           1938        1938      1938   \n",
              "7               1304        1304           1304        1304      1304   \n",
              "8                908         908            908         908       908   \n",
              "9               1198        1198           1198        1198      1198   \n",
              "10              2191        2191           2191        2191      2191   \n",
              "11              1275        1275           1275        1275      1275   \n",
              "12              1562        1562           1562        1562      1562   \n",
              "13              1121        1121           1121        1121      1121   \n",
              "14              3562        3562           3562        3562      3562   \n",
              "15              2188        2188           2188        2188      2188   \n",
              "16              3963        3963           3963        3963      3963   \n",
              "\n",
              "               manifesto_id  sentence_id  cap_topic  cap_subtopic  header  \\\n",
              "cap_topic_new                                                               \n",
              "0                      6437         6437       6437          6437    6437   \n",
              "1                      2852         2852       2852          2852    2852   \n",
              "2                      1688         1688       1688          1688    1688   \n",
              "3                       928          928        928           928     928   \n",
              "4                      5869         5869       5869          5869    5869   \n",
              "5                      2360         2360       2360          2360    2360   \n",
              "6                      1938         1938       1938          1938    1938   \n",
              "7                      1304         1304       1304          1304    1304   \n",
              "8                       908          908        908           908     908   \n",
              "9                      1198         1198       1198          1198    1198   \n",
              "10                     2191         2191       2191          2191    2191   \n",
              "11                     1275         1275       1275          1275    1275   \n",
              "12                     1562         1562       1562          1562    1562   \n",
              "13                     1121         1121       1121          1121    1121   \n",
              "14                     3562         3562       3562          3562    3562   \n",
              "15                     2188         2188       2188          2188    2188   \n",
              "16                     3963         3963       3963          3963    3963   \n",
              "\n",
              "               ...  party  CDU/CSU   FDP  GRUENEN  PDS/DIE LINKE   SPD  \\\n",
              "cap_topic_new  ...                                                       \n",
              "0              ...   6437     6437  6437     6437           6437  6437   \n",
              "1              ...   2852     2852  2852     2852           2852  2852   \n",
              "2              ...   1688     1688  1688     1688           1688  1688   \n",
              "3              ...    928      928   928      928            928   928   \n",
              "4              ...   5869     5869  5869     5869           5869  5869   \n",
              "5              ...   2360     2360  2360     2360           2360  2360   \n",
              "6              ...   1938     1938  1938     1938           1938  1938   \n",
              "7              ...   1304     1304  1304     1304           1304  1304   \n",
              "8              ...    908      908   908      908            908   908   \n",
              "9              ...   1198     1198  1198     1198           1198  1198   \n",
              "10             ...   2191     2191  2191     2191           2191  2191   \n",
              "11             ...   1275     1275  1275     1275           1275  1275   \n",
              "12             ...   1562     1562  1562     1562           1562  1562   \n",
              "13             ...   1121     1121  1121     1121           1121  1121   \n",
              "14             ...   3562     3562  3562     3562           3562  3562   \n",
              "15             ...   2188     2188  2188     2188           2188  2188   \n",
              "16             ...   3963     3963  3963     3963           3963  3963   \n",
              "\n",
              "               gov_last  opp_last  year_recoded  length_recoded  \n",
              "cap_topic_new                                                    \n",
              "0                  6437      6437          6437            6437  \n",
              "1                  2852      2852          2852            2852  \n",
              "2                  1688      1688          1688            1688  \n",
              "3                   928       928           928             928  \n",
              "4                  5869      5869          5869            5869  \n",
              "5                  2360      2360          2360            2360  \n",
              "6                  1938      1938          1938            1938  \n",
              "7                  1304      1304          1304            1304  \n",
              "8                   908       908           908             908  \n",
              "9                  1198      1198          1198            1198  \n",
              "10                 2191      2191          2191            2191  \n",
              "11                 1275      1275          1275            1275  \n",
              "12                 1562      1562          1562            1562  \n",
              "13                 1121      1121          1121            1121  \n",
              "14                 3562      3562          3562            3562  \n",
              "15                 2188      2188          2188            2188  \n",
              "16                 3963      3963          3963            3963  \n",
              "\n",
              "[17 rows x 24 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.groupby('cap_topic_new').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmenter = naw.ContextualWordEmbsAug(model_path=bert_model, model_type = 'bert', device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_cols = ['cap_topic_new','SPD', 'CDU/CSU', 'FDP', 'PDS/DIE LINKE', 'GRUENEN', 'gov_last', 'opp_last', 'year_recoded']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts, vars = functions.augment_iter(list_cols = list_cols, dataset = df_train, text_col = 'sentence_text', n_aug = 3, augmenter=augmenter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_aug = pd.DataFrame(vars, columns = list_cols)\n",
        "df_train_aug['sentence_text'] = texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_aug.loc[:,'length'] = df_train_aug.sentence_text.str.split().str.len()\n",
        "arr_senlen = np.reshape(np.array(df_train_aug['length']),(-1,1))\n",
        "encoder = StandardScaler()\n",
        "encoded_senlen = encoder.fit_transform(arr_senlen)\n",
        "df_train_aug['length_recoded'] = encoded_senlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_cols = ['cap_topic','SPD', 'CDU/CSU', 'FDP', 'PDS/DIE LINKE', 'GRUENEN', 'gov_last', 'opp_last', 'year_recoded']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts, vars = functions.augment_iter(list_cols = list_cols, dataset = df_train_new, text_col = 'sentence_text', n_aug = 3, augmenter=augmenter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_new_aug = pd.DataFrame(vars, columns = list_cols)\n",
        "df_train_new_aug['sentence_text'] = texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_new_aug.loc[:,'length'] = df_train_new_aug.sentence_text.str.split().str.len()\n",
        "arr_senlen = np.reshape(np.array(df_train_new_aug['length']),(-1,1))\n",
        "encoder = StandardScaler()\n",
        "encoded_senlen = encoder.fit_transform(arr_senlen)\n",
        "df_train_new_aug['length_recoded'] = encoded_senlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_extra_dims = ['SPD', 'CDU/CSU', 'FDP', 'PDS/DIE LINKE', 'GRUENEN', 'gov_last', 'opp_last', 'length_recoded']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxivvRy6XmXg"
      },
      "outputs": [],
      "source": [
        "train_meta_dataset = dataset.CustomTextDataset(df_train, list_extra_dims)\n",
        "train_meta_dataset_aug = dataset.CustomTextDataset(df_train_aug, list_extra_dims)\n",
        "test_meta_dataset = dataset.CustomTextDataset(df_test, list_extra_dims)\n",
        "eval_meta_dataset = dataset.CustomTextDataset(df_eval, list_extra_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = dataset.BareDataset(df_train)\n",
        "train_dataset_aug = dataset.BareDataset(df_train_aug)\n",
        "test_dataset = dataset.BareDataset(df_test)\n",
        "eval_dataset = dataset.BareDataset(df_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_meta_dataset_new = dataset.CustomTextDataset(df_train_new, list_extra_dims)\n",
        "train_meta_dataset_new_aug = dataset.CustomTextDataset(df_train_new_aug, list_extra_dims)\n",
        "test_meta_dataset_new = dataset.CustomTextDataset(df_test_new, list_extra_dims)\n",
        "eval_meta_dataset_new = dataset.CustomTextDataset(df_eval_new, list_extra_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset_new = dataset.BareDataset(df_train_new)\n",
        "train_dataset_new_aug = dataset.BareDataset(df_train_new_aug)\n",
        "test_dataset_new = dataset.BareDataset(df_test_new)\n",
        "eval_dataset_new = dataset.BareDataset(df_eval_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ds0MQn7XmXg"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "train_dataloader_aug =  DataLoader(train_dataset_aug, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_meta_dataloader = DataLoader(train_meta_dataset, batch_size=16, shuffle=True)\n",
        "train_meta_dataloader_aug =  DataLoader(train_meta_dataset_aug, batch_size=16, shuffle=True)\n",
        "test_meta_dataloader = DataLoader(test_meta_dataset, batch_size=16, shuffle=True)\n",
        "eval_meta_dataloader = DataLoader(eval_meta_dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader_new = DataLoader(train_dataset_new, batch_size=16, shuffle=True)\n",
        "train_dataloader_new_aug =  DataLoader(train_dataset_new_aug, batch_size=16, shuffle=True)\n",
        "test_dataloader_new = DataLoader(test_dataset_new, batch_size=16, shuffle=True)\n",
        "eval_dataloader_new = DataLoader(eval_dataset_new, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_meta_dataloader = DataLoader(train_meta_dataset_new, batch_size=16, shuffle=True)\n",
        "train_meta_dataloader_new_aug =  DataLoader(train_meta_dataset_new_aug, batch_size=16, shuffle=True)\n",
        "test_meta_dataloader_new = DataLoader(test_meta_dataset_new, batch_size=16, shuffle=True)\n",
        "eval_meta_dataloader_new = DataLoader(eval_meta_dataset_new, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX78kM_sXmXg",
        "outputId": "361bc2fb-3667-4160-e70f-43077a052cf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_base = models.NormalBERT(bert_model, labels_count=17).to(device)\n",
        "model_meta = models.MetaBERT(bert_model, labels_count=17, extra_dim=8, hidden_dim=20).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5btjUKHWXmXg"
      },
      "source": [
        "# Train-test loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "seed_val = 1670\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normal BERT, no augmentation, standard topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "optimizer = torch.optim.Adam(model_base.parameters(), lr=0.0000525)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode = 'min')\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    functions.train_normal(train_dataloader, model_base, loss_fn, optimizer, scheduler)\n",
        "    functions.test_normal(eval_dataloader, model_base, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normal BERT, no augmentation, recoded topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normal BERT, with augmentation, standard topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normal BERT, with augmentation, recoded topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta BERT, no augmentation, standard topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta BERT, no augmentation, recoded topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta BERT, with augmentation, standard topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta BERT, with augmentation, recoded topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT7Km310XmXh"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0000525)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode = 'min')\n",
        "loss_fn = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYN9c9cZXmXh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG7QXkJoqDTH",
        "outputId": "2e70bc2e-3a47-4c89-abcd-6e3300776c3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "\n",
            "Training...\n",
            "loss: 2.794420  [    0/30601]. Took 0:00:01\n",
            "loss: 2.662218  [  800/30601]. Took 0:00:34\n",
            "loss: 2.548109  [ 1600/30601]. Took 0:01:07\n",
            "loss: 2.495279  [ 2400/30601]. Took 0:01:39\n",
            "loss: 2.700026  [ 3200/30601]. Took 0:02:12\n",
            "loss: 2.603777  [ 4000/30601]. Took 0:02:45\n",
            "loss: 2.168311  [ 4800/30601]. Took 0:03:18\n",
            "loss: 2.428246  [ 5600/30601]. Took 0:03:51\n",
            "loss: 2.345435  [ 6400/30601]. Took 0:04:24\n",
            "loss: 1.979844  [ 7200/30601]. Took 0:04:57\n",
            "loss: 1.996744  [ 8000/30601]. Took 0:05:29\n",
            "loss: 1.968703  [ 8800/30601]. Took 0:06:02\n",
            "loss: 1.770010  [ 9600/30601]. Took 0:06:35\n",
            "loss: 1.980413  [10400/30601]. Took 0:07:08\n",
            "loss: 2.295319  [11200/30601]. Took 0:07:41\n",
            "loss: 1.491683  [12000/30601]. Took 0:08:14\n",
            "loss: 1.995092  [12800/30601]. Took 0:08:47\n",
            "loss: 2.177581  [13600/30601]. Took 0:09:19\n",
            "loss: 1.684760  [14400/30601]. Took 0:09:52\n",
            "loss: 1.993751  [15200/30601]. Took 0:10:25\n",
            "loss: 2.154440  [16000/30601]. Took 0:10:58\n",
            "loss: 1.448552  [16800/30601]. Took 0:11:31\n",
            "loss: 2.211304  [17600/30601]. Took 0:12:04\n",
            "loss: 1.390060  [18400/30601]. Took 0:12:37\n",
            "loss: 1.801273  [19200/30601]. Took 0:13:09\n",
            "loss: 1.806726  [20000/30601]. Took 0:13:42\n",
            "loss: 1.738307  [20800/30601]. Took 0:14:15\n",
            "loss: 1.321640  [21600/30601]. Took 0:14:48\n",
            "loss: 1.682504  [22400/30601]. Took 0:15:21\n",
            "loss: 1.828884  [23200/30601]. Took 0:15:54\n",
            "loss: 2.020876  [24000/30601]. Took 0:16:26\n",
            "loss: 1.541422  [24800/30601]. Took 0:16:59\n",
            "loss: 1.178296  [25600/30601]. Took 0:17:32\n",
            "loss: 1.814732  [26400/30601]. Took 0:18:05\n",
            "loss: 1.317544  [27200/30601]. Took 0:18:38\n",
            "loss: 1.470259  [28000/30601]. Took 0:19:11\n",
            "loss: 0.629163  [28800/30601]. Took 0:19:44\n",
            "loss: 0.745279  [29600/30601]. Took 0:20:17\n",
            "loss: 1.326095  [30400/30601]. Took 0:20:49\n",
            "\n",
            "  Training epoch took: 0:20:57\n",
            "Test Error: \n",
            " Accuracy: 64.1%, Avg loss: 1.447859 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "\n",
            "Training...\n",
            "loss: 1.450167  [    0/30601]. Took 0:00:01\n",
            "loss: 1.272074  [  800/30601]. Took 0:00:33\n",
            "loss: 1.352220  [ 1600/30601]. Took 0:01:06\n",
            "loss: 1.287273  [ 2400/30601]. Took 0:01:39\n",
            "loss: 1.202899  [ 3200/30601]. Took 0:02:12\n",
            "loss: 1.407136  [ 4000/30601]. Took 0:02:45\n",
            "loss: 1.273144  [ 4800/30601]. Took 0:03:18\n",
            "loss: 1.823341  [ 5600/30601]. Took 0:03:51\n",
            "loss: 1.824458  [ 6400/30601]. Took 0:04:23\n",
            "loss: 1.057006  [ 7200/30601]. Took 0:04:56\n",
            "loss: 0.911149  [ 8000/30601]. Took 0:05:29\n",
            "loss: 1.110013  [ 8800/30601]. Took 0:06:02\n",
            "loss: 0.998140  [ 9600/30601]. Took 0:06:35\n",
            "loss: 1.499329  [10400/30601]. Took 0:07:08\n",
            "loss: 1.282093  [11200/30601]. Took 0:07:41\n",
            "loss: 1.323650  [12000/30601]. Took 0:08:13\n",
            "loss: 1.078692  [12800/30601]. Took 0:08:46\n",
            "loss: 1.940857  [13600/30601]. Took 0:09:19\n",
            "loss: 1.247787  [14400/30601]. Took 0:09:52\n",
            "loss: 0.678725  [15200/30601]. Took 0:10:25\n",
            "loss: 1.255630  [16000/30601]. Took 0:10:58\n",
            "loss: 1.864327  [16800/30601]. Took 0:11:31\n",
            "loss: 1.223367  [17600/30601]. Took 0:12:03\n",
            "loss: 1.066130  [18400/30601]. Took 0:12:36\n",
            "loss: 0.936743  [19200/30601]. Took 0:13:09\n",
            "loss: 1.075559  [20000/30601]. Took 0:13:42\n",
            "loss: 1.187104  [20800/30601]. Took 0:14:15\n",
            "loss: 0.958544  [21600/30601]. Took 0:14:48\n",
            "loss: 0.622560  [22400/30601]. Took 0:15:21\n",
            "loss: 1.291540  [23200/30601]. Took 0:15:53\n",
            "loss: 1.071260  [24000/30601]. Took 0:16:26\n",
            "loss: 1.419424  [24800/30601]. Took 0:16:59\n",
            "loss: 0.830569  [25600/30601]. Took 0:17:32\n",
            "loss: 1.302651  [26400/30601]. Took 0:18:05\n",
            "loss: 0.877328  [27200/30601]. Took 0:18:38\n",
            "loss: 1.034943  [28000/30601]. Took 0:19:11\n",
            "loss: 0.883628  [28800/30601]. Took 0:19:43\n",
            "loss: 1.117684  [29600/30601]. Took 0:20:16\n",
            "loss: 1.480416  [30400/30601]. Took 0:20:49\n",
            "\n",
            "  Training epoch took: 0:20:57\n",
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 1.167731 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "\n",
            "Training...\n",
            "loss: 0.570682  [    0/30601]. Took 0:00:01\n",
            "loss: 0.835904  [  800/30601]. Took 0:00:34\n",
            "loss: 0.853627  [ 1600/30601]. Took 0:01:06\n",
            "loss: 1.299906  [ 2400/30601]. Took 0:01:39\n",
            "loss: 0.949838  [ 3200/30601]. Took 0:02:12\n",
            "loss: 1.638593  [ 4000/30601]. Took 0:02:45\n",
            "loss: 1.381888  [ 4800/30601]. Took 0:03:18\n",
            "loss: 0.537511  [ 5600/30601]. Took 0:03:51\n",
            "loss: 1.017070  [ 6400/30601]. Took 0:04:23\n",
            "loss: 1.202908  [ 7200/30601]. Took 0:04:56\n",
            "loss: 1.902590  [ 8000/30601]. Took 0:05:29\n",
            "loss: 0.186690  [ 8800/30601]. Took 0:06:02\n",
            "loss: 0.847553  [ 9600/30601]. Took 0:06:35\n",
            "loss: 0.713392  [10400/30601]. Took 0:07:08\n",
            "loss: 0.890897  [11200/30601]. Took 0:07:41\n",
            "loss: 0.731246  [12000/30601]. Took 0:08:13\n",
            "loss: 1.213737  [12800/30601]. Took 0:08:46\n",
            "loss: 0.846289  [13600/30601]. Took 0:09:19\n",
            "loss: 0.895673  [14400/30601]. Took 0:09:52\n",
            "loss: 0.833441  [15200/30601]. Took 0:10:25\n",
            "loss: 0.900511  [16000/30601]. Took 0:10:58\n",
            "loss: 0.887595  [16800/30601]. Took 0:11:31\n",
            "loss: 1.258453  [17600/30601]. Took 0:12:03\n",
            "loss: 0.952756  [18400/30601]. Took 0:12:36\n",
            "loss: 1.020552  [19200/30601]. Took 0:13:09\n",
            "loss: 0.884875  [20000/30601]. Took 0:13:42\n",
            "loss: 0.920161  [20800/30601]. Took 0:14:15\n",
            "loss: 0.765705  [21600/30601]. Took 0:14:48\n",
            "loss: 0.888647  [22400/30601]. Took 0:15:21\n",
            "loss: 1.034019  [23200/30601]. Took 0:15:53\n",
            "loss: 0.764565  [24000/30601]. Took 0:16:26\n",
            "loss: 1.097879  [24800/30601]. Took 0:16:59\n",
            "loss: 0.977851  [25600/30601]. Took 0:17:32\n",
            "loss: 0.939898  [26400/30601]. Took 0:18:05\n",
            "loss: 1.597532  [27200/30601]. Took 0:18:38\n",
            "loss: 1.209703  [28000/30601]. Took 0:19:10\n",
            "loss: 0.880094  [28800/30601]. Took 0:19:43\n",
            "loss: 0.729163  [29600/30601]. Took 0:20:16\n",
            "loss: 0.564312  [30400/30601]. Took 0:20:49\n",
            "\n",
            "  Training epoch took: 0:20:56\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 1.117948 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "\n",
            "Training...\n",
            "loss: 0.496479  [    0/30601]. Took 0:00:01\n",
            "loss: 0.323143  [  800/30601]. Took 0:00:34\n",
            "loss: 1.671662  [ 1600/30601]. Took 0:01:06\n",
            "loss: 0.767285  [ 2400/30601]. Took 0:01:39\n",
            "loss: 0.379840  [ 3200/30601]. Took 0:02:12\n",
            "loss: 0.953735  [ 4000/30601]. Took 0:02:45\n",
            "loss: 0.318069  [ 4800/30601]. Took 0:03:18\n",
            "loss: 0.660050  [ 5600/30601]. Took 0:03:51\n",
            "loss: 0.644426  [ 6400/30601]. Took 0:04:23\n",
            "loss: 0.517290  [ 7200/30601]. Took 0:04:56\n",
            "loss: 1.293034  [ 8000/30601]. Took 0:05:29\n",
            "loss: 0.967264  [ 8800/30601]. Took 0:06:02\n",
            "loss: 0.933083  [ 9600/30601]. Took 0:06:35\n",
            "loss: 0.613704  [10400/30601]. Took 0:07:08\n",
            "loss: 0.501071  [11200/30601]. Took 0:07:40\n",
            "loss: 0.871370  [12000/30601]. Took 0:08:13\n",
            "loss: 0.813288  [12800/30601]. Took 0:08:46\n",
            "loss: 0.754289  [13600/30601]. Took 0:09:19\n",
            "loss: 0.916782  [14400/30601]. Took 0:09:52\n",
            "loss: 0.967588  [15200/30601]. Took 0:10:25\n",
            "loss: 0.647680  [16000/30601]. Took 0:10:58\n",
            "loss: 0.528358  [16800/30601]. Took 0:11:30\n",
            "loss: 0.330889  [17600/30601]. Took 0:12:03\n",
            "loss: 0.721667  [18400/30601]. Took 0:12:36\n",
            "loss: 0.759125  [19200/30601]. Took 0:13:09\n",
            "loss: 0.769237  [20000/30601]. Took 0:13:42\n",
            "loss: 0.682733  [20800/30601]. Took 0:14:14\n",
            "loss: 0.779902  [21600/30601]. Took 0:14:47\n",
            "loss: 1.251172  [22400/30601]. Took 0:15:20\n",
            "loss: 0.494799  [23200/30601]. Took 0:15:53\n",
            "loss: 0.896719  [24000/30601]. Took 0:16:26\n",
            "loss: 0.225274  [24800/30601]. Took 0:16:58\n",
            "loss: 1.025207  [25600/30601]. Took 0:17:31\n",
            "loss: 0.975788  [26400/30601]. Took 0:18:04\n",
            "loss: 0.880185  [27200/30601]. Took 0:18:37\n",
            "loss: 0.191496  [28000/30601]. Took 0:19:10\n",
            "loss: 1.556454  [28800/30601]. Took 0:19:43\n",
            "loss: 0.503025  [29600/30601]. Took 0:20:15\n",
            "loss: 0.665992  [30400/30601]. Took 0:20:48\n",
            "\n",
            "  Training epoch took: 0:20:56\n",
            "Test Error: \n",
            " Accuracy: 73.2%, Avg loss: 1.103797 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "\n",
            "Training...\n",
            "loss: 0.402634  [    0/30601]. Took 0:00:01\n",
            "loss: 0.417296  [  800/30601]. Took 0:00:33\n",
            "loss: 0.224544  [ 1600/30601]. Took 0:01:06\n",
            "loss: 0.243900  [ 2400/30601]. Took 0:01:39\n",
            "loss: 0.308293  [ 3200/30601]. Took 0:02:12\n",
            "loss: 0.498636  [ 4000/30601]. Took 0:02:45\n",
            "loss: 0.370222  [ 4800/30601]. Took 0:03:18\n",
            "loss: 0.390861  [ 5600/30601]. Took 0:03:50\n",
            "loss: 0.519252  [ 6400/30601]. Took 0:04:23\n",
            "loss: 0.486362  [ 7200/30601]. Took 0:04:56\n",
            "loss: 0.334269  [ 8000/30601]. Took 0:05:29\n",
            "loss: 0.565696  [ 8800/30601]. Took 0:06:02\n",
            "loss: 0.337267  [ 9600/30601]. Took 0:06:35\n",
            "loss: 0.522057  [10400/30601]. Took 0:07:07\n",
            "loss: 1.075891  [11200/30601]. Took 0:07:40\n",
            "loss: 0.141854  [12000/30601]. Took 0:08:13\n",
            "loss: 0.741271  [12800/30601]. Took 0:08:46\n",
            "loss: 0.344330  [13600/30601]. Took 0:09:19\n",
            "loss: 0.163255  [14400/30601]. Took 0:09:52\n",
            "loss: 1.001308  [15200/30601]. Took 0:10:24\n",
            "loss: 1.267938  [16000/30601]. Took 0:10:57\n",
            "loss: 0.333741  [16800/30601]. Took 0:11:30\n",
            "loss: 0.755164  [17600/30601]. Took 0:12:03\n",
            "loss: 0.594571  [18400/30601]. Took 0:12:36\n",
            "loss: 0.663937  [19200/30601]. Took 0:13:09\n",
            "loss: 0.558819  [20000/30601]. Took 0:13:41\n",
            "loss: 0.808699  [20800/30601]. Took 0:14:14\n",
            "loss: 0.328854  [21600/30601]. Took 0:14:47\n",
            "loss: 0.514238  [22400/30601]. Took 0:15:20\n",
            "loss: 0.287204  [23200/30601]. Took 0:15:53\n",
            "loss: 0.081036  [24000/30601]. Took 0:16:25\n",
            "loss: 0.894930  [24800/30601]. Took 0:16:58\n",
            "loss: 0.736988  [25600/30601]. Took 0:17:31\n",
            "loss: 0.993588  [26400/30601]. Took 0:18:04\n",
            "loss: 0.229319  [27200/30601]. Took 0:18:37\n",
            "loss: 1.542891  [28000/30601]. Took 0:19:10\n",
            "loss: 0.244989  [28800/30601]. Took 0:19:42\n",
            "loss: 1.021151  [29600/30601]. Took 0:20:15\n",
            "loss: 0.453790  [30400/30601]. Took 0:20:48\n",
            "\n",
            "  Training epoch took: 0:20:56\n",
            "Test Error: \n",
            " Accuracy: 72.7%, Avg loss: 1.168654 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
        "    eval_loop(eval_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHkCmQNRuiLx"
      },
      "outputs": [],
      "source": [
        "output = torch.full([10, 64], 1.5)\n",
        "target = torch.ones([10, 64], dtype=torch.float32)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soVjfVBGunAk"
      },
      "outputs": [],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YOUEtnnc9Nn"
      },
      "outputs": [],
      "source": [
        "set(cap_deu['year_recoded'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75jGQ41BPneS"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC55STu_NkNU"
      },
      "outputs": [],
      "source": [
        "ls_res = []\n",
        "ls_y = []\n",
        "with torch.no_grad():\n",
        "  for item in test_dataloader:\n",
        "    list_keys = [x for i,x in enumerate(list(item)) if i not in [0,1,2,len(list(item))-1, len(list(item))-2]]\n",
        "    extras =  torch.cat(tuple(item[key] for key in list_keys), dim=1).to(device)\n",
        "    output = model(input_ids = item['input_ids'], attention_mask = item['attention_mask'], token_type_ids = item['token_type_ids'], extras = extras, year=item['year'])\n",
        "    argmax = output.argmax(-1).detach().cpu().numpy()\n",
        "    ls_res.append(argmax)\n",
        "    y = item['labels'].detach().cpu().numpy()\n",
        "    ls_y.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yErpK_JKJqV0"
      },
      "outputs": [],
      "source": [
        "ls_y_1 = np.concatenate(ls_y).tolist()\n",
        "ls_res_1 = np.concatenate(ls_res).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0HhsE84Jth7"
      },
      "outputs": [],
      "source": [
        " precision, recall, f1, n = precision_recall_fscore_support(ls_res_1, ls_y_1, average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUYgGKcSJudm"
      },
      "outputs": [],
      "source": [
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C45TqvXLoaGb"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join('MetaBERT', 'results', 'model.pth')\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcXFywJPZe-H"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join('MetaBERT', 'results', 'model.pth')\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AczDGeXaKW2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZWe5tJK1B-1"
      },
      "outputs": [],
      "source": [
        "cap_deu_9418_econsoc = cap_deu_9418_long[cap_deu_9418_long.cap_topic_new.isin([0,4])] ## Economics + Labour and Social Welfare\n",
        "cap_deu_9418_3000_long = cap_deu_9418_long[cap_deu_9418_long.cap_topic_new.isin([1,14])] # 2800+ to 3000+\n",
        "cap_deu_9418_u2500_long = cap_deu_9418_long[cap_deu_9418_long.cap_topic_new.isin([3,5,8,10,12,11,9,13,7,2,6,16,15])] # under 2500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYiWou7B2VXE"
      },
      "outputs": [],
      "source": [
        "cap_deu_9418_econsoc = cap_deu_9418_econsoc.groupby('cap_topic_new', as_index = False,group_keys=False).apply(lambda s: s.sample(5500,replace=True, random_state = 1234))\n",
        "cap_deu_9418_3000_long = cap_deu_9418_3000_long.groupby('cap_topic_new', as_index = False,group_keys=False).apply(lambda s: s.sample(2800,replace=True, random_state = 1234))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54_s_a4A2Ksw"
      },
      "outputs": [],
      "source": [
        "frames_long = [cap_deu_9418_econsoc, cap_deu_9418_3000_long, cap_deu_9418_u2500_long]\n",
        "df_long = pd.concat(frames_long)\n",
        "df_long.groupby('cap_topic_new').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMEMdlOy2mVh"
      },
      "outputs": [],
      "source": [
        "len(df_long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzTGttRT0IJg"
      },
      "outputs": [],
      "source": [
        "## export labels to a list\n",
        "labels = df_long['cap_topic_new'].tolist()\n",
        "set(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JMBN83e0IJh"
      },
      "outputs": [],
      "source": [
        "texts = df_long['sentence_text'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecZaIjXH0IJh"
      },
      "outputs": [],
      "source": [
        "min_length = min(len(sentence.split()) for sentence in texts)\n",
        "max_length = max(len(sentence.split()) for sentence in texts)\n",
        "\n",
        "print('Min length (word) is: {}'.format(min_length))\n",
        "print('Min length (word) is: {}'.format(max_length))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucPmoi3G6Ij7"
      },
      "outputs": [],
      "source": [
        "## train test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size = 0.25, random_state = 1234, stratify = labels)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.4, random_state=4321, stratify=train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j34WV-nu0IJh"
      },
      "outputs": [],
      "source": [
        "## Load tokenizer and models\n",
        "bert_version = 'deepset/gbert-base'\n",
        "model = BertForSequenceClassification.from_pretrained(bert_version, num_labels = 17)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(bert_version)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx6lVk3t0IJh"
      },
      "outputs": [],
      "source": [
        "## tokenize \n",
        "train_encodings = tokenizer.batch_encode_plus(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer.batch_encode_plus(val_texts, truncation=True,  padding=True)\n",
        "test_encodings = tokenizer.batch_encode_plus(test_texts, truncation=True,  padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ-YLuAY0IJh"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Dataset(train_encodings, train_labels)\n",
        "val_dataset = Dataset(val_encodings, val_labels)\n",
        "test_dataset = Dataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3dTjQwC0IJi"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, n = precision_recall_fscore_support(labels, preds, average=None)\n",
        "    cf = confusion_matrix(labels,preds)\n",
        "    cf_n = cf.astype('float') / cf.sum(axis=1)[:, np.newaxis]\n",
        "    acc=cf_n.diagonal() ## accuracy for each class\n",
        "    return {\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'n': n,\n",
        "        'cf': cf,\n",
        "        'acc': acc\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ow67tXN0IJi"
      },
      "outputs": [],
      "source": [
        "## Fine tuning \n",
        "training_args = TrainingArguments(  \n",
        "    # output directory\n",
        "    output_dir=os.path.join(\"Hung's paper\", \"results\", \"Deu9418_Long\"),\n",
        "    # total number of training epochs\n",
        "    num_train_epochs= 16,\n",
        "    # batch size per device during training\n",
        "    per_device_train_batch_size=16,\n",
        "    # batch size for evaluation\n",
        "    per_device_eval_batch_size=16,\n",
        "    # number of warmup steps for learning rate scheduler\n",
        "    warmup_steps=500,\n",
        "    weight_decay = 0.01,\n",
        "    # learning rate\n",
        "    learning_rate = 2e-5,  \n",
        "    # directory for storing logs\n",
        "    logging_dir=os.path.join(\"Hung's paper\", \"logs\", \"Deu9418_Long\"),            \n",
        "    logging_steps= 1000,    \n",
        "    load_best_model_at_end=True,\n",
        "    save_strategy = \"no\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywa4Y1Cf0IJi"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I232b__y0IJi"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RubfVodl0IJi"
      },
      "outputs": [],
      "source": [
        "eval_res = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK1PUWiy0IJi"
      },
      "outputs": [],
      "source": [
        "evaluated = pd.DataFrame()\n",
        "evaluated[\"f1\"] = eval_res[\"eval_f1\"]\n",
        "evaluated[\"precision\"] = eval_res[\"eval_precision\"]\n",
        "evaluated[\"recall\"] = eval_res[\"eval_recall\"]\n",
        "evaluated[\"n\"] = eval_res[\"eval_n\"]\n",
        "evaluated[\"accuracy\"] = eval_res[\"eval_acc\"]\n",
        "list_index = evaluated.index.tolist()\n",
        "evaluated['pred_topics'] = list_index\n",
        "evaluated['topic'] = lab_to_top(evaluated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jKa8_jO0IJi"
      },
      "outputs": [],
      "source": [
        "evaluated = evaluated.sort_values(by=\"f1\", ascending=False)\n",
        "evaluated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVTABXgjKJjF"
      },
      "outputs": [],
      "source": [
        "evaluated.to_csv(\"classification_res_trimmed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5lA6pJh9ePB"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(\"Hung's paper\", \"results\", \"trimmed\")\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9zI8ICNl5wg"
      },
      "source": [
        "# Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecn6vtllLsvP"
      },
      "outputs": [],
      "source": [
        "## Load pre-trained models\n",
        "model_path = os.path.join(\"Hung's paper\", \"results\", \"final\")\n",
        "model = BertForSequenceClassification.from_pretrained(model_path).to(device)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaPbOPPXNwX9"
      },
      "outputs": [],
      "source": [
        "germaparl = pd.read_csv(os.path.join(\"Hung's paper\", \"germaparl.csv\"), encoding='utf-8')\n",
        "germaparl = germaparl.dropna(subset=['text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S4ylAKLDchh"
      },
      "outputs": [],
      "source": [
        "germaparl.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwB988HEE70i"
      },
      "outputs": [],
      "source": [
        "pred_texts = germaparl['text'].tolist()\n",
        "len(pred_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEPsL7V_b5vz"
      },
      "outputs": [],
      "source": [
        "from statistics import stdev, mean\n",
        "## Before\n",
        "seq_len = [len(i.split()) for i in pred_texts]\n",
        "seq_len_mean = mean(seq_len)\n",
        "seq_len_std = stdev(seq_len)\n",
        "seq_len_max = max(seq_len)\n",
        "seq_len_min = min(seq_len)\n",
        "print('Mean length (word) is: {}'.format(seq_len_mean))\n",
        "print('Std length (word) is: {}'.format(seq_len_std))\n",
        "print('Min length (word) is: {}'.format(seq_len_min))\n",
        "print('Max length (word) is: {}'.format(seq_len_max))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGgNmuBmkYTQ"
      },
      "outputs": [],
      "source": [
        "pd.Series(seq_len).hist(bins = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP8oG3aiSJwZ"
      },
      "outputs": [],
      "source": [
        "## This piece of code takes a lot of RAM. If you can't access high-ram session, consider doing this in R or using iterrows instead (much slower).\n",
        "germaparl.loc[:, 'length'] = germaparl.text.str.split().str.len()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy-Qt8pUcVVN"
      },
      "outputs": [],
      "source": [
        "germaparl = germaparl[germaparl.length.between(10,256)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfnHYlmKEziW"
      },
      "outputs": [],
      "source": [
        "pred_texts = germaparl['text'].tolist()\n",
        "len(pred_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95nUFbgjeBaC"
      },
      "outputs": [],
      "source": [
        "germaparl.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9qWnTRwj6uZ"
      },
      "outputs": [],
      "source": [
        "## After\n",
        "seq_len = [len(i.split()) for i in pred_texts]\n",
        "seq_len_mean = mean(seq_len)\n",
        "seq_len_std = stdev(seq_len)\n",
        "seq_len_max = max(seq_len)\n",
        "seq_len_min = min(seq_len)\n",
        "print('Mean length (word) is: {}'.format(seq_len_mean))\n",
        "print('Std length (word) is: {}'.format(seq_len_std))\n",
        "print('Min length (word) is: {}'.format(seq_len_min))\n",
        "print('Max length (word) is: {}'.format(seq_len_max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFput7zdh5fL"
      },
      "outputs": [],
      "source": [
        "pd.Series(seq_len).hist(bins = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWtZ_5S0aphg"
      },
      "outputs": [],
      "source": [
        "def get_prediction(text):\n",
        "  res = []\n",
        "  with torch.no_grad():\n",
        "    for x in text:\n",
        "      inputs = tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "      # perform inference to our model\n",
        "      outputs = model(**inputs)\n",
        "      # get output probabilities by doing softmax\n",
        "      probs = outputs[0].softmax(1)\n",
        "      argmax = probs.argmax()\n",
        "      res.append(argmax)\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFFJkoOrQG6S"
      },
      "outputs": [],
      "source": [
        "text_test = pred_texts[0:10]\n",
        "res = get_prediction(text_test)\n",
        "print(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzR9ihAPQT7L"
      },
      "outputs": [],
      "source": [
        "pred_texts[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCGe_ka3RUQp"
      },
      "outputs": [],
      "source": [
        "def chunkIt(seq, num):\n",
        "    avg = len(seq) / float(num)\n",
        "    out = []\n",
        "    last = 0.0\n",
        "    while last < len(seq):\n",
        "        out.append(seq[int(last):int(last + avg)])\n",
        "        last += avg\n",
        "\n",
        "    return out\n",
        "pred_texts_chunk = chunkIt(pred_texts, 1000)\n",
        "len(pred_texts_chunk[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V44BQ5ZgxDJZ"
      },
      "outputs": [],
      "source": [
        "len(pred_texts_chunk[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhc8efGrfIoX"
      },
      "outputs": [],
      "source": [
        "def iter_pred(obj, pre, post):\n",
        "  preds_final = []\n",
        "  for i in range(pre,post):\n",
        "    if i % 10 == 0:\n",
        "      print(f'Starting the {i+1}th chunk.')\n",
        "    pred = get_prediction(obj[i])\n",
        "    preds_final.append(pred)\n",
        "  return preds_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuA2NifJXIDT"
      },
      "outputs": [],
      "source": [
        "def concat(obj):\n",
        "    pred_topics_con = []\n",
        "    pred_topics_final = []\n",
        "    for i in obj:\n",
        "        pred_topics_con += i\n",
        "    for i in pred_topics_con:\n",
        "        pred_topics_final.append(float(i))\n",
        "    return pred_topics_final\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sua3hYroNr2"
      },
      "outputs": [],
      "source": [
        "def lab_to_top(df):\n",
        "  topic = []\n",
        "  for value in df['pred_topics']:\n",
        "    if value == 0:\n",
        "      topic.append(\"Economics\")\n",
        "    elif value == 1:\n",
        "      topic.append(\"Civil Rights\")\n",
        "    elif value == 2:\n",
        "      topic.append(\"Health\")\n",
        "    elif value == 3:\n",
        "      topic.append(\"Agriculture\")\n",
        "    elif value == 4:\n",
        "      topic.append(\"Labor and Social Welfare\")\n",
        "    elif value == 5:\n",
        "      topic.append(\"Education\")\n",
        "    elif value == 6:\n",
        "      topic.append(\"Environment\")\n",
        "    elif value == 7:\n",
        "      topic.append(\"Energy\")\n",
        "    elif value == 8:\n",
        "      topic.append(\"Immigration\")\n",
        "    elif value == 9:\n",
        "      topic.append(\"Transportation\")\n",
        "    elif value == 10:\n",
        "      topic.append(\"Law and Crime\")\n",
        "    elif value == 11:\n",
        "      topic.append(\"Housing\")\n",
        "    elif value == 12:\n",
        "      topic.append(\"Defense\")\n",
        "    elif value == 13:\n",
        "      topic.append(\"Technology\")\n",
        "    elif value == 14:\n",
        "      topic.append(\"International Affairs\")\n",
        "    elif value == 15:\n",
        "      topic.append(\"Government Operations\")\n",
        "    else:\n",
        "      topic.append(\"Other\")\n",
        "  return(topic)\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO6cF_e56VQO"
      },
      "outputs": [],
      "source": [
        "pred_topics_1 = iter_pred(pred_texts_chunk, 0, 500)\n",
        "pred_topics_concat_1 = concat(pred_topics_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OBO8nJQ6bPr"
      },
      "outputs": [],
      "source": [
        "len(pred_topics_concat_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqAWDEIk6frK"
      },
      "outputs": [],
      "source": [
        "germaparl_1 = germaparl[:len(pred_topics_concat_1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvTDa3CL-vJW"
      },
      "outputs": [],
      "source": [
        "germaparl_1['pred_topics'] = pred_topics_concat_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwOo9-vrlfnP"
      },
      "outputs": [],
      "source": [
        "germaparl_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UmIIazy-xca"
      },
      "outputs": [],
      "source": [
        "germaparl_1['topic_name'] = lab_to_top(germaparl_1)\n",
        "germaparl_1.groupby('topic_name').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYJTp3hg-2kq"
      },
      "outputs": [],
      "source": [
        "germaparl_1.to_csv('germaparl_pred_1.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bN7cILZq-uw"
      },
      "outputs": [],
      "source": [
        "pred_topics_2 = iter_pred(pred_texts_chunk, 500, 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9jf8J44KP5F"
      },
      "outputs": [],
      "source": [
        "pred_topics_concat_2 = concat(pred_topics_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mELzYsv6C163"
      },
      "outputs": [],
      "source": [
        "len(germaparl)-len(pred_topics_concat_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHxzhjveC9IX"
      },
      "outputs": [],
      "source": [
        "len(pred_topics_concat_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Axyc3RFFYK"
      },
      "outputs": [],
      "source": [
        "germaparl_2 = germaparl[len(germaparl)-len(pred_topics_concat_2):]\n",
        "germaparl_2['pred_topics'] = pred_topics_concat_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TvR7KohFaNB"
      },
      "outputs": [],
      "source": [
        "germaparl_2['topic_name'] = lab_to_top(germaparl_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsL_-ia6sqWf"
      },
      "outputs": [],
      "source": [
        "germaparl_2.to_csv('germaparl_pred_2.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiH-tomLp1nD"
      },
      "outputs": [],
      "source": [
        "germaparl_1 = pd.read_csv(\"germaparl_pred_1.csv\", encoding = \"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBB9Eu2UqIDM"
      },
      "outputs": [],
      "source": [
        "germaparl_2 = pd.read_csv(\"germaparl_pred_2.csv\", encoding = \"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-YxWR_5t11S"
      },
      "outputs": [],
      "source": [
        "frames = [germaparl_1, germaparl_2]\n",
        "final_df = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOWhlke3qxJj"
      },
      "outputs": [],
      "source": [
        "print(len(germaparl_1))\n",
        "print(len(germaparl_2))\n",
        "print(len(germaparl_1)+len(germaparl_2))\n",
        "print(len(germaparl)-len(pred_topics_concat_2))\n",
        "print(len(final_df))\n",
        "print(len(germaparl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLePMJ9IuCxm"
      },
      "outputs": [],
      "source": [
        "final_df.groupby('topic_name').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgkvC3uTFksX"
      },
      "outputs": [],
      "source": [
        "final_df = final_df[[\"speaker\", \"role\", \"party\", \"position\", \"session\", \"date\",\"bundestag\", \"year\" ,\"pred_topics\", \"topic_name\", \"length\",\"text\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jHceAU_uPv9"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv('germaparl_pred.csv', encoding='utf-8')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 ('bargaining_space')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "8fcbfdfefafdf96e842e6c667a4c66c318e5bdd52f6fec22d679768d8e4eb444"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
