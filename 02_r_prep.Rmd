---
title: "02_r_prep"
output: html_document
date: "2023-09-29"
---

## Load packages
```{r setup, include=FALSE}
rm(list=ls())
pacman::p_load(quanteda, quanteda.textmodels, tidyverse, readr, ggplot2, rstatix, grid, gridExtra, viridis, ggsci, ggpubr, ragg, scales, openxlsx, countrycode)

pulled_manifestoes <- read_csv("data/r_outputs/pulled_manifestoes.csv")
ches <- read_csv("data/ches/1999-2019_CHES_dataset_meansv3.csv")

```
## CHES - Process data


```{r ches}
ches_deu <- ches %>%
    filter(country == 3 & party_id %in% c("301","302","303","304","306","308","310")) %>%
    mutate(
        party = case_when(
            party_id %in% c("301","308") ~ "CDU/CSU",
            party_id == "302" ~ "SPD",
            party_id == "303" ~ "FDP",
            party_id == "304" ~ "Alliance 90/Greens",
            party_id == "306" ~ "The Left",
            party_id == "310" ~ "AfD"
        ),
        election = case_when(
            year == 2014  ~ 2013,
            year == 2019 ~ 2017,
            year == 1999 ~ 1998,
            year == 2006 ~ 2005,
            year == 2002 ~ 2002,
            year == 2010 ~ 2009
        )
    ) %>%
    group_by(party, election) %>%
    summarise(
        ches_lr = mean(lrgen, na.rm=TRUE),
        ches_regions = mean(regions, na.rm=TRUE),
        ches_econ = mean(lrecon, na.rm=TRUE),
        ches_env = mean(environment, na.rm=TRUE),
        ches_eu = mean(eu_position, na.rm=TRUE),
        ches_immgr = mean(immigrate_policy, na.rm=TRUE),
        ches_wf = mean(redistribution, na.rm = TRUE)
    ) %>%
    ungroup() 


write.csv(ches_deu, "data/r_outputs/ches_deu.csv", row.names=FALSE)
```

## Wordfish - Gen


```{r wf_gen}


manifesto_deu <- pulled_manifestoes %>%
    filter(countryname == "Germany") %>%
    mutate(
        code_extract = substr(code, 1,3)
    ) %>%
    filter(!code %in% c("H"))


grouped_texts <- manifesto_deu %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )


dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 50, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta

write.csv(results, "data/r_outputs/wf_gen.csv", row.names=FALSE)


```

## Wordfish - Environment

```{r wf_env}

manifesto_env = manifesto_deu[which(manifesto_deu$code_extract %in% c(410,416,501)),]
grouped_texts <- manifesto_env %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )
dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 10, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta

write.csv(results, "data/r_outputs/wf_env.csv", row.names = FALSE)


```



## Wordfish - Economy

```{r wf_econ}

manifesto_econ = manifesto_deu[which(manifesto_deu$code_extract %in%
                                       c(401,402,403,404,409,412,413,414)),]
grouped_texts <- manifesto_econ %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )
dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 10, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta


write.csv(results, "data/r_outputs/wf_econ.csv", row.names=FALSE)

```

## Wordfish - Welfare

```{r wf_socwel}

manifesto_socwel = manifesto_deu[which(manifesto_deu$code_extract %in% c(503,504,505,701,702)),]
grouped_texts <- manifesto_socwel %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )
dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 10, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta


write.csv(results, "data/r_outputs/wf_socwel.csv", row.names=FALSE)

```

## Wordfish - EU Integration


```{r wf_eu}

manifesto_eu = manifesto_deu[which(manifesto_deu$code_extract %in% c(108,110)),]
grouped_texts <- manifesto_eu %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )
dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 10, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta


write.csv(results, "data/r_outputs/wf_eu.csv", row.names = FALSE)

```

## Wordfish - Immigration


```{r wf_imm}

manifesto_imm = manifesto_deu[which(manifesto_deu$code_extract %in% c(601,602,607,608)),]
grouped_texts <- manifesto_imm %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )
dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 10, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta


write.csv(results, "data/r_outputs/wf_imm.csv", row.names = FALSE)

```

## Wordfish - Environment Protection 


```{r wf_ep}

manifesto_ep = manifesto_deu[which(manifesto_deu$code_extract ==501),]
grouped_texts <- manifesto_ep %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )
dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 10, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta


write.csv(results, "data/r_outputs/wf_ep.csv", row.names = FALSE)

```
## Wordfish - Growth vs. Anti Growth


```{r wf_growth}

manifesto_growth = manifesto_deu[which(manifesto_deu$code_extract %in% c(410,416)),]
grouped_texts <- manifesto_growth %>% 
    mutate(
        party_election = paste(party, election, sep="_"),
        party = case_when(
            grepl("Linke|Sozialismus", name) ~ "The Left",
            grepl("Sozialdemokratische", name) ~ "SPD",
            grepl("Christlich", name) ~ "CDU/CSU",
            grepl("Freie", name) ~ "FDP",
            grepl("Grünen", name) ~ "Alliance 90/Greens",
            grepl("Alternative", name) ~ "AfD",
            TRUE ~ NA_character_
        )
    ) %>%
    filter(!is.na(party)) %>%
    group_by(party, election) %>%
    summarise(
        text_new = paste(text, collapse = " "),
        num_speeches = n()
    )
dfmat <- corpus(grouped_texts, text_field = "text_new") %>%
             tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
             tokens_remove(stopwords("de")) %>%
             dfm() %>%
             dfm_trim(min_termfreq = 10, verbose = TRUE, min_docfreq = 0.03, docfreq_type = "prop") %>%
             dfm_subset(ntoken(.) > 0, drop_docid = TRUE)

wf_mod <- quanteda.textmodels::textmodel_wordfish(dfmat, dispersion = "poisson", 
                                 sparse = TRUE)
results <- grouped_texts %>% select(-text_new)

results$wf_score <- wf_mod$theta
results$wf_se <- wf_mod$se.theta


write.csv(results, "data/r_outputs/wf_growth.csv", row.names = FALSE)

```

## Prepping data for COALITIONAGREE

```{r coalitionagree}

folder = "data/coalitionagree/Coalition Agreements_coded"
folder_list = list.dirs(path = folder)

all_files <- lapply(folder_list, list.files, pattern=".xlsx")
coalitionagree <- data.frame()

for (i in seq_along(all_files)){
    if (length(all_files[[i]]) >1){
        for (j in seq_along(all_files[[i]])){
            if (!is.na(all_files[[i]][j])){
                xlsx <- read.xlsx(paste(folder_list[i], all_files[[i]][j],
                                    sep="/"))
                xlsx$country_init <- rep(stringi::stri_split_regex(all_files[[i]][j],
                                                   pattern="_")[[1]][1],
                                   nrow(xlsx))
                xlsx$cabinet_year = rep(stringi::stri_split_regex(all_files[[i]][j],
                                                   pattern="_")[[1]][2],
                                   nrow(xlsx))
                coalitionagree <- bind_rows(coalitionagree, xlsx)
            }
            
        }
    }
}

coalitionagree <- coalitionagree %>%
    mutate(
        country = countrycode(country_init, origin="iso2c", destination="country.name")
    ) %>%
    filter(country %in% pulled_manifestoes$countryname)

write.csv(coalitionagree, "data/r_outputs/coalitionagree_texts.csv")
```



