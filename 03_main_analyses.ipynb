{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4k3dCezyXmXQ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dPi54JU9XmXR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, BertModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from utils.functions import group_texts, sentiment_code, topic_code,party_deu, clean_text_loop, sentiment_code_coalition, topic_code_coalition\n",
    "from utils.functions import train_loop, eval_loop, tokenize_function, d2v_reduct, scale_func, recode_tw, copy_weights\n",
    "# Import the new uncertainty module\n",
    "from utils.uncertainty import (\n",
    "    ensemble_inference,\n",
    "    train_deep_ensemble,\n",
    "    load_ensemble_models,\n",
    "    save_ensemble_results,\n",
    "    create_ensemble_summary_dataframe\n",
    ")\n",
    "from utils.models import ContextScalePrediction, corpusIterator, phraseIterator\n",
    "from safetensors.torch import load_file, save_file\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import nltk\n",
    "#nltk.download('stopwords') ## Remove comments and do it once if you haven't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mDclkfIWZcwv",
    "outputId": "769a0b89-1e46-4b79-c424-cb6022cd4971"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX PRO 6000 Blackwell Workstation Edition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "device = torch.device('cuda')\n",
    "torch.cuda.get_device_name(device=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULX0gK7mg6d3",
    "outputId": "bdbd3c77-e5c0-46f3-cb41-c78bdbbbd4ab"
   },
   "outputs": [],
   "source": [
    "## Pseudo-randomness for reproducibility\n",
    "seed_val = 1234\n",
    "torch.manual_seed(seed_val)\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small test of BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = 'I went to the river bank'\n",
    "sentence_b = 'I went to the bank by the river'\n",
    "tok_a = tokenizer(sentence_a, return_tensors='pt')\n",
    "tok_b = tokenizer(sentence_b, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs_a = model(**tok_a)\n",
    "    outputs_b = model(**tok_b)\n",
    "# Extract word embeddings from the last hidden layer\n",
    "last_hidden_states_a = outputs_a.last_hidden_state\n",
    "last_hidden_states_b = outputs_b.last_hidden_state\n",
    "\n",
    "# Extract the word embedding for the first token (CLS token)\n",
    "word_embedding_a = last_hidden_states_a[:, -2, :] ## 0 is the CLS token, river is the last token\n",
    "word_embedding_b = last_hidden_states_b[:, 5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(word_embedding_a.numpy(), word_embedding_b.numpy()).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "b41aechYXmXT"
   },
   "source": [
    "# Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qB4dt7BNuojT"
   },
   "outputs": [],
   "source": [
    "manifesto = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes.csv\"), encoding=\"utf-8\", dtype = {2: 'str', 18:'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto = manifesto[(manifesto.cmp_code.notna()) & ~(manifesto.cmp_code.isin(['H']))].reset_index(drop=True)\n",
    "len(manifesto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto['sentiment'] = manifesto['cmp_code'].apply(sentiment_code)\n",
    "manifesto['topic'] = manifesto['cmp_code'].apply(topic_code)\n",
    "manifesto['election'] = manifesto['date'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_result = manifesto.groupby(['topic', 'sentiment', 'cmp_code']).size().reset_index(name='count')\n",
    "grouped_result.to_csv('data/temps/categorization_table.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto[manifesto.topic==\"Military\"])/len(manifesto)*100 ## minority group: 1.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = manifesto['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev, mean\n",
    "## Before\n",
    "seq_len = [len(i.split()) for i in texts]\n",
    "seq_len_mean = mean(seq_len)\n",
    "seq_len_std = stdev(seq_len)\n",
    "seq_len_max = max(seq_len)\n",
    "seq_len_min = min(seq_len)\n",
    "print('Mean length (word) is: {}'.format(seq_len_mean))\n",
    "print('Std length (word) is: {}'.format(seq_len_std))\n",
    "print('Min length (word) is: {}'.format(seq_len_min))\n",
    "print('Max length (word) is: {}'.format(seq_len_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(manifesto, \n",
    "                      ['countryname','election','party','cmp_code'], 'text', \n",
    "                      max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped = pd.DataFrame(results)\n",
    "manifesto_regrouped = manifesto_regrouped.explode('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = manifesto_regrouped['labels'].str.split(';', expand=True)\n",
    "manifesto_regrouped = pd.concat([manifesto_regrouped, df_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.columns = ['text', 'idx', 'country','election', 'party', 'cmp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'sentiment'] = manifesto_regrouped['cmp_code'].apply(sentiment_code)\n",
    "manifesto_regrouped.loc[:,'topic'] = manifesto_regrouped['cmp_code'].apply(topic_code)\n",
    "manifesto_regrouped = manifesto_regrouped.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = manifesto_regrouped['text'].tolist()\n",
    "from statistics import stdev, mean\n",
    "## Before\n",
    "seq_len = [len(i.split()) for i in texts]\n",
    "seq_len_mean = mean(seq_len)\n",
    "seq_len_std = stdev(seq_len)\n",
    "seq_len_max = max(seq_len)\n",
    "seq_len_min = min(seq_len)\n",
    "print('Mean length (word) is: {}'.format(seq_len_mean))\n",
    "print('Std length (word) is: {}'.format(seq_len_std))\n",
    "print('Min length (word) is: {}'.format(seq_len_min))\n",
    "print('Max length (word) is: {}'.format(seq_len_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.to_csv('data/temps/manifesto_regrouped.csv', encoding='utf-8', index=False)\n",
    "manifesto.to_csv('data/temps/manifesto.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto = pd.read_csv('data/temps/manifesto.csv', encoding='utf-8', dtype={2:'str',18: 'str'})\n",
    "manifesto_regrouped = pd.read_csv('data/temps/manifesto_regrouped.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced = manifesto_regrouped[['topic','sentiment','text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base' \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced['topic_sentiment'] = manifesto_reduced['topic'] + '_' + manifesto_reduced['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a2c03149a04178a001f10fb74db830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/337412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e09d139a3e4cd38e590dcc4a8b7466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/337412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2223240c08425583c0c1a9782be637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/337412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_reduced)\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic_sentiment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save class labels\n",
    "import pickle\n",
    "topic_labels = manifesto_dataset.features['topic'].names\n",
    "file_path = 'data/temps/topic_labels'\n",
    "with open(file_path, 'wb') as fp:\n",
    "    pickle.dump(topic_labels, fp)\n",
    "\n",
    "sentiment_labels = manifesto_dataset.features['sentiment'].names\n",
    "file_path = 'data/temps/sentiment_labels'\n",
    "with open(file_path, 'wb') as fp:\n",
    "    pickle.dump(sentiment_labels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = manifesto_dataset.train_test_split(test_size=0.1, stratify_by_column='topic_sentiment', seed=seed_val)\n",
    "train_eval = train_test['train'].train_test_split(test_size=0.3, stratify_by_column='topic_sentiment', seed=seed_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 212569\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 33742\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 91101\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_datasets = DatasetDict({\n",
    "    'train': train_eval['train'],\n",
    "    'test': train_test['test'],\n",
    "    'eval': train_eval['test']\n",
    "})\n",
    "manifesto_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bce694a64d43509cb6fa1848f27ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/212569 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664f531fc453483b866d3025d0de28e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe6363f75a14990ab092c1fc7299a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['topic', 'sentiment', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = manifesto_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text', 'topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16, shuffle=False, collate_fn = data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_datasets['eval'], batch_size=16, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Ensemble Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model factory function for ensemble training\n",
    "num_topics = len(set(manifesto_dataset['topic']))\n",
    "num_sentiments = len(set(manifesto_dataset['sentiment']))\n",
    "model_base = ContextScalePrediction(\n",
    "        roberta_model=model_name, \n",
    "        num_topics=num_topics, \n",
    "        num_sentiments=num_sentiments,\n",
    "        lora=False,\n",
    "        use_shared_attention=True  # Using shared attention architecture\n",
    "    )\n",
    "\n",
    "print(\"Model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble inference on the test set\n",
    "\n",
    "Training is done using train.py script. Here we implement ensemble inference on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate checkpoint paths for the ensemble models trained with different splits\n",
    "checkpoint_paths_splits = [\n",
    "    os.path.join('results/models/ensemble', f\"model_ensemble_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "print(\"Checkpoint paths for split-based ensemble:\")\n",
    "for i, path in enumerate(checkpoint_paths_splits):\n",
    "    print(f\"  Model {i}: {path}\")\n",
    "\n",
    "# Load the ensemble models\n",
    "ensemble_models = load_ensemble_models(\n",
    "    model_base=model_base,\n",
    "    checkpoint_paths=checkpoint_paths_splits,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ensemble inference with uncertainty estimation\n",
    "print(\"Performing ensemble inference with uncertainty estimation...\")\n",
    "print(\"The ensemble will compute:\")\n",
    "print(\"  - Mean position scores across all 5 models\")\n",
    "print(\"  - Position score variance for each text sequence\")\n",
    "print(\"  - Epistemic uncertainty (model disagreement)\")\n",
    "print(\"  - Aleatoric uncertainty (inherent data uncertainty)\")\n",
    "\n",
    "ensemble_results = ensemble_inference(\n",
    "    models=ensemble_models,\n",
    "    dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=True\n",
    ")\n",
    "\n",
    "print(f\"\\nEnsemble inference completed!\")\n",
    "print(f\"Final position scores are the mean of {len(ensemble_models)} models\")\n",
    "print(f\"Position score variance included for each sequence\")\n",
    "\n",
    "save_ensemble_results(\n",
    "    ensemble_results,\n",
    "    'results/datasets/ensemble_results_test.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge back to original test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load ensemble results with pickle\n",
    "file_path = 'results/datasets/ensemble_results_test.pkl'\n",
    "with open(file_path, \"rb\") as file:\n",
    "    ensemble_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_summary_df = create_ensemble_summary_dataframe(ensemble_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge ensemble_summary_df with original test dataset for analysis\n",
    "test_dataset = manifesto_datasets['test'].to_pandas().reset_index(drop=True)\n",
    "merged_df = pd.concat([test_dataset, ensemble_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to csv\n",
    "merged_df.to_csv('results/datasets/ensemble_test_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on the entire dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate checkpoint paths for the ensemble models trained with different splits\n",
    "checkpoint_paths_splits = [\n",
    "    os.path.join('results/models/ensemble_scaling', f\"model_ensemble_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "print(\"Checkpoint paths for split-based ensemble:\")\n",
    "for i, path in enumerate(checkpoint_paths_splits):\n",
    "    print(f\"  Model {i}: {path}\")\n",
    "\n",
    "# Load the ensemble models\n",
    "ensemble_models = load_ensemble_models(\n",
    "    model_base=model_base,\n",
    "    checkpoint_paths=checkpoint_paths_splits,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = manifesto_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])\n",
    "full_dataset.set_format(\"torch\")\n",
    "full_dataloader = DataLoader(full_dataset, batch_size=64, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "full_ensemble_results = ensemble_inference(\n",
    "    models=ensemble_models,\n",
    "    dataloader=full_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=True\n",
    ")\n",
    "\n",
    "save_ensemble_results(\n",
    "    full_ensemble_results,\n",
    "    'results/datasets/ensemble_results_full.pkl'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load ensemble results with pickle\n",
    "file_path = 'data/py_outputs/ensemble_results_full.pkl'\n",
    "with open(file_path, \"rb\") as file:\n",
    "    full_ensemble_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_summary_df = create_ensemble_summary_dataframe(full_ensemble_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge ensemble_summary_df with original test dataset for analysis\n",
    "merged_df = pd.concat([manifesto_regrouped, ensemble_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to csv\n",
    "merged_df.to_csv('results/datasets/ensemble_full_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation: Model architecture comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_base/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_base'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_base, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_sentiment'].to_csv('results/classification results/base_sentiment.csv', index=False)\n",
    "outputs_base['res_table_topic'].to_csv('results/classification results/base_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with simple flow of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_simple_flow=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_sf/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_sf'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_sf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_sentiment'].to_csv('results/classification results/sf_sentiment.csv', index=False)\n",
    "outputs_sf['res_table_topic'].to_csv('results/classification results/sf_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with shared attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_shared_attention=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_sa/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_sa'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_sa, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_sentiment'].to_csv('results/classification results/sa_sentiment.csv', index=False)\n",
    "outputs_sa['res_table_topic'].to_csv('results/classification results/sa_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with dynamic gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_dynamic_gating=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_dg/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_dg'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_dg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_sentiment'].to_csv('results/classification results/dg_sentiment.csv', index=False)\n",
    "outputs_dg['res_table_topic'].to_csv('results/classification results/dg_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on test languages unseen during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_test = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes_test.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cmp_code</th>\n",
       "      <th>eu_code</th>\n",
       "      <th>pos</th>\n",
       "      <th>manifesto_id</th>\n",
       "      <th>party</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>translation_en</th>\n",
       "      <th>country</th>\n",
       "      <th>party_code</th>\n",
       "      <th>countryname</th>\n",
       "      <th>abbrev</th>\n",
       "      <th>name</th>\n",
       "      <th>edate</th>\n",
       "      <th>parfam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>安倍政権の暴走ストップ！</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>71220_201412</td>\n",
       "      <td>71220</td>\n",
       "      <td>201412</td>\n",
       "      <td>japanese</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>71220</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JCP</td>\n",
       "      <td>Nihon Kyōsan-tō</td>\n",
       "      <td>14/12/2014</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>国民の声が生きる新しい政治を</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>71220_201412</td>\n",
       "      <td>71220</td>\n",
       "      <td>201412</td>\n",
       "      <td>japanese</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>71220</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JCP</td>\n",
       "      <td>Nihon Kyōsan-tō</td>\n",
       "      <td>14/12/2014</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本共産党の総選挙政策</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>71220_201412</td>\n",
       "      <td>71220</td>\n",
       "      <td>201412</td>\n",
       "      <td>japanese</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>71220</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JCP</td>\n",
       "      <td>Nihon Kyōsan-tō</td>\n",
       "      <td>14/12/2014</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>日本共産党</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>71220_201412</td>\n",
       "      <td>71220</td>\n",
       "      <td>201412</td>\n",
       "      <td>japanese</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>71220</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JCP</td>\n",
       "      <td>Nihon Kyōsan-tō</td>\n",
       "      <td>14/12/2014</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>安倍政権の暴走ストップ、政治を変えるチャンスです……</td>\n",
       "      <td>305.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>71220_201412</td>\n",
       "      <td>71220</td>\n",
       "      <td>201412</td>\n",
       "      <td>japanese</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>71220</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JCP</td>\n",
       "      <td>Nihon Kyōsan-tō</td>\n",
       "      <td>14/12/2014</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text cmp_code  eu_code  pos  manifesto_id  party  \\\n",
       "0                安倍政権の暴走ストップ！        H      NaN    1  71220_201412  71220   \n",
       "1              国民の声が生きる新しい政治を        H      NaN    2  71220_201412  71220   \n",
       "2                 日本共産党の総選挙政策        H      NaN    3  71220_201412  71220   \n",
       "3                       日本共産党        H      NaN    4  71220_201412  71220   \n",
       "4  安倍政権の暴走ストップ、政治を変えるチャンスです……    305.1      NaN    5  71220_201412  71220   \n",
       "\n",
       "     date  language  annotations  translation_en  country  party_code  \\\n",
       "0  201412  japanese         True           False       71       71220   \n",
       "1  201412  japanese         True           False       71       71220   \n",
       "2  201412  japanese         True           False       71       71220   \n",
       "3  201412  japanese         True           False       71       71220   \n",
       "4  201412  japanese         True           False       71       71220   \n",
       "\n",
       "  countryname abbrev             name       edate  parfam  \n",
       "0       Japan    JCP  Nihon Kyōsan-tō  14/12/2014    20.0  \n",
       "1       Japan    JCP  Nihon Kyōsan-tō  14/12/2014    20.0  \n",
       "2       Japan    JCP  Nihon Kyōsan-tō  14/12/2014    20.0  \n",
       "3       Japan    JCP  Nihon Kyōsan-tō  14/12/2014    20.0  \n",
       "4       Japan    JCP  Nihon Kyōsan-tō  14/12/2014    20.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_test = manifesto_test[(manifesto_test.cmp_code.notna()) & ~(manifesto_test.cmp_code == 'H')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_test['sentiment'] = manifesto_test['cmp_code'].apply(sentiment_code)\n",
    "manifesto_test['topic'] = manifesto_test['cmp_code'].apply(topic_code)\n",
    "manifesto_test['election'] = manifesto_test['date'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(manifesto_test, \n",
    "                      ['countryname','election','party','cmp_code'], 'text', \n",
    "                      max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped = pd.DataFrame(results)\n",
    "manifesto_regrouped = manifesto_regrouped.explode('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = manifesto_regrouped['labels'].str.split(';', expand=True)\n",
    "manifesto_regrouped = pd.concat([manifesto_regrouped, df_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.columns = ['text', 'country_election_party_code', 'country','election', 'party', 'cmp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>country_election_party_code</th>\n",
       "      <th>country</th>\n",
       "      <th>election</th>\n",
       "      <th>party</th>\n",
       "      <th>cmp_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Za základ považujeme povinnou školní docházku....</td>\n",
       "      <td>Czech Republic;2002;82320;000</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2002</td>\n",
       "      <td>82320</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proto chceme modernizovat armádu - Profesional...</td>\n",
       "      <td>Czech Republic;2002;82320;104</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2002</td>\n",
       "      <td>82320</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chceme prosadit zrušení základní vojenské služ...</td>\n",
       "      <td>Czech Republic;2002;82320;105</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2002</td>\n",
       "      <td>82320</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Prosazujeme vstup do EU tak, aby se ČR stala...</td>\n",
       "      <td>Czech Republic;2002;82320;108</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2002</td>\n",
       "      <td>82320</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Těm, kdo chtějí zkusit štěstí v zahraničí, o...</td>\n",
       "      <td>Czech Republic;2002;82320;108</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2002</td>\n",
       "      <td>82320</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Za základ považujeme povinnou školní docházku....   \n",
       "1  Proto chceme modernizovat armádu - Profesional...   \n",
       "2  Chceme prosadit zrušení základní vojenské služ...   \n",
       "3  - Prosazujeme vstup do EU tak, aby se ČR stala...   \n",
       "4  - Těm, kdo chtějí zkusit štěstí v zahraničí, o...   \n",
       "\n",
       "     country_election_party_code         country election  party cmp_code  \n",
       "0  Czech Republic;2002;82320;000  Czech Republic     2002  82320      000  \n",
       "1  Czech Republic;2002;82320;104  Czech Republic     2002  82320      104  \n",
       "2  Czech Republic;2002;82320;105  Czech Republic     2002  82320      105  \n",
       "3  Czech Republic;2002;82320;108  Czech Republic     2002  82320      108  \n",
       "4  Czech Republic;2002;82320;108  Czech Republic     2002  82320      108  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'sentiment'] = manifesto_regrouped['cmp_code'].apply(sentiment_code)\n",
    "manifesto_regrouped.loc[:,'topic'] = manifesto_regrouped['cmp_code'].apply(topic_code)\n",
    "manifesto_regrouped = manifesto_regrouped.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>country_election_party_code</th>\n",
       "      <th>country</th>\n",
       "      <th>election</th>\n",
       "      <th>party</th>\n",
       "      <th>cmp_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Agriculture - Protectionism</th>\n",
       "      <th>left</th>\n",
       "      <td>1341</td>\n",
       "      <td>1341</td>\n",
       "      <td>1341</td>\n",
       "      <td>1341</td>\n",
       "      <td>1341</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Economics</th>\n",
       "      <th>left</th>\n",
       "      <td>2070</td>\n",
       "      <td>2070</td>\n",
       "      <td>2070</td>\n",
       "      <td>2070</td>\n",
       "      <td>2070</td>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3703</td>\n",
       "      <td>3703</td>\n",
       "      <td>3703</td>\n",
       "      <td>3703</td>\n",
       "      <td>3703</td>\n",
       "      <td>3703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>2421</td>\n",
       "      <td>2421</td>\n",
       "      <td>2421</td>\n",
       "      <td>2421</td>\n",
       "      <td>2421</td>\n",
       "      <td>2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Education</th>\n",
       "      <th>left</th>\n",
       "      <td>1534</td>\n",
       "      <td>1534</td>\n",
       "      <td>1534</td>\n",
       "      <td>1534</td>\n",
       "      <td>1534</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Environment - Growth</th>\n",
       "      <th>left</th>\n",
       "      <td>1241</td>\n",
       "      <td>1241</td>\n",
       "      <td>1241</td>\n",
       "      <td>1241</td>\n",
       "      <td>1241</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">European Integration</th>\n",
       "      <th>left</th>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Fabrics of Society</th>\n",
       "      <th>left</th>\n",
       "      <td>1016</td>\n",
       "      <td>1016</td>\n",
       "      <td>1016</td>\n",
       "      <td>1016</td>\n",
       "      <td>1016</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1808</td>\n",
       "      <td>1808</td>\n",
       "      <td>1808</td>\n",
       "      <td>1808</td>\n",
       "      <td>1808</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Immigration</th>\n",
       "      <th>left</th>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">International Relations</th>\n",
       "      <th>left</th>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Labour and Social Welfare</th>\n",
       "      <th>left</th>\n",
       "      <td>4303</td>\n",
       "      <td>4303</td>\n",
       "      <td>4303</td>\n",
       "      <td>4303</td>\n",
       "      <td>4303</td>\n",
       "      <td>4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Military</th>\n",
       "      <th>left</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <th>neutral</th>\n",
       "      <td>4541</td>\n",
       "      <td>4541</td>\n",
       "      <td>4541</td>\n",
       "      <td>4541</td>\n",
       "      <td>4541</td>\n",
       "      <td>4541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Political System</th>\n",
       "      <th>left</th>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1639</td>\n",
       "      <td>1639</td>\n",
       "      <td>1639</td>\n",
       "      <td>1639</td>\n",
       "      <td>1639</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  country_election_party_code  \\\n",
       "topic                       sentiment                                      \n",
       "Agriculture - Protectionism left       1341                         1341   \n",
       "                            right       123                          123   \n",
       "Economics                   left       2070                         2070   \n",
       "                            neutral    3703                         3703   \n",
       "                            right      2421                         2421   \n",
       "Education                   left       1534                         1534   \n",
       "                            right         4                            4   \n",
       "Environment - Growth        left       1241                         1241   \n",
       "                            neutral     155                          155   \n",
       "                            right      1292                         1292   \n",
       "European Integration        left        252                          252   \n",
       "                            right        72                           72   \n",
       "Fabrics of Society          left       1016                         1016   \n",
       "                            neutral     606                          606   \n",
       "                            right      1808                         1808   \n",
       "Immigration                 left        210                          210   \n",
       "                            right       790                          790   \n",
       "International Relations     left        985                          985   \n",
       "                            neutral     334                          334   \n",
       "                            right        74                           74   \n",
       "Labour and Social Welfare   left       4303                         4303   \n",
       "                            neutral      97                           97   \n",
       "                            right       135                          135   \n",
       "Military                    left        159                          159   \n",
       "                            right       585                          585   \n",
       "Other                       neutral    4541                         4541   \n",
       "Political System            left         93                           93   \n",
       "                            neutral    1639                         1639   \n",
       "                            right       760                          760   \n",
       "\n",
       "                                       country  election  party  cmp_code  \n",
       "topic                       sentiment                                      \n",
       "Agriculture - Protectionism left          1341      1341   1341      1341  \n",
       "                            right          123       123    123       123  \n",
       "Economics                   left          2070      2070   2070      2070  \n",
       "                            neutral       3703      3703   3703      3703  \n",
       "                            right         2421      2421   2421      2421  \n",
       "Education                   left          1534      1534   1534      1534  \n",
       "                            right            4         4      4         4  \n",
       "Environment - Growth        left          1241      1241   1241      1241  \n",
       "                            neutral        155       155    155       155  \n",
       "                            right         1292      1292   1292      1292  \n",
       "European Integration        left           252       252    252       252  \n",
       "                            right           72        72     72        72  \n",
       "Fabrics of Society          left          1016      1016   1016      1016  \n",
       "                            neutral        606       606    606       606  \n",
       "                            right         1808      1808   1808      1808  \n",
       "Immigration                 left           210       210    210       210  \n",
       "                            right          790       790    790       790  \n",
       "International Relations     left           985       985    985       985  \n",
       "                            neutral        334       334    334       334  \n",
       "                            right           74        74     74        74  \n",
       "Labour and Social Welfare   left          4303      4303   4303      4303  \n",
       "                            neutral         97        97     97        97  \n",
       "                            right          135       135    135       135  \n",
       "Military                    left           159       159    159       159  \n",
       "                            right          585       585    585       585  \n",
       "Other                       neutral       4541      4541   4541      4541  \n",
       "Political System            left            93        93     93        93  \n",
       "                            neutral       1639      1639   1639      1639  \n",
       "                            right          760       760    760       760  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_regrouped.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced = manifesto_regrouped[['topic','sentiment','text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7866bf32a60c4813a1a36db45ae5412d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/32343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040e2dae7c1a417989fa1bd5d6a87a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/32343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_reduced)\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d77e708c3f5447b87f0354e9ec2f603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = manifesto_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataloader = DataLoader(tokenized_dataset, batch_size=64, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ensemble member 0 from results/models/ensemble_scaling/model_ensemble_0.safetensors\n",
      "Loading ensemble member 1 from results/models/ensemble_scaling/model_ensemble_1.safetensors\n",
      "Loading ensemble member 2 from results/models/ensemble_scaling/model_ensemble_2.safetensors\n",
      "Loading ensemble member 3 from results/models/ensemble_scaling/model_ensemble_3.safetensors\n",
      "Loading ensemble member 4 from results/models/ensemble_scaling/model_ensemble_4.safetensors\n"
     ]
    }
   ],
   "source": [
    "## Load ensemble models for validity checks\n",
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "\n",
    "model_base = ContextScalePrediction(\n",
    "        roberta_model=model_name,\n",
    "        num_topics=num_topics,\n",
    "        num_sentiments=num_sentiments,\n",
    "        lora=False,\n",
    "        use_shared_attention=True\n",
    "    )\n",
    "\n",
    "ensemble_checkpoint_paths = [\n",
    "    os.path.join('results/models/ensemble_scaling', f\"model_ensemble_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "validity_ensemble_models = load_ensemble_models(\n",
    "    model_base=model_base,\n",
    "    checkpoint_paths=ensemble_checkpoint_paths,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ensemble inference with 5 models...\n",
      "\n",
      "Running inference with model 1/5\n",
      "  Batch 100/506 | Elapsed: 5.16s, Remaining: 20.96s\n",
      "  Batch 200/506 | Elapsed: 9.90s, Remaining: 15.15s\n",
      "  Batch 300/506 | Elapsed: 14.69s, Remaining: 10.08s\n",
      "  Batch 400/506 | Elapsed: 19.38s, Remaining: 5.14s\n",
      "  Batch 500/506 | Elapsed: 24.90s, Remaining: 0.30s\n",
      "  Using ground truth topic labels for position score computation\n",
      "\n",
      "Running inference with model 2/5\n",
      "  Batch 100/506 | Elapsed: 5.09s, Remaining: 20.68s\n",
      "  Batch 200/506 | Elapsed: 9.97s, Remaining: 15.25s\n",
      "  Batch 300/506 | Elapsed: 14.89s, Remaining: 10.22s\n",
      "  Batch 400/506 | Elapsed: 19.71s, Remaining: 5.22s\n",
      "  Batch 500/506 | Elapsed: 25.38s, Remaining: 0.30s\n",
      "\n",
      "Running inference with model 3/5\n",
      "  Batch 100/506 | Elapsed: 5.23s, Remaining: 21.21s\n",
      "  Batch 200/506 | Elapsed: 10.22s, Remaining: 15.63s\n",
      "  Batch 300/506 | Elapsed: 15.25s, Remaining: 10.47s\n",
      "  Batch 400/506 | Elapsed: 20.18s, Remaining: 5.35s\n",
      "  Batch 500/506 | Elapsed: 25.96s, Remaining: 0.31s\n",
      "\n",
      "Running inference with model 4/5\n",
      "  Batch 100/506 | Elapsed: 5.32s, Remaining: 21.60s\n",
      "  Batch 200/506 | Elapsed: 10.40s, Remaining: 15.91s\n",
      "  Batch 300/506 | Elapsed: 15.51s, Remaining: 10.65s\n",
      "  Batch 400/506 | Elapsed: 20.51s, Remaining: 5.44s\n",
      "  Batch 500/506 | Elapsed: 26.36s, Remaining: 0.32s\n",
      "\n",
      "Running inference with model 5/5\n",
      "  Batch 100/506 | Elapsed: 5.38s, Remaining: 21.85s\n",
      "  Batch 200/506 | Elapsed: 10.52s, Remaining: 16.09s\n",
      "  Batch 300/506 | Elapsed: 15.68s, Remaining: 10.77s\n",
      "  Batch 400/506 | Elapsed: 20.73s, Remaining: 5.49s\n",
      "  Batch 500/506 | Elapsed: 26.64s, Remaining: 0.32s\n",
      "\n",
      "Computing ensemble statistics...\n",
      "Total inference time: 131.07s\n",
      "Used predicted topic labels for position scaling\n",
      "Mean position score range: [-0.946, 0.906]\n",
      "Mean epistemic variance: 0.000000\n",
      "Mean aleatoric variance: 0.289663\n",
      "Ensemble inference completed!\n"
     ]
    }
   ],
   "source": [
    "outputs_dl = ensemble_inference(\n",
    "    models=validity_ensemble_models,\n",
    "    dataloader=pred_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=False\n",
    ")\n",
    "\n",
    "true_topics = outputs_dl.get('ground_truth_topics')\n",
    "if true_topics is not None:\n",
    "    true_topics = np.asarray(true_topics).ravel()\n",
    "    topic_precision, topic_recall, topic_f1, _ = precision_recall_fscore_support(\n",
    "        true_topics,\n",
    "        outputs_dl['ensemble_pred_topics'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_topic = confusion_matrix(true_topics, outputs_dl['ensemble_pred_topics'])\n",
    "    accuracy_topic = matrix_topic.diagonal() / matrix_topic.sum(axis=1)\n",
    "    outputs_dl['res_table_topic'] = pd.DataFrame({\n",
    "        'f1': np.round(topic_f1, 2),\n",
    "        'precision': np.round(topic_precision, 2),\n",
    "        'recall': np.round(topic_recall, 2),\n",
    "        'accuracy': np.round(accuracy_topic, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_dl['res_table_topic'] = None\n",
    "\n",
    "true_sentiments = outputs_dl.get('ground_truth_sentiments')\n",
    "if true_sentiments is not None:\n",
    "    true_sentiments = np.asarray(true_sentiments).ravel()\n",
    "    sent_precision, sent_recall, sent_f1, _ = precision_recall_fscore_support(\n",
    "        true_sentiments,\n",
    "        outputs_dl['ensemble_pred_sentiments'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_sentiment = confusion_matrix(true_sentiments, outputs_dl['ensemble_pred_sentiments'])\n",
    "    accuracy_sentiment = matrix_sentiment.diagonal() / matrix_sentiment.sum(axis=1)\n",
    "    outputs_dl['res_table_sentiment'] = pd.DataFrame({\n",
    "        'f1': np.round(sent_f1, 2),\n",
    "        'precision': np.round(sent_precision, 2),\n",
    "        'recall': np.round(sent_recall, 2),\n",
    "        'accuracy': np.round(accuracy_sentiment, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_dl['res_table_sentiment'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1           0.76\n",
       "precision    0.75\n",
       "recall       0.78\n",
       "accuracy     0.78\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dl['res_table_topic'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1           0.76\n",
       "precision    0.76\n",
       "recall       0.76\n",
       "accuracy     0.76\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dl['res_table_sentiment'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_dl'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_dl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl['res_table_sentiment'].to_csv('results/classification results/dl_sentiment.csv', index=False)\n",
    "outputs_dl['res_table_topic'].to_csv('results/classification results/dl_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model using only 10% of labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced['topic_sentiment'] = manifesto_reduced['topic'] + '_' + manifesto_reduced['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbabf44539e41228543249d7b46866e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/32343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc34eab2b9b541f486a6f2b4a073e688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/32343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae820f7a7d74e3d9506ce0b6470fa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/32343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_reduced)\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic_sentiment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = manifesto_dataset.train_test_split(test_size=0.9, stratify_by_column='topic_sentiment', seed=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 3234\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 29109\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_datasets = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test'],\n",
    "})\n",
    "manifesto_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbb8f96b692413fbad2447682efa46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3234 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe72d9a52494aa5b64d81cba536a4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29109 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['topic', 'sentiment', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = manifesto_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text', 'topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=64, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=64, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifesto ensemble members used for 10% supervision adaptation:\n"
     ]
    }
   ],
   "source": [
    "## Define ensemble model factories for 10% labelled subset with borrowed weights\n",
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "\n",
    "checkpoint_path = os.path.join('results/models/ensemble_scaling/model_ensemble_1.safetensors')\n",
    "\n",
    "print(\"Manifesto ensemble members used for 10% supervision adaptation:\")\n",
    "\n",
    "\n",
    "\n",
    "def copy_source_model(checkpoint_path):\n",
    "    source_model = ContextScalePrediction(\n",
    "        roberta_model=model_name,\n",
    "        num_topics=num_topics,\n",
    "        num_sentiments=num_sentiments,\n",
    "        lora=False,\n",
    "        use_shared_attention=True\n",
    "    ).to(device)\n",
    "    source_state = load_file(checkpoint_path)\n",
    "    source_model.load_state_dict(source_state)\n",
    "\n",
    "    return source_model\n",
    "\n",
    "\n",
    "model_base = copy_source_model(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training ensemble member 1/5\n",
      "Using shuffled training data with seed 1234\n",
      "==================================================\n",
      "Training ensemble member 1\n",
      "Using shuffled data with seed 1234\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.14s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.94s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.89s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.96s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.98s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_0.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 2/5\n",
      "Using shuffled training data with seed 1235\n",
      "==================================================\n",
      "Training ensemble member 2\n",
      "Using shuffled data with seed 1235\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.96s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.97s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.89s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.95s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.94s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_1.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 3/5\n",
      "Using shuffled training data with seed 1236\n",
      "==================================================\n",
      "Training ensemble member 3\n",
      "Using shuffled data with seed 1236\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.94s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.90s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.94s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.01s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.96s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_2.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 4/5\n",
      "Using shuffled training data with seed 1237\n",
      "==================================================\n",
      "Training ensemble member 4\n",
      "Using shuffled data with seed 1237\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.96s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.97s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.95s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.99s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.98s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_3.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 5/5\n",
      "Using shuffled training data with seed 1238\n",
      "==================================================\n",
      "Training ensemble member 5\n",
      "Using shuffled data with seed 1238\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.93s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.93s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.97s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.95s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 3.90s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_4.safetensors\n",
      "\n",
      "==================================================\n",
      "Ensemble training completed!\n",
      "Trained 5 models with different data shuffles\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble_training_info_dl_10 = train_deep_ensemble(\n",
    "    model_base=model_base,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=None,\n",
    "    device=device,\n",
    "    num_models=5,\n",
    "    n_epochs=5,\n",
    "    lr=2e-5,\n",
    "    sentiment_var='sentiment',\n",
    "    topic_var='topic',\n",
    "    save_dir='results/models/manifesto_ensemble_dl_10',\n",
    "    model_prefix='model_ensemble_dl_10',\n",
    "    org_seed=seed_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint paths for 10% ensemble:\n",
      "  Model 0: results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_0.safetensors\n",
      "  Model 1: results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_1.safetensors\n",
      "  Model 2: results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_2.safetensors\n",
      "  Model 3: results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_3.safetensors\n",
      "  Model 4: results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_4.safetensors\n",
      "Loading ensemble member 0 from results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_0.safetensors\n",
      "Loading ensemble member 1 from results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_1.safetensors\n",
      "Loading ensemble member 2 from results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_2.safetensors\n",
      "Loading ensemble member 3 from results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_3.safetensors\n",
      "Loading ensemble member 4 from results/models/manifesto_ensemble_dl_10/model_ensemble_dl_10_4.safetensors\n"
     ]
    }
   ],
   "source": [
    "checkpoint_paths_dl_10 = [\n",
    "    os.path.join('results/models/manifesto_ensemble_dl_10', f\"model_ensemble_dl_10_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "print(\"Checkpoint paths for 10% ensemble:\")\n",
    "for idx, path in enumerate(checkpoint_paths_dl_10):\n",
    "    print(f\"  Model {idx}: {path}\")\n",
    "\n",
    "manifesto_ensemble_dl_10_models = load_ensemble_models(\n",
    "    model_base=model_base,\n",
    "    checkpoint_paths=checkpoint_paths_dl_10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ensemble inference with 5 models...\n",
      "\n",
      "Running inference with model 1/5\n",
      "  Batch 100/455 | Elapsed: 6.10s, Remaining: 21.64s\n",
      "  Batch 200/455 | Elapsed: 12.56s, Remaining: 16.01s\n",
      "  Batch 300/455 | Elapsed: 18.97s, Remaining: 9.80s\n",
      "  Batch 400/455 | Elapsed: 25.39s, Remaining: 3.49s\n",
      "  Using ground truth topic labels for position score computation\n",
      "\n",
      "Running inference with model 2/5\n",
      "  Batch 100/455 | Elapsed: 6.20s, Remaining: 22.01s\n",
      "  Batch 200/455 | Elapsed: 12.74s, Remaining: 16.24s\n",
      "  Batch 300/455 | Elapsed: 19.21s, Remaining: 9.92s\n",
      "  Batch 400/455 | Elapsed: 25.59s, Remaining: 3.52s\n",
      "\n",
      "Running inference with model 3/5\n",
      "  Batch 100/455 | Elapsed: 6.24s, Remaining: 22.15s\n",
      "  Batch 200/455 | Elapsed: 12.82s, Remaining: 16.34s\n",
      "  Batch 300/455 | Elapsed: 19.31s, Remaining: 9.98s\n",
      "  Batch 400/455 | Elapsed: 25.73s, Remaining: 3.54s\n",
      "\n",
      "Running inference with model 4/5\n",
      "  Batch 100/455 | Elapsed: 6.27s, Remaining: 22.25s\n",
      "  Batch 200/455 | Elapsed: 12.86s, Remaining: 16.40s\n",
      "  Batch 300/455 | Elapsed: 19.38s, Remaining: 10.02s\n",
      "  Batch 400/455 | Elapsed: 25.82s, Remaining: 3.55s\n",
      "\n",
      "Running inference with model 5/5\n",
      "  Batch 100/455 | Elapsed: 6.28s, Remaining: 22.30s\n",
      "  Batch 200/455 | Elapsed: 12.89s, Remaining: 16.44s\n",
      "  Batch 300/455 | Elapsed: 19.43s, Remaining: 10.04s\n",
      "  Batch 400/455 | Elapsed: 25.87s, Remaining: 3.56s\n",
      "\n",
      "Computing ensemble statistics...\n",
      "Total inference time: 146.46s\n",
      "Used predicted topic labels for position scaling\n",
      "Mean position score range: [-0.975, 0.955]\n",
      "Mean epistemic variance: 0.000000\n",
      "Mean aleatoric variance: 0.153146\n",
      "Ensemble inference completed!\n"
     ]
    }
   ],
   "source": [
    "outputs_dl_10 = ensemble_inference(\n",
    "    models=manifesto_ensemble_dl_10_models,\n",
    "    dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=False\n",
    ")\n",
    "\n",
    "true_topics_dl_10 = outputs_dl_10.get('ground_truth_topics')\n",
    "if true_topics_dl_10 is not None:\n",
    "    true_topics_dl_10 = np.asarray(true_topics_dl_10).ravel()\n",
    "    topic_precision_dl_10, topic_recall_dl_10, topic_f1_dl_10, _ = precision_recall_fscore_support(\n",
    "        true_topics_dl_10,\n",
    "        outputs_dl_10['ensemble_pred_topics'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_topic_dl_10 = confusion_matrix(true_topics_dl_10, outputs_dl_10['ensemble_pred_topics'])\n",
    "    accuracy_topic_dl_10 = matrix_topic_dl_10.diagonal() / matrix_topic_dl_10.sum(axis=1)\n",
    "    outputs_dl_10['res_table_topic'] = pd.DataFrame({\n",
    "        'f1': np.round(topic_f1_dl_10, 2),\n",
    "        'precision': np.round(topic_precision_dl_10, 2),\n",
    "        'recall': np.round(topic_recall_dl_10, 2),\n",
    "        'accuracy': np.round(accuracy_topic_dl_10, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_dl_10['res_table_topic'] = None\n",
    "\n",
    "true_sentiments_dl_10 = outputs_dl_10.get('ground_truth_sentiments')\n",
    "if true_sentiments_dl_10 is not None:\n",
    "    true_sentiments_dl_10 = np.asarray(true_sentiments_dl_10).ravel()\n",
    "    sent_precision_dl_10, sent_recall_dl_10, sent_f1_dl_10, _ = precision_recall_fscore_support(\n",
    "        true_sentiments_dl_10,\n",
    "        outputs_dl_10['ensemble_pred_sentiments'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_sentiment_dl_10 = confusion_matrix(true_sentiments_dl_10, outputs_dl_10['ensemble_pred_sentiments'])\n",
    "    accuracy_sentiment_dl_10 = matrix_sentiment_dl_10.diagonal() / matrix_sentiment_dl_10.sum(axis=1)\n",
    "    outputs_dl_10['res_table_sentiment'] = pd.DataFrame({\n",
    "        'f1': np.round(sent_f1_dl_10, 2),\n",
    "        'precision': np.round(sent_precision_dl_10, 2),\n",
    "        'recall': np.round(sent_recall_dl_10, 2),\n",
    "        'accuracy': np.round(accuracy_sentiment_dl_10, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_dl_10['res_table_sentiment'] = None\n",
    "\n",
    "outputs_dl_10['position_scores'] = outputs_dl_10['mean_position_scores']\n",
    "outputs_dl_10['pred_topics'] = outputs_dl_10['ensemble_pred_topics']\n",
    "outputs_dl_10['pred_sentiment'] = outputs_dl_10['ensemble_pred_sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dl_10['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1  precision  recall  accuracy\n",
       "0  0.87       0.85    0.88      0.88\n",
       "1  0.83       0.84    0.81      0.81\n",
       "2  0.79       0.79    0.78      0.78"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dl_10['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dl_10['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_dl_10'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_dl_10, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10['res_table_sentiment'].to_csv('results/classification results/dl_10_sentiment.csv', index=False)\n",
    "outputs_dl_10['res_table_topic'].to_csv('results/classification results/dl_10_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COALITIONAGREE, same coding style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitionagree = pd.read_csv('data/r_outputs/coalitionagree_texts.csv', encoding='utf-8', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "      <th>country_init</th>\n",
       "      <th>cabinet_year</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Abkommen vom Dezember 1945</td>\n",
       "      <td>8</td>\n",
       "      <td>800</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AT</td>\n",
       "      <td>1945</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Der Proporz soll nicht nur bei der Bildung der...</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>90001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>AT</td>\n",
       "      <td>1945</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Staatssekretäre sollen nur in Ausnahmefällen n...</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>90004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>AT</td>\n",
       "      <td>1945</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Das Programm der Parteien soll in der Erklärun...</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>90001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>AT</td>\n",
       "      <td>1945</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Österreichische Volkspartei bietet den Soz...</td>\n",
       "      <td>9</td>\n",
       "      <td>900</td>\n",
       "      <td>90002</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>AT</td>\n",
       "      <td>1945</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  domain  category2  \\\n",
       "0                     1. Abkommen vom Dezember 1945        8        800   \n",
       "1  Der Proporz soll nicht nur bei der Bildung der...       9        900   \n",
       "2  Staatssekretäre sollen nur in Ausnahmefällen n...       9        900   \n",
       "3  Das Programm der Parteien soll in der Erklärun...       9        900   \n",
       "4  Die Österreichische Volkspartei bietet den Soz...       9        900   \n",
       "\n",
       "   category3  level  id country_init  cabinet_year  country  \n",
       "0      80000      0   1           AT          1945  Austria  \n",
       "1      90001      0   2           AT          1945  Austria  \n",
       "2      90004      0   3           AT          1945  Austria  \n",
       "3      90001      0   4           AT          1945  Austria  \n",
       "4      90002      0   5           AT          1945  Austria  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coalitionagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(coalitionagree, ['country','cabinet_year','category2','category3'], 'sentence', max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped = pd.DataFrame(results)\n",
    "coalition_regrouped = coalition_regrouped.explode('text').reset_index(drop=True)\n",
    "df_cols = coalition_regrouped['labels'].str.split(';', expand=True)\n",
    "coalition_regrouped = pd.concat([coalition_regrouped, df_cols], axis=1)\n",
    "coalition_regrouped.columns =['text','labels', 'country','year', 'cmp_short','cmp_long']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cmp_short</th>\n",
       "      <th>cmp_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abmachungen über die Beamtenbesoldung,  ebenso...</td>\n",
       "      <td>Austria;1945;303;30301</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1945</td>\n",
       "      <td>303</td>\n",
       "      <td>30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Der Gemeinde Wien soll, wenn die Sozialistisch...</td>\n",
       "      <td>Austria;1945;303;30303</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1945</td>\n",
       "      <td>303</td>\n",
       "      <td>30303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>über die Behandlung der Nationalsozialisten</td>\n",
       "      <td>Austria;1945;305;30506</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1945</td>\n",
       "      <td>305</td>\n",
       "      <td>30506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sowie über die Verstaatlichung werden in Aussi...</td>\n",
       "      <td>Austria;1945;413;41301</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1945</td>\n",
       "      <td>413</td>\n",
       "      <td>41301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Schaffung eines einheitlichen Dienst- und ...</td>\n",
       "      <td>Austria;1945;506;50602</td>\n",
       "      <td>Austria</td>\n",
       "      <td>1945</td>\n",
       "      <td>506</td>\n",
       "      <td>50602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  labels  \\\n",
       "0  Abmachungen über die Beamtenbesoldung,  ebenso...  Austria;1945;303;30301   \n",
       "1  Der Gemeinde Wien soll, wenn die Sozialistisch...  Austria;1945;303;30303   \n",
       "2       über die Behandlung der Nationalsozialisten   Austria;1945;305;30506   \n",
       "3  sowie über die Verstaatlichung werden in Aussi...  Austria;1945;413;41301   \n",
       "4  Die Schaffung eines einheitlichen Dienst- und ...  Austria;1945;506;50602   \n",
       "\n",
       "   country  year cmp_short cmp_long  \n",
       "0  Austria  1945       303    30301  \n",
       "1  Austria  1945       303    30303  \n",
       "2  Austria  1945       305    30506  \n",
       "3  Austria  1945       413    41301  \n",
       "4  Austria  1945       506    50602  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coalition_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped['sentiment'] = coalition_regrouped.apply(lambda x: sentiment_code_coalition(x['cmp_short'], x['cmp_long']), axis=1)\n",
    "coalition_regrouped['topic'] = coalition_regrouped['cmp_short'].apply(topic_code_coalition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>cmp_short</th>\n",
       "      <th>cmp_long</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Agriculture - Protectionism</th>\n",
       "      <th>left</th>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Economics</th>\n",
       "      <th>left</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3564</td>\n",
       "      <td>3564</td>\n",
       "      <td>3564</td>\n",
       "      <td>3564</td>\n",
       "      <td>3564</td>\n",
       "      <td>3564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>2592</td>\n",
       "      <td>2592</td>\n",
       "      <td>2592</td>\n",
       "      <td>2592</td>\n",
       "      <td>2592</td>\n",
       "      <td>2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Education</th>\n",
       "      <th>left</th>\n",
       "      <td>1883</td>\n",
       "      <td>1883</td>\n",
       "      <td>1883</td>\n",
       "      <td>1883</td>\n",
       "      <td>1883</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Environment - Growth</th>\n",
       "      <th>left</th>\n",
       "      <td>2045</td>\n",
       "      <td>2045</td>\n",
       "      <td>2045</td>\n",
       "      <td>2045</td>\n",
       "      <td>2045</td>\n",
       "      <td>2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>754</td>\n",
       "      <td>754</td>\n",
       "      <td>754</td>\n",
       "      <td>754</td>\n",
       "      <td>754</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">European Integration</th>\n",
       "      <th>left</th>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Fabrics of Society</th>\n",
       "      <th>left</th>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>769</td>\n",
       "      <td>769</td>\n",
       "      <td>769</td>\n",
       "      <td>769</td>\n",
       "      <td>769</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Immigration</th>\n",
       "      <th>left</th>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">International Relations</th>\n",
       "      <th>left</th>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Labour and Social Welfare</th>\n",
       "      <th>left</th>\n",
       "      <td>6767</td>\n",
       "      <td>6767</td>\n",
       "      <td>6767</td>\n",
       "      <td>6767</td>\n",
       "      <td>6767</td>\n",
       "      <td>6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Military</th>\n",
       "      <th>left</th>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <th>neutral</th>\n",
       "      <td>5633</td>\n",
       "      <td>5633</td>\n",
       "      <td>5633</td>\n",
       "      <td>5633</td>\n",
       "      <td>5633</td>\n",
       "      <td>5633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Political System</th>\n",
       "      <th>left</th>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2541</td>\n",
       "      <td>2541</td>\n",
       "      <td>2541</td>\n",
       "      <td>2541</td>\n",
       "      <td>2541</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1542</td>\n",
       "      <td>1542</td>\n",
       "      <td>1542</td>\n",
       "      <td>1542</td>\n",
       "      <td>1542</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  labels  country  year  cmp_short  \\\n",
       "topic                       sentiment                                           \n",
       "Agriculture - Protectionism left        877     877      877   877        877   \n",
       "                            right        86      86       86    86         86   \n",
       "Economics                   left       2025    2025     2025  2025       2025   \n",
       "                            neutral    3564    3564     3564  3564       3564   \n",
       "                            right      2592    2592     2592  2592       2592   \n",
       "Education                   left       1883    1883     1883  1883       1883   \n",
       "                            right        37      37       37    37         37   \n",
       "Environment - Growth        left       2045    2045     2045  2045       2045   \n",
       "                            neutral     337     337      337   337        337   \n",
       "                            right       754     754      754   754        754   \n",
       "European Integration        left        862     862      862   862        862   \n",
       "                            right        90      90       90    90         90   \n",
       "Fabrics of Society          left        831     831      831   831        831   \n",
       "                            neutral     769     769      769   769        769   \n",
       "                            right      2115    2115     2115  2115       2115   \n",
       "Immigration                 left        485     485      485   485        485   \n",
       "                            right       429     429      429   429        429   \n",
       "International Relations     left       1236    1236     1236  1236       1236   \n",
       "                            neutral     202     202      202   202        202   \n",
       "                            right        36      36       36    36         36   \n",
       "Labour and Social Welfare   left       6767    6767     6767  6767       6767   \n",
       "                            neutral      30      30       30    30         30   \n",
       "                            right       502     502      502   502        502   \n",
       "Military                    left        211     211      211   211        211   \n",
       "                            right       685     685      685   685        685   \n",
       "Other                       neutral    5633    5633     5633  5633       5633   \n",
       "Political System            left        121     121      121   121        121   \n",
       "                            neutral    2541    2541     2541  2541       2541   \n",
       "                            right      1542    1542     1542  1542       1542   \n",
       "\n",
       "                                       cmp_long  \n",
       "topic                       sentiment            \n",
       "Agriculture - Protectionism left            877  \n",
       "                            right            86  \n",
       "Economics                   left           2025  \n",
       "                            neutral        3564  \n",
       "                            right          2592  \n",
       "Education                   left           1883  \n",
       "                            right            37  \n",
       "Environment - Growth        left           2045  \n",
       "                            neutral         337  \n",
       "                            right           754  \n",
       "European Integration        left            862  \n",
       "                            right            90  \n",
       "Fabrics of Society          left            831  \n",
       "                            neutral         769  \n",
       "                            right          2115  \n",
       "Immigration                 left            485  \n",
       "                            right           429  \n",
       "International Relations     left           1236  \n",
       "                            neutral         202  \n",
       "                            right            36  \n",
       "Labour and Social Welfare   left           6767  \n",
       "                            neutral          30  \n",
       "                            right           502  \n",
       "Military                    left            211  \n",
       "                            right           685  \n",
       "Other                       neutral        5633  \n",
       "Political System            left            121  \n",
       "                            neutral        2541  \n",
       "                            right          1542  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coalition_regrouped.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.to_csv('data/temps/coalitionagree_regrouped_processed.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_reduced = coalition_regrouped[['sentiment', 'topic','text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433e7332210848f989fb9ea4ff7ab90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/39287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f965ef21f124199bc0c978a5df7dced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/39287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cagree_dataset = Dataset.from_pandas(cagree_reduced)\n",
    "cagree_dataset = cagree_dataset.class_encode_column('sentiment')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687961ee01174f7ab50ad8f2909ed30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = cagree_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ensemble member 0 from results/models/ensemble_scaling/model_ensemble_0.safetensors\n",
      "Loading ensemble member 1 from results/models/ensemble_scaling/model_ensemble_1.safetensors\n",
      "Loading ensemble member 2 from results/models/ensemble_scaling/model_ensemble_2.safetensors\n",
      "Loading ensemble member 3 from results/models/ensemble_scaling/model_ensemble_3.safetensors\n",
      "Loading ensemble member 4 from results/models/ensemble_scaling/model_ensemble_4.safetensors\n"
     ]
    }
   ],
   "source": [
    "## Load ensemble models for validity checks\n",
    "num_topics = len(set(cagree_reduced['topic']))\n",
    "num_sentiments = len(set(cagree_reduced['sentiment']))\n",
    "\n",
    "model_base = ContextScalePrediction(\n",
    "        roberta_model=model_name,\n",
    "        num_topics=num_topics,\n",
    "        num_sentiments=num_sentiments,\n",
    "        lora=False,\n",
    "        use_shared_attention=True\n",
    "    )\n",
    "\n",
    "ensemble_checkpoint_paths = [\n",
    "    os.path.join('results/models/ensemble_scaling', f\"model_ensemble_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "validity_ensemble_models = load_ensemble_models(\n",
    "    model_base=model_base,\n",
    "    checkpoint_paths=ensemble_checkpoint_paths,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ensemble inference with 5 models...\n",
      "\n",
      "Running inference with model 1/5\n",
      "  Batch 100/2456 | Elapsed: 1.54s, Remaining: 36.26s\n",
      "  Batch 200/2456 | Elapsed: 2.91s, Remaining: 32.84s\n",
      "  Batch 300/2456 | Elapsed: 4.20s, Remaining: 30.15s\n",
      "  Batch 400/2456 | Elapsed: 5.65s, Remaining: 29.06s\n",
      "  Batch 500/2456 | Elapsed: 7.25s, Remaining: 28.35s\n",
      "  Batch 600/2456 | Elapsed: 8.85s, Remaining: 27.37s\n",
      "  Batch 700/2456 | Elapsed: 10.45s, Remaining: 26.21s\n",
      "  Batch 800/2456 | Elapsed: 12.08s, Remaining: 25.00s\n",
      "  Batch 900/2456 | Elapsed: 13.15s, Remaining: 22.74s\n",
      "  Batch 1000/2456 | Elapsed: 14.20s, Remaining: 20.68s\n",
      "  Batch 1100/2456 | Elapsed: 15.33s, Remaining: 18.90s\n",
      "  Batch 1200/2456 | Elapsed: 16.51s, Remaining: 17.28s\n",
      "  Batch 1300/2456 | Elapsed: 17.66s, Remaining: 15.70s\n",
      "  Batch 1400/2456 | Elapsed: 18.91s, Remaining: 14.26s\n",
      "  Batch 1500/2456 | Elapsed: 20.22s, Remaining: 12.89s\n",
      "  Batch 1600/2456 | Elapsed: 21.47s, Remaining: 11.49s\n",
      "  Batch 1700/2456 | Elapsed: 22.65s, Remaining: 10.07s\n",
      "  Batch 1800/2456 | Elapsed: 23.88s, Remaining: 8.70s\n",
      "  Batch 1900/2456 | Elapsed: 25.06s, Remaining: 7.33s\n",
      "  Batch 2000/2456 | Elapsed: 26.47s, Remaining: 6.04s\n",
      "  Batch 2100/2456 | Elapsed: 27.87s, Remaining: 4.72s\n",
      "  Batch 2200/2456 | Elapsed: 29.07s, Remaining: 3.38s\n",
      "  Batch 2300/2456 | Elapsed: 30.22s, Remaining: 2.05s\n",
      "  Batch 2400/2456 | Elapsed: 31.32s, Remaining: 0.73s\n",
      "  Using ground truth topic labels for position score computation\n",
      "\n",
      "Running inference with model 2/5\n",
      "  Batch 100/2456 | Elapsed: 1.58s, Remaining: 37.31s\n",
      "  Batch 200/2456 | Elapsed: 2.99s, Remaining: 33.69s\n",
      "  Batch 300/2456 | Elapsed: 4.30s, Remaining: 30.87s\n",
      "  Batch 400/2456 | Elapsed: 5.78s, Remaining: 29.72s\n",
      "  Batch 500/2456 | Elapsed: 7.40s, Remaining: 28.97s\n",
      "  Batch 600/2456 | Elapsed: 9.03s, Remaining: 27.94s\n",
      "  Batch 700/2456 | Elapsed: 10.66s, Remaining: 26.73s\n",
      "  Batch 800/2456 | Elapsed: 12.31s, Remaining: 25.49s\n",
      "  Batch 900/2456 | Elapsed: 13.40s, Remaining: 23.16s\n",
      "  Batch 1000/2456 | Elapsed: 14.46s, Remaining: 21.06s\n",
      "  Batch 1100/2456 | Elapsed: 15.60s, Remaining: 19.23s\n",
      "  Batch 1200/2456 | Elapsed: 16.79s, Remaining: 17.58s\n",
      "  Batch 1300/2456 | Elapsed: 17.95s, Remaining: 15.96s\n",
      "  Batch 1400/2456 | Elapsed: 19.22s, Remaining: 14.50s\n",
      "  Batch 1500/2456 | Elapsed: 20.54s, Remaining: 13.09s\n",
      "  Batch 1600/2456 | Elapsed: 21.80s, Remaining: 11.66s\n",
      "  Batch 1700/2456 | Elapsed: 22.99s, Remaining: 10.22s\n",
      "  Batch 1800/2456 | Elapsed: 24.23s, Remaining: 8.83s\n",
      "  Batch 1900/2456 | Elapsed: 25.42s, Remaining: 7.44s\n",
      "  Batch 2000/2456 | Elapsed: 26.85s, Remaining: 6.12s\n",
      "  Batch 2100/2456 | Elapsed: 28.25s, Remaining: 4.79s\n",
      "  Batch 2200/2456 | Elapsed: 29.47s, Remaining: 3.43s\n",
      "  Batch 2300/2456 | Elapsed: 30.62s, Remaining: 2.08s\n",
      "  Batch 2400/2456 | Elapsed: 31.72s, Remaining: 0.74s\n",
      "\n",
      "Running inference with model 3/5\n",
      "  Batch 100/2456 | Elapsed: 1.59s, Remaining: 37.58s\n",
      "  Batch 200/2456 | Elapsed: 3.01s, Remaining: 33.92s\n",
      "  Batch 300/2456 | Elapsed: 4.32s, Remaining: 31.08s\n",
      "  Batch 400/2456 | Elapsed: 5.82s, Remaining: 29.92s\n",
      "  Batch 500/2456 | Elapsed: 7.45s, Remaining: 29.16s\n",
      "  Batch 600/2456 | Elapsed: 9.09s, Remaining: 28.13s\n",
      "  Batch 700/2456 | Elapsed: 10.73s, Remaining: 26.91s\n",
      "  Batch 800/2456 | Elapsed: 12.39s, Remaining: 25.65s\n",
      "  Batch 900/2456 | Elapsed: 13.48s, Remaining: 23.31s\n",
      "  Batch 1000/2456 | Elapsed: 14.55s, Remaining: 21.19s\n",
      "  Batch 1100/2456 | Elapsed: 15.70s, Remaining: 19.35s\n",
      "  Batch 1200/2456 | Elapsed: 16.90s, Remaining: 17.69s\n",
      "  Batch 1300/2456 | Elapsed: 18.06s, Remaining: 16.06s\n",
      "  Batch 1400/2456 | Elapsed: 19.33s, Remaining: 14.58s\n",
      "  Batch 1500/2456 | Elapsed: 20.66s, Remaining: 13.17s\n",
      "  Batch 1600/2456 | Elapsed: 21.93s, Remaining: 11.73s\n",
      "  Batch 1700/2456 | Elapsed: 23.12s, Remaining: 10.28s\n",
      "  Batch 1800/2456 | Elapsed: 24.37s, Remaining: 8.88s\n",
      "  Batch 1900/2456 | Elapsed: 25.56s, Remaining: 7.48s\n",
      "  Batch 2000/2456 | Elapsed: 26.99s, Remaining: 6.15s\n",
      "  Batch 2100/2456 | Elapsed: 28.41s, Remaining: 4.82s\n",
      "  Batch 2200/2456 | Elapsed: 29.62s, Remaining: 3.45s\n",
      "  Batch 2300/2456 | Elapsed: 30.78s, Remaining: 2.09s\n",
      "  Batch 2400/2456 | Elapsed: 31.89s, Remaining: 0.74s\n",
      "\n",
      "Running inference with model 4/5\n",
      "  Batch 100/2456 | Elapsed: 1.60s, Remaining: 37.72s\n",
      "  Batch 200/2456 | Elapsed: 3.02s, Remaining: 34.05s\n",
      "  Batch 300/2456 | Elapsed: 4.34s, Remaining: 31.19s\n",
      "  Batch 400/2456 | Elapsed: 5.84s, Remaining: 30.02s\n",
      "  Batch 500/2456 | Elapsed: 7.48s, Remaining: 29.26s\n",
      "  Batch 600/2456 | Elapsed: 9.12s, Remaining: 28.22s\n",
      "  Batch 700/2456 | Elapsed: 10.76s, Remaining: 27.00s\n",
      "  Batch 800/2456 | Elapsed: 12.43s, Remaining: 25.74s\n",
      "  Batch 900/2456 | Elapsed: 13.53s, Remaining: 23.39s\n",
      "  Batch 1000/2456 | Elapsed: 14.60s, Remaining: 21.26s\n",
      "  Batch 1100/2456 | Elapsed: 15.74s, Remaining: 19.41s\n",
      "  Batch 1200/2456 | Elapsed: 16.95s, Remaining: 17.74s\n",
      "  Batch 1300/2456 | Elapsed: 18.12s, Remaining: 16.11s\n",
      "  Batch 1400/2456 | Elapsed: 19.39s, Remaining: 14.62s\n",
      "  Batch 1500/2456 | Elapsed: 20.72s, Remaining: 13.21s\n",
      "  Batch 1600/2456 | Elapsed: 21.99s, Remaining: 11.76s\n",
      "  Batch 1700/2456 | Elapsed: 23.18s, Remaining: 10.31s\n",
      "  Batch 1800/2456 | Elapsed: 24.43s, Remaining: 8.90s\n",
      "  Batch 1900/2456 | Elapsed: 25.63s, Remaining: 7.50s\n",
      "  Batch 2000/2456 | Elapsed: 27.06s, Remaining: 6.17s\n",
      "  Batch 2100/2456 | Elapsed: 28.48s, Remaining: 4.83s\n",
      "  Batch 2200/2456 | Elapsed: 29.70s, Remaining: 3.46s\n",
      "  Batch 2300/2456 | Elapsed: 30.86s, Remaining: 2.09s\n",
      "  Batch 2400/2456 | Elapsed: 31.97s, Remaining: 0.75s\n",
      "\n",
      "Running inference with model 5/5\n",
      "  Batch 100/2456 | Elapsed: 1.60s, Remaining: 37.80s\n",
      "  Batch 200/2456 | Elapsed: 3.02s, Remaining: 34.11s\n",
      "  Batch 300/2456 | Elapsed: 4.35s, Remaining: 31.25s\n",
      "  Batch 400/2456 | Elapsed: 5.85s, Remaining: 30.08s\n",
      "  Batch 500/2456 | Elapsed: 7.49s, Remaining: 29.31s\n",
      "  Batch 600/2456 | Elapsed: 9.14s, Remaining: 28.27s\n",
      "  Batch 700/2456 | Elapsed: 10.78s, Remaining: 27.04s\n",
      "  Batch 800/2456 | Elapsed: 12.45s, Remaining: 25.77s\n",
      "  Batch 900/2456 | Elapsed: 13.55s, Remaining: 23.42s\n",
      "  Batch 1000/2456 | Elapsed: 14.62s, Remaining: 21.28s\n",
      "  Batch 1100/2456 | Elapsed: 15.76s, Remaining: 19.43s\n",
      "  Batch 1200/2456 | Elapsed: 16.97s, Remaining: 17.76s\n",
      "  Batch 1300/2456 | Elapsed: 18.14s, Remaining: 16.13s\n",
      "  Batch 1400/2456 | Elapsed: 19.41s, Remaining: 14.64s\n",
      "  Batch 1500/2456 | Elapsed: 20.75s, Remaining: 13.22s\n",
      "  Batch 1600/2456 | Elapsed: 22.01s, Remaining: 11.78s\n",
      "  Batch 1700/2456 | Elapsed: 23.21s, Remaining: 10.32s\n",
      "  Batch 1800/2456 | Elapsed: 24.46s, Remaining: 8.92s\n",
      "  Batch 1900/2456 | Elapsed: 25.66s, Remaining: 7.51s\n",
      "  Batch 2000/2456 | Elapsed: 27.09s, Remaining: 6.18s\n",
      "  Batch 2100/2456 | Elapsed: 28.51s, Remaining: 4.83s\n",
      "  Batch 2200/2456 | Elapsed: 29.73s, Remaining: 3.46s\n",
      "  Batch 2300/2456 | Elapsed: 30.89s, Remaining: 2.10s\n",
      "  Batch 2400/2456 | Elapsed: 32.00s, Remaining: 0.75s\n",
      "\n",
      "Computing ensemble statistics...\n",
      "Total inference time: 161.69s\n",
      "Used predicted topic labels for position scaling\n",
      "Mean position score range: [-0.944, 0.899]\n",
      "Mean epistemic variance: 0.000000\n",
      "Mean aleatoric variance: 0.322101\n",
      "Ensemble inference completed!\n"
     ]
    }
   ],
   "source": [
    "outputs_ca_test = ensemble_inference(\n",
    "    models=validity_ensemble_models,\n",
    "    dataloader=pred_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=False\n",
    ")\n",
    "\n",
    "true_topics_ca = outputs_ca_test.get('ground_truth_topics')\n",
    "if true_topics_ca is not None:\n",
    "    true_topics_ca = np.asarray(true_topics_ca).ravel()\n",
    "    topic_precision_ca, topic_recall_ca, topic_f1_ca, _ = precision_recall_fscore_support(\n",
    "        true_topics_ca,\n",
    "        outputs_ca_test['ensemble_pred_topics'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_topic_ca = confusion_matrix(true_topics_ca, outputs_ca_test['ensemble_pred_topics'])\n",
    "    accuracy_topic_ca = matrix_topic_ca.diagonal() / matrix_topic_ca.sum(axis=1)\n",
    "    outputs_ca_test['res_table_topic'] = pd.DataFrame({\n",
    "        'f1': np.round(topic_f1_ca, 2),\n",
    "        'precision': np.round(topic_precision_ca, 2),\n",
    "        'recall': np.round(topic_recall_ca, 2),\n",
    "        'accuracy': np.round(accuracy_topic_ca, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_ca_test['res_table_topic'] = None\n",
    "\n",
    "true_sentiments_ca = outputs_ca_test.get('ground_truth_sentiments')\n",
    "if true_sentiments_ca is not None:\n",
    "    true_sentiments_ca = np.asarray(true_sentiments_ca).ravel()\n",
    "    sent_precision_ca, sent_recall_ca, sent_f1_ca, _ = precision_recall_fscore_support(\n",
    "        true_sentiments_ca,\n",
    "        outputs_ca_test['ensemble_pred_sentiments'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_sentiment_ca = confusion_matrix(true_sentiments_ca, outputs_ca_test['ensemble_pred_sentiments'])\n",
    "    accuracy_sentiment_ca = matrix_sentiment_ca.diagonal() / matrix_sentiment_ca.sum(axis=1)\n",
    "    outputs_ca_test['res_table_sentiment'] = pd.DataFrame({\n",
    "        'f1': np.round(sent_f1_ca, 2),\n",
    "        'precision': np.round(sent_precision_ca, 2),\n",
    "        'recall': np.round(sent_recall_ca, 2),\n",
    "        'accuracy': np.round(accuracy_sentiment_ca, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_ca_test['res_table_sentiment'] = None\n",
    "\n",
    "outputs_ca_test['position_scores'] = outputs_ca_test['mean_position_scores']\n",
    "outputs_ca_test['pred_topics'] = outputs_ca_test['ensemble_pred_topics']\n",
    "outputs_ca_test['pred_sentiment'] = outputs_ca_test['ensemble_pred_sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_ca_test['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_ca_test['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_ca_test'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_ca_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_test['res_table_sentiment'].to_csv('results/classification results/cagree_noft_sentiment.csv', index=False)\n",
    "outputs_ca_test['res_table_topic'].to_csv('results/classification results/cagree_noft_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10% supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_reduced.loc[:,'topic_sentiment'] = cagree_reduced.loc[:,'topic'] + '_' + cagree_reduced.loc[:,'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b795e85e994f9682e9fd89b170a354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/39287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b4168c6b044344ab7de1bf18cec288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/39287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9077055b1ddd4a18ad7cad6a1afd0676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/39287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cagree_dataset = Dataset.from_pandas(cagree_reduced)\n",
    "cagree_dataset = cagree_dataset.class_encode_column('sentiment')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = cagree_dataset.train_test_split(test_size=0.9, stratify_by_column='topic_sentiment', seed=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentiment', 'topic', 'text', 'topic_sentiment'],\n",
       "        num_rows: 3928\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentiment', 'topic', 'text', 'topic_sentiment'],\n",
       "        num_rows: 35359\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cagree_datasets = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test'],\n",
    "})\n",
    "cagree_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391a370e72c5457dafd3a7481ec3d021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3928 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da128350db554519b8596a7bcb81b2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['sentiment', 'topic', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = cagree_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text','topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=64, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=64, shuffle=False, collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifesto ensemble members used for 10% supervision adaptation:\n"
     ]
    }
   ],
   "source": [
    "## Define ensemble model factories for 10% labelled subset with borrowed weights\n",
    "num_topics = len(set(cagree_reduced['topic']))\n",
    "num_sentiments = len(set(cagree_reduced['sentiment']))\n",
    "\n",
    "checkpoint_path = os.path.join('results/models/ensemble_scaling/model_ensemble_1.safetensors')\n",
    "\n",
    "print(\"Manifesto ensemble members used for 10% supervision adaptation:\")\n",
    "\n",
    "\n",
    "\n",
    "def copy_source_model(checkpoint_path):\n",
    "    source_model = ContextScalePrediction(\n",
    "        roberta_model=model_name,\n",
    "        num_topics=num_topics,\n",
    "        num_sentiments=num_sentiments,\n",
    "        lora=False,\n",
    "        use_shared_attention=True\n",
    "    ).to(device)\n",
    "    source_state = load_file(checkpoint_path)\n",
    "    source_model.load_state_dict(source_state)\n",
    "\n",
    "    return source_model\n",
    "\n",
    "\n",
    "model_base = copy_source_model(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training ensemble member 1/5\n",
      "Using shuffled training data with seed 1234\n",
      "==================================================\n",
      "Training ensemble member 1\n",
      "Using shuffled data with seed 1234\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.76s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.78s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.83s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.79s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.83s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_0.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 2/5\n",
      "Using shuffled training data with seed 1235\n",
      "==================================================\n",
      "Training ensemble member 2\n",
      "Using shuffled data with seed 1235\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.82s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.85s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.78s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.78s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.78s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_1.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 3/5\n",
      "Using shuffled training data with seed 1236\n",
      "==================================================\n",
      "Training ensemble member 3\n",
      "Using shuffled data with seed 1236\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.78s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.80s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.77s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.80s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.67s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_2.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 4/5\n",
      "Using shuffled training data with seed 1237\n",
      "==================================================\n",
      "Training ensemble member 4\n",
      "Using shuffled data with seed 1237\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.79s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.77s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.80s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.76s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.84s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_3.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 5/5\n",
      "Using shuffled training data with seed 1238\n",
      "==================================================\n",
      "Training ensemble member 5\n",
      "Using shuffled data with seed 1238\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.75s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.83s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.79s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.84s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 4.82s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_4.safetensors\n",
      "\n",
      "==================================================\n",
      "Ensemble training completed!\n",
      "Trained 5 models with different data shuffles\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "ensemble_training_info_ca_10 = train_deep_ensemble(\n",
    "    model_base=model_base,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=None,\n",
    "    device=device,\n",
    "    num_models=5,\n",
    "    n_epochs=5,\n",
    "    lr=2e-5,\n",
    "    sentiment_var='sentiment',\n",
    "    topic_var='topic',\n",
    "    save_dir='results/models/coalitionagree_ensemble_10',\n",
    "    model_prefix='model_ensemble_ca_10',\n",
    "    org_seed=seed_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_ensemble_ca_10_0.safetensors',\n",
       " 'model_ensemble_ca_10_1.safetensors',\n",
       " 'model_ensemble_ca_10_2.safetensors',\n",
       " 'model_ensemble_ca_10_3.safetensors',\n",
       " 'model_ensemble_ca_10_4.safetensors']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir('results/models/coalitionagree_ensemble_10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint paths for COALITIONAGREE 10% ensemble:\n",
      "  Model 0: results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_0.safetensors\n",
      "  Model 1: results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_1.safetensors\n",
      "  Model 2: results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_2.safetensors\n",
      "  Model 3: results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_3.safetensors\n",
      "  Model 4: results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_4.safetensors\n",
      "Loading ensemble member 0 from results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_0.safetensors\n",
      "Loading ensemble member 1 from results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_1.safetensors\n",
      "Loading ensemble member 2 from results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_2.safetensors\n",
      "Loading ensemble member 3 from results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_3.safetensors\n",
      "Loading ensemble member 4 from results/models/coalitionagree_ensemble_10/model_ensemble_ca_10_4.safetensors\n"
     ]
    }
   ],
   "source": [
    "coalition_ensemble_checkpoint_paths = [\n",
    "    os.path.join('results/models/coalitionagree_ensemble_10', f\"model_ensemble_ca_10_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "print(\"Checkpoint paths for COALITIONAGREE 10% ensemble:\")\n",
    "for idx, path in enumerate(coalition_ensemble_checkpoint_paths):\n",
    "    print(f\"  Model {idx}: {path}\")\n",
    "\n",
    "coalitionagree_ensemble_10_models = load_ensemble_models(\n",
    "    model_base=model_base,\n",
    "    checkpoint_paths=coalition_ensemble_checkpoint_paths,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ensemble inference with 5 models...\n",
      "\n",
      "Running inference with model 1/5\n",
      "  Batch 100/553 | Elapsed: 6.48s, Remaining: 29.35s\n",
      "  Batch 200/553 | Elapsed: 13.00s, Remaining: 22.94s\n",
      "  Batch 300/553 | Elapsed: 19.57s, Remaining: 16.51s\n",
      "  Batch 400/553 | Elapsed: 26.02s, Remaining: 9.95s\n",
      "  Batch 500/553 | Elapsed: 32.61s, Remaining: 3.46s\n",
      "  Using ground truth topic labels for position score computation\n",
      "\n",
      "Running inference with model 2/5\n",
      "  Batch 100/553 | Elapsed: 6.59s, Remaining: 29.85s\n",
      "  Batch 200/553 | Elapsed: 13.18s, Remaining: 23.27s\n",
      "  Batch 300/553 | Elapsed: 19.82s, Remaining: 16.71s\n",
      "  Batch 400/553 | Elapsed: 26.31s, Remaining: 10.06s\n",
      "  Batch 500/553 | Elapsed: 32.95s, Remaining: 3.49s\n",
      "\n",
      "Running inference with model 3/5\n",
      "  Batch 100/553 | Elapsed: 6.63s, Remaining: 30.02s\n",
      "  Batch 200/553 | Elapsed: 13.25s, Remaining: 23.39s\n",
      "  Batch 300/553 | Elapsed: 19.91s, Remaining: 16.79s\n",
      "  Batch 400/553 | Elapsed: 26.43s, Remaining: 10.11s\n",
      "  Batch 500/553 | Elapsed: 33.09s, Remaining: 3.51s\n",
      "\n",
      "Running inference with model 4/5\n",
      "  Batch 100/553 | Elapsed: 6.65s, Remaining: 30.10s\n",
      "  Batch 200/553 | Elapsed: 13.29s, Remaining: 23.45s\n",
      "  Batch 300/553 | Elapsed: 19.96s, Remaining: 16.83s\n",
      "  Batch 400/553 | Elapsed: 26.49s, Remaining: 10.13s\n",
      "  Batch 500/553 | Elapsed: 33.17s, Remaining: 3.52s\n",
      "\n",
      "Running inference with model 5/5\n",
      "  Batch 100/553 | Elapsed: 6.66s, Remaining: 30.15s\n",
      "  Batch 200/553 | Elapsed: 13.31s, Remaining: 23.49s\n",
      "  Batch 300/553 | Elapsed: 19.99s, Remaining: 16.86s\n",
      "  Batch 400/553 | Elapsed: 26.53s, Remaining: 10.15s\n",
      "  Batch 500/553 | Elapsed: 33.21s, Remaining: 3.52s\n",
      "\n",
      "Computing ensemble statistics...\n",
      "Total inference time: 183.41s\n",
      "Used predicted topic labels for position scaling\n",
      "Mean position score range: [-0.980, 0.954]\n",
      "Mean epistemic variance: 0.000000\n",
      "Mean aleatoric variance: 0.143274\n",
      "Ensemble inference completed!\n"
     ]
    }
   ],
   "source": [
    "outputs_ca_10 = ensemble_inference(\n",
    "    models=coalitionagree_ensemble_10_models,\n",
    "    dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=False\n",
    ")\n",
    "\n",
    "true_topics_ca_10 = outputs_ca_10.get('ground_truth_topics')\n",
    "if true_topics_ca_10 is not None:\n",
    "    true_topics_ca_10 = np.asarray(true_topics_ca_10).ravel()\n",
    "    topic_precision_ca_10, topic_recall_ca_10, topic_f1_ca_10, _ = precision_recall_fscore_support(\n",
    "        true_topics_ca_10,\n",
    "        outputs_ca_10['ensemble_pred_topics'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_topic_ca_10 = confusion_matrix(true_topics_ca_10, outputs_ca_10['ensemble_pred_topics'])\n",
    "    accuracy_topic_ca_10 = matrix_topic_ca_10.diagonal() / matrix_topic_ca_10.sum(axis=1)\n",
    "    outputs_ca_10['res_table_topic'] = pd.DataFrame({\n",
    "        'f1': np.round(topic_f1_ca_10, 2),\n",
    "        'precision': np.round(topic_precision_ca_10, 2),\n",
    "        'recall': np.round(topic_recall_ca_10, 2),\n",
    "        'accuracy': np.round(accuracy_topic_ca_10, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_ca_10['res_table_topic'] = None\n",
    "\n",
    "true_sentiments_ca_10 = outputs_ca_10.get('ground_truth_sentiments')\n",
    "if true_sentiments_ca_10 is not None:\n",
    "    true_sentiments_ca_10 = np.asarray(true_sentiments_ca_10).ravel()\n",
    "    sent_precision_ca_10, sent_recall_ca_10, sent_f1_ca_10, _ = precision_recall_fscore_support(\n",
    "        true_sentiments_ca_10,\n",
    "        outputs_ca_10['ensemble_pred_sentiments'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_sentiment_ca_10 = confusion_matrix(true_sentiments_ca_10, outputs_ca_10['ensemble_pred_sentiments'])\n",
    "    accuracy_sentiment_ca_10 = matrix_sentiment_ca_10.diagonal() / matrix_sentiment_ca_10.sum(axis=1)\n",
    "    outputs_ca_10['res_table_sentiment'] = pd.DataFrame({\n",
    "        'f1': np.round(sent_f1_ca_10, 2),\n",
    "        'precision': np.round(sent_precision_ca_10, 2),\n",
    "        'recall': np.round(sent_recall_ca_10, 2),\n",
    "        'accuracy': np.round(accuracy_sentiment_ca_10, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_ca_10['res_table_sentiment'] = None\n",
    "\n",
    "outputs_ca_10['position_scores'] = outputs_ca_10['mean_position_scores']\n",
    "outputs_ca_10['pred_topics'] = outputs_ca_10['ensemble_pred_topics']\n",
    "outputs_ca_10['pred_sentiment'] = outputs_ca_10['ensemble_pred_sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_ca_10['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_ca_10['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_ca_10'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_ca_10, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10['res_table_sentiment'].to_csv('results/classification results/cagree_10ft_sentiment.csv', index=False)\n",
    "outputs_ca_10['res_table_topic'].to_csv('results/classification results/cagree_10ft_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting to twitter data (Sentiment is not Stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_trump = pd.read_csv('data/MOTN/MOTN_responses_groundtruth.csv', encoding='utf-8')\n",
    "tw_kav = pd.read_csv('data/MOTN/kavanaugh_tweets_groundtruth.csv', encoding='utf-8')\n",
    "tw_wm = pd.read_csv('data/MOTN/WM_tweets_groundtruth.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wavenum</th>\n",
       "      <th>ideo5</th>\n",
       "      <th>edits_clean_text</th>\n",
       "      <th>qpos</th>\n",
       "      <th>trump_stance_auto</th>\n",
       "      <th>lexicoder_sentiment</th>\n",
       "      <th>fold</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>SVM_sentiment</th>\n",
       "      <th>BERT_sentiment</th>\n",
       "      <th>SVM_stance</th>\n",
       "      <th>BERT_stance</th>\n",
       "      <th>vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>the recent election of donald trump the freedo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Very conservative</td>\n",
       "      <td>donald trump won</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>that donald trump beat hillary clinton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>donald trump was elected president</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>the american people saw through the obfuscatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wavenum              ideo5  \\\n",
       "0        3           Moderate   \n",
       "1        3  Very conservative   \n",
       "2        3       Conservative   \n",
       "3        3       Conservative   \n",
       "4        3       Conservative   \n",
       "\n",
       "                                    edits_clean_text  qpos  trump_stance_auto  \\\n",
       "0  the recent election of donald trump the freedo...     1                  1   \n",
       "1                                   donald trump won     1                  1   \n",
       "2             that donald trump beat hillary clinton     1                  1   \n",
       "3                 donald trump was elected president     1                  1   \n",
       "4  the american people saw through the obfuscatio...     1                  1   \n",
       "\n",
       "   lexicoder_sentiment  fold  vader_sentiment  SVM_sentiment  BERT_sentiment  \\\n",
       "0                  1.0     3              1.0              1               1   \n",
       "1                  1.0     1              1.0              1               1   \n",
       "2                  NaN     5              NaN              1               1   \n",
       "3                  NaN     5              NaN              1               1   \n",
       "4                  1.0     3              1.0              0               1   \n",
       "\n",
       "   SVM_stance  BERT_stance  vader_scores  \n",
       "0           1            0        0.6369  \n",
       "1           1            1        0.5719  \n",
       "2           1            1        0.0000  \n",
       "3           1            1        0.0000  \n",
       "4           1            1        0.4019  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stance</th>\n",
       "      <th>fold</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>SVM_sentiment</th>\n",
       "      <th>BERT_sentiment</th>\n",
       "      <th>SVM_stance</th>\n",
       "      <th>BERT_stance</th>\n",
       "      <th>lexicoder_sentiment</th>\n",
       "      <th>vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @willchamberlain Ms. Ford sent an anonymou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @dbongino Is there ever going to come a da...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @SuzeOrmanShow He violates every one of my...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @funder Dear Judge Kavanaugh-  We request ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @BrianKarem BREAKING: Montgomery MD  PD Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  stance  fold  \\\n",
       "0   RT @willchamberlain Ms. Ford sent an anonymou...          0       1     3   \n",
       "1   RT @dbongino Is there ever going to come a da...          0       1     1   \n",
       "2   RT @SuzeOrmanShow He violates every one of my...          0       0     5   \n",
       "3   RT @funder Dear Judge Kavanaugh-  We request ...          0       0     5   \n",
       "4   RT @BrianKarem BREAKING: Montgomery MD  PD Ch...          0       0     3   \n",
       "\n",
       "   vader_sentiment  SVM_sentiment  BERT_sentiment  SVM_stance  BERT_stance  \\\n",
       "0              0.0              0               0           1            1   \n",
       "1              0.0              0               0           1            1   \n",
       "2              1.0              0               0           0            0   \n",
       "3              0.0              0               0           0            0   \n",
       "4              0.0              0               0           0            0   \n",
       "\n",
       "   lexicoder_sentiment  vader_scores  \n",
       "0                  0.0       -0.7579  \n",
       "1                  0.0       -0.4767  \n",
       "2                  0.0        0.5423  \n",
       "3                  0.0       -0.8020  \n",
       "4                  0.0       -0.2960  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_kav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>balanced_train</th>\n",
       "      <th>vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YES! I'm still with her and always will be. ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pics or it didn't happen. https://t.co/o1GddSmwk2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love this nasty woman. @MaribethMonroe #wome...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @YiawayYeh: Marching for love.  Nashville #...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These people are just Sad. https://t.co/0LK6iG...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stance  sentiment  \\\n",
       "0  YES! I'm still with her and always will be. ht...       1        1.0   \n",
       "1  Pics or it didn't happen. https://t.co/o1GddSmwk2       1        0.0   \n",
       "2  I love this nasty woman. @MaribethMonroe #wome...       1        1.0   \n",
       "3  RT @YiawayYeh: Marching for love.  Nashville #...       1        1.0   \n",
       "4  These people are just Sad. https://t.co/0LK6iG...       0        0.0   \n",
       "\n",
       "   balanced_train  vader_scores  \n",
       "0             0.0        0.5754  \n",
       "1             0.0        0.0000  \n",
       "2             1.0       -0.0129  \n",
       "3             1.0        0.6369  \n",
       "4             1.0       -0.4767  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_wm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_trump = tw_trump[['edits_clean_text','trump_stance_auto']].copy()\n",
    "tw_trump = tw_trump.rename(columns={'edits_clean_text': 'text', 'trump_stance_auto': 'stance'})\n",
    "tw_trump['topic'] = 'trump'\n",
    "tw_kav = tw_kav[['text', 'stance']].copy()\n",
    "tw_kav['topic'] = 'kavanaugh'\n",
    "tw_wm = tw_wm[['text','stance']].copy()\n",
    "tw_wm['topic'] = 'women march'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df = pd.concat([tw_trump, tw_kav,tw_wm]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df.loc[:,'lr'] = tw_df.apply(lambda x: recode_tw(x['topic'], x['stance']), axis=1)\n",
    "tw_df.loc[:,'topic_lr'] = tw_df['topic'] + '_' + tw_df['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stance</th>\n",
       "      <th>topic_lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th>lr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">kavanaugh</th>\n",
       "      <th>left</th>\n",
       "      <td>1672</td>\n",
       "      <td>1672</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1988</td>\n",
       "      <td>1988</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">trump</th>\n",
       "      <th>left</th>\n",
       "      <td>4312</td>\n",
       "      <td>4312</td>\n",
       "      <td>4312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>2834</td>\n",
       "      <td>2834</td>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">women march</th>\n",
       "      <th>left</th>\n",
       "      <td>16965</td>\n",
       "      <td>16965</td>\n",
       "      <td>16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>2647</td>\n",
       "      <td>2647</td>\n",
       "      <td>2647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  stance  topic_lr\n",
       "topic       lr                            \n",
       "kavanaugh   left    1672    1672      1672\n",
       "            right   1988    1988      1988\n",
       "trump       left    4312    4312      4312\n",
       "            right   2834    2834      2834\n",
       "women march left   16965   16965     16965\n",
       "            right   2647    2647      2647"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_df.groupby(['topic','lr']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30418 entries, 0 to 30417\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      30418 non-null  object\n",
      " 1   stance    30418 non-null  int64 \n",
      " 2   topic     30418 non-null  object\n",
      " 3   lr        30418 non-null  object\n",
      " 4   topic_lr  30418 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0805b817a60d4429b7689aea5552f38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/30418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ae72d846fb4ca895145ab64704c54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/30418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c524ccd82dbf48189f4226a865a66f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/30418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tw_dataset = Dataset.from_pandas(tw_df[['text','lr','topic', 'topic_lr']].copy())\n",
    "tw_dataset = tw_dataset.class_encode_column('lr')\n",
    "tw_dataset = tw_dataset.class_encode_column('topic')\n",
    "tw_dataset = tw_dataset.class_encode_column('topic_lr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = tw_dataset.train_test_split(test_size=0.9, stratify_by_column='topic_lr',seed=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'lr', 'topic', 'topic_lr'],\n",
       "        num_rows: 3041\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'lr', 'topic', 'topic_lr'],\n",
       "        num_rows: 27377\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_datasets = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test'],\n",
    "})\n",
    "tw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c07e57ae1d542b38c21ed47cc1e35e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7337fc6412ce409d99b61c7b59e75fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['lr', 'topic', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tw_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length':512}, \n",
    "                                            remove_columns=['text', 'topic_lr'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=64, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=64, shuffle=False, collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifesto ensemble members used for 10% supervision adaptation:\n",
      "Skipping topic.weight as it is not present or should be skipped in the scaling model.\n",
      "Skipping topic.bias as it is not present or should be skipped in the scaling model.\n",
      "Skipping sentiment.weight as it is not present or should be skipped in the scaling model.\n",
      "Skipping sentiment.bias as it is not present or should be skipped in the scaling model.\n",
      "Trainable Parameters after copying:\n",
      "roberta.embeddings.word_embeddings.weight\n",
      "roberta.embeddings.position_embeddings.weight\n",
      "roberta.embeddings.token_type_embeddings.weight\n",
      "roberta.embeddings.LayerNorm.weight\n",
      "roberta.embeddings.LayerNorm.bias\n",
      "roberta.encoder.layer.0.attention.self.query.weight\n",
      "roberta.encoder.layer.0.attention.self.query.bias\n",
      "roberta.encoder.layer.0.attention.self.key.weight\n",
      "roberta.encoder.layer.0.attention.self.key.bias\n",
      "roberta.encoder.layer.0.attention.self.value.weight\n",
      "roberta.encoder.layer.0.attention.self.value.bias\n",
      "roberta.encoder.layer.0.attention.output.dense.weight\n",
      "roberta.encoder.layer.0.attention.output.dense.bias\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.0.intermediate.dense.weight\n",
      "roberta.encoder.layer.0.intermediate.dense.bias\n",
      "roberta.encoder.layer.0.output.dense.weight\n",
      "roberta.encoder.layer.0.output.dense.bias\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.attention.self.query.weight\n",
      "roberta.encoder.layer.1.attention.self.query.bias\n",
      "roberta.encoder.layer.1.attention.self.key.weight\n",
      "roberta.encoder.layer.1.attention.self.key.bias\n",
      "roberta.encoder.layer.1.attention.self.value.weight\n",
      "roberta.encoder.layer.1.attention.self.value.bias\n",
      "roberta.encoder.layer.1.attention.output.dense.weight\n",
      "roberta.encoder.layer.1.attention.output.dense.bias\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.intermediate.dense.weight\n",
      "roberta.encoder.layer.1.intermediate.dense.bias\n",
      "roberta.encoder.layer.1.output.dense.weight\n",
      "roberta.encoder.layer.1.output.dense.bias\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.attention.self.query.weight\n",
      "roberta.encoder.layer.2.attention.self.query.bias\n",
      "roberta.encoder.layer.2.attention.self.key.weight\n",
      "roberta.encoder.layer.2.attention.self.key.bias\n",
      "roberta.encoder.layer.2.attention.self.value.weight\n",
      "roberta.encoder.layer.2.attention.self.value.bias\n",
      "roberta.encoder.layer.2.attention.output.dense.weight\n",
      "roberta.encoder.layer.2.attention.output.dense.bias\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.intermediate.dense.weight\n",
      "roberta.encoder.layer.2.intermediate.dense.bias\n",
      "roberta.encoder.layer.2.output.dense.weight\n",
      "roberta.encoder.layer.2.output.dense.bias\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.attention.self.query.weight\n",
      "roberta.encoder.layer.3.attention.self.query.bias\n",
      "roberta.encoder.layer.3.attention.self.key.weight\n",
      "roberta.encoder.layer.3.attention.self.key.bias\n",
      "roberta.encoder.layer.3.attention.self.value.weight\n",
      "roberta.encoder.layer.3.attention.self.value.bias\n",
      "roberta.encoder.layer.3.attention.output.dense.weight\n",
      "roberta.encoder.layer.3.attention.output.dense.bias\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.intermediate.dense.weight\n",
      "roberta.encoder.layer.3.intermediate.dense.bias\n",
      "roberta.encoder.layer.3.output.dense.weight\n",
      "roberta.encoder.layer.3.output.dense.bias\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.attention.self.query.weight\n",
      "roberta.encoder.layer.4.attention.self.query.bias\n",
      "roberta.encoder.layer.4.attention.self.key.weight\n",
      "roberta.encoder.layer.4.attention.self.key.bias\n",
      "roberta.encoder.layer.4.attention.self.value.weight\n",
      "roberta.encoder.layer.4.attention.self.value.bias\n",
      "roberta.encoder.layer.4.attention.output.dense.weight\n",
      "roberta.encoder.layer.4.attention.output.dense.bias\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.intermediate.dense.weight\n",
      "roberta.encoder.layer.4.intermediate.dense.bias\n",
      "roberta.encoder.layer.4.output.dense.weight\n",
      "roberta.encoder.layer.4.output.dense.bias\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.attention.self.query.weight\n",
      "roberta.encoder.layer.5.attention.self.query.bias\n",
      "roberta.encoder.layer.5.attention.self.key.weight\n",
      "roberta.encoder.layer.5.attention.self.key.bias\n",
      "roberta.encoder.layer.5.attention.self.value.weight\n",
      "roberta.encoder.layer.5.attention.self.value.bias\n",
      "roberta.encoder.layer.5.attention.output.dense.weight\n",
      "roberta.encoder.layer.5.attention.output.dense.bias\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.intermediate.dense.weight\n",
      "roberta.encoder.layer.5.intermediate.dense.bias\n",
      "roberta.encoder.layer.5.output.dense.weight\n",
      "roberta.encoder.layer.5.output.dense.bias\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.attention.self.query.weight\n",
      "roberta.encoder.layer.6.attention.self.query.bias\n",
      "roberta.encoder.layer.6.attention.self.key.weight\n",
      "roberta.encoder.layer.6.attention.self.key.bias\n",
      "roberta.encoder.layer.6.attention.self.value.weight\n",
      "roberta.encoder.layer.6.attention.self.value.bias\n",
      "roberta.encoder.layer.6.attention.output.dense.weight\n",
      "roberta.encoder.layer.6.attention.output.dense.bias\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.intermediate.dense.weight\n",
      "roberta.encoder.layer.6.intermediate.dense.bias\n",
      "roberta.encoder.layer.6.output.dense.weight\n",
      "roberta.encoder.layer.6.output.dense.bias\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.attention.self.query.weight\n",
      "roberta.encoder.layer.7.attention.self.query.bias\n",
      "roberta.encoder.layer.7.attention.self.key.weight\n",
      "roberta.encoder.layer.7.attention.self.key.bias\n",
      "roberta.encoder.layer.7.attention.self.value.weight\n",
      "roberta.encoder.layer.7.attention.self.value.bias\n",
      "roberta.encoder.layer.7.attention.output.dense.weight\n",
      "roberta.encoder.layer.7.attention.output.dense.bias\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.intermediate.dense.weight\n",
      "roberta.encoder.layer.7.intermediate.dense.bias\n",
      "roberta.encoder.layer.7.output.dense.weight\n",
      "roberta.encoder.layer.7.output.dense.bias\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.attention.self.query.weight\n",
      "roberta.encoder.layer.8.attention.self.query.bias\n",
      "roberta.encoder.layer.8.attention.self.key.weight\n",
      "roberta.encoder.layer.8.attention.self.key.bias\n",
      "roberta.encoder.layer.8.attention.self.value.weight\n",
      "roberta.encoder.layer.8.attention.self.value.bias\n",
      "roberta.encoder.layer.8.attention.output.dense.weight\n",
      "roberta.encoder.layer.8.attention.output.dense.bias\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.intermediate.dense.weight\n",
      "roberta.encoder.layer.8.intermediate.dense.bias\n",
      "roberta.encoder.layer.8.output.dense.weight\n",
      "roberta.encoder.layer.8.output.dense.bias\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.attention.self.query.weight\n",
      "roberta.encoder.layer.9.attention.self.query.bias\n",
      "roberta.encoder.layer.9.attention.self.key.weight\n",
      "roberta.encoder.layer.9.attention.self.key.bias\n",
      "roberta.encoder.layer.9.attention.self.value.weight\n",
      "roberta.encoder.layer.9.attention.self.value.bias\n",
      "roberta.encoder.layer.9.attention.output.dense.weight\n",
      "roberta.encoder.layer.9.attention.output.dense.bias\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.intermediate.dense.weight\n",
      "roberta.encoder.layer.9.intermediate.dense.bias\n",
      "roberta.encoder.layer.9.output.dense.weight\n",
      "roberta.encoder.layer.9.output.dense.bias\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.attention.self.query.weight\n",
      "roberta.encoder.layer.10.attention.self.query.bias\n",
      "roberta.encoder.layer.10.attention.self.key.weight\n",
      "roberta.encoder.layer.10.attention.self.key.bias\n",
      "roberta.encoder.layer.10.attention.self.value.weight\n",
      "roberta.encoder.layer.10.attention.self.value.bias\n",
      "roberta.encoder.layer.10.attention.output.dense.weight\n",
      "roberta.encoder.layer.10.attention.output.dense.bias\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.intermediate.dense.weight\n",
      "roberta.encoder.layer.10.intermediate.dense.bias\n",
      "roberta.encoder.layer.10.output.dense.weight\n",
      "roberta.encoder.layer.10.output.dense.bias\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.attention.self.query.weight\n",
      "roberta.encoder.layer.11.attention.self.query.bias\n",
      "roberta.encoder.layer.11.attention.self.key.weight\n",
      "roberta.encoder.layer.11.attention.self.key.bias\n",
      "roberta.encoder.layer.11.attention.self.value.weight\n",
      "roberta.encoder.layer.11.attention.self.value.bias\n",
      "roberta.encoder.layer.11.attention.output.dense.weight\n",
      "roberta.encoder.layer.11.attention.output.dense.bias\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.intermediate.dense.weight\n",
      "roberta.encoder.layer.11.intermediate.dense.bias\n",
      "roberta.encoder.layer.11.output.dense.weight\n",
      "roberta.encoder.layer.11.output.dense.bias\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "roberta.pooler.dense.weight\n",
      "roberta.pooler.dense.bias\n",
      "intermediate.0.weight\n",
      "intermediate.0.bias\n",
      "intermediate.1.weight\n",
      "intermediate.1.bias\n",
      "intermediate_topic.0.weight\n",
      "intermediate_topic.0.bias\n",
      "intermediate_topic.1.weight\n",
      "intermediate_topic.1.bias\n",
      "intermediate_sentiment.0.weight\n",
      "intermediate_sentiment.0.bias\n",
      "intermediate_sentiment.1.weight\n",
      "intermediate_sentiment.1.bias\n",
      "shared_attention.in_proj_weight\n",
      "shared_attention.in_proj_bias\n",
      "shared_attention.out_proj.weight\n",
      "shared_attention.out_proj.bias\n",
      "topic.weight\n",
      "topic.bias\n",
      "sentiment.weight\n",
      "sentiment.bias\n",
      "attention_regularizer.weight\n",
      "attention_regularizer.bias\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.path.join('results/models/ensemble_scaling/model_ensemble_1.safetensors')\n",
    "\n",
    "print(\"Manifesto ensemble members used for 10% supervision adaptation:\")\n",
    "\n",
    "\n",
    "\n",
    "def copy_source_model(checkpoint_path):\n",
    "    source_model = ContextScalePrediction(\n",
    "        roberta_model=model_name,\n",
    "        num_topics=12,\n",
    "        num_sentiments=3,\n",
    "        lora=False,\n",
    "        use_shared_attention=True\n",
    "    ).to(device)\n",
    "    source_state = load_file(checkpoint_path)\n",
    "    source_model.load_state_dict(source_state)\n",
    "    target_model = ContextScalePrediction(\n",
    "        roberta_model=model_name,\n",
    "        num_topics=3,\n",
    "        num_sentiments=2,\n",
    "        lora=False,\n",
    "        use_shared_attention=True\n",
    "    ).to(device)\n",
    "\n",
    "    copy_weights(source_model, target_model, patterns = ('topic', 'sentiment'), freeze_copied=False)\n",
    "    del source_model\n",
    "    return target_model\n",
    "\n",
    "\n",
    "model_base = copy_source_model(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training ensemble member 1/5\n",
      "Using shuffled training data with seed 1234\n",
      "==================================================\n",
      "Training ensemble member 1\n",
      "Using shuffled data with seed 1234\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.03s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.02s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.05s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.03s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.03s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/tw_ensemble/model_ensemble_tw_0.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 2/5\n",
      "Using shuffled training data with seed 1235\n",
      "==================================================\n",
      "Training ensemble member 2\n",
      "Using shuffled data with seed 1235\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.04s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.04s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.05s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.04s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.03s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/tw_ensemble/model_ensemble_tw_1.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 3/5\n",
      "Using shuffled training data with seed 1236\n",
      "==================================================\n",
      "Training ensemble member 3\n",
      "Using shuffled data with seed 1236\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.03s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.02s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.00s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.01s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.01s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/tw_ensemble/model_ensemble_tw_2.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 4/5\n",
      "Using shuffled training data with seed 1237\n",
      "==================================================\n",
      "Training ensemble member 4\n",
      "Using shuffled data with seed 1237\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.00s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.01s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.01s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.01s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.02s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/tw_ensemble/model_ensemble_tw_3.safetensors\n",
      "\n",
      "==================================================\n",
      "Training ensemble member 5/5\n",
      "Using shuffled training data with seed 1238\n",
      "==================================================\n",
      "Training ensemble member 5\n",
      "Using shuffled data with seed 1238\n",
      "Epoch: 1/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.04s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 2/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.04s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 3/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.01s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 4/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.00s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Epoch: 5/5\n",
      "\n",
      "Training...\n",
      "\n",
      "Training epoch took: 2.04s\n",
      "  Skipping evaluation (no eval_dataloader provided)\n",
      "Saved model checkpoint to results/models/tw_ensemble/model_ensemble_tw_4.safetensors\n",
      "\n",
      "==================================================\n",
      "Ensemble training completed!\n",
      "Trained 5 models with different data shuffles\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "ensemble_training_info_tw = train_deep_ensemble(\n",
    "    model_base=model_base,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=None,\n",
    "    device=device,\n",
    "    num_models=5,\n",
    "    n_epochs=5,\n",
    "    lr=2e-5,\n",
    "    sentiment_var='lr',\n",
    "    topic_var='topic',\n",
    "    save_dir='results/models/tw_ensemble',\n",
    "    model_prefix='model_ensemble_tw',\n",
    "    org_seed=seed_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint paths for adapted Twitter ensemble:\n",
      "  Model 0: results/models/tw_ensemble/model_ensemble_tw_0.safetensors\n",
      "  Model 1: results/models/tw_ensemble/model_ensemble_tw_1.safetensors\n",
      "  Model 2: results/models/tw_ensemble/model_ensemble_tw_2.safetensors\n",
      "  Model 3: results/models/tw_ensemble/model_ensemble_tw_3.safetensors\n",
      "  Model 4: results/models/tw_ensemble/model_ensemble_tw_4.safetensors\n",
      "Loading ensemble member 0 from results/models/tw_ensemble/model_ensemble_tw_0.safetensors\n",
      "Loading ensemble member 1 from results/models/tw_ensemble/model_ensemble_tw_1.safetensors\n",
      "Loading ensemble member 2 from results/models/tw_ensemble/model_ensemble_tw_2.safetensors\n",
      "Loading ensemble member 3 from results/models/tw_ensemble/model_ensemble_tw_3.safetensors\n",
      "Loading ensemble member 4 from results/models/tw_ensemble/model_ensemble_tw_4.safetensors\n"
     ]
    }
   ],
   "source": [
    "twitter_ensemble_checkpoint_paths = [\n",
    "    os.path.join('results/models/tw_ensemble', f\"model_ensemble_tw_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "print(\"Checkpoint paths for adapted Twitter ensemble:\")\n",
    "for idx, path in enumerate(twitter_ensemble_checkpoint_paths):\n",
    "    print(f\"  Model {idx}: {path}\")\n",
    "\n",
    "twitter_ensemble_models = load_ensemble_models(\n",
    "    model_base=model_base,\n",
    "    checkpoint_paths=twitter_ensemble_checkpoint_paths,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ensemble inference with 5 models...\n",
      "\n",
      "Running inference with model 1/5\n",
      "  Batch 100/428 | Elapsed: 2.50s, Remaining: 8.19s\n",
      "  Batch 200/428 | Elapsed: 4.90s, Remaining: 5.58s\n",
      "  Batch 300/428 | Elapsed: 7.29s, Remaining: 3.11s\n",
      "  Batch 400/428 | Elapsed: 9.73s, Remaining: 0.68s\n",
      "  Using ground truth topic labels for position score computation\n",
      "\n",
      "Running inference with model 2/5\n",
      "  Batch 100/428 | Elapsed: 2.53s, Remaining: 8.29s\n",
      "  Batch 200/428 | Elapsed: 4.95s, Remaining: 5.64s\n",
      "  Batch 300/428 | Elapsed: 7.37s, Remaining: 3.14s\n",
      "  Batch 400/428 | Elapsed: 9.83s, Remaining: 0.69s\n",
      "\n",
      "Running inference with model 3/5\n",
      "  Batch 100/428 | Elapsed: 2.55s, Remaining: 8.37s\n",
      "  Batch 200/428 | Elapsed: 4.99s, Remaining: 5.69s\n",
      "  Batch 300/428 | Elapsed: 7.43s, Remaining: 3.17s\n",
      "  Batch 400/428 | Elapsed: 9.91s, Remaining: 0.69s\n",
      "\n",
      "Running inference with model 4/5\n",
      "  Batch 100/428 | Elapsed: 2.58s, Remaining: 8.45s\n",
      "  Batch 200/428 | Elapsed: 5.04s, Remaining: 5.74s\n",
      "  Batch 300/428 | Elapsed: 7.49s, Remaining: 3.20s\n",
      "  Batch 400/428 | Elapsed: 9.99s, Remaining: 0.70s\n",
      "\n",
      "Running inference with model 5/5\n",
      "  Batch 100/428 | Elapsed: 2.58s, Remaining: 8.48s\n",
      "  Batch 200/428 | Elapsed: 5.06s, Remaining: 5.77s\n",
      "  Batch 300/428 | Elapsed: 7.52s, Remaining: 3.21s\n",
      "  Batch 400/428 | Elapsed: 10.04s, Remaining: 0.70s\n",
      "\n",
      "Computing ensemble statistics...\n",
      "Total inference time: 53.44s\n",
      "Used predicted topic labels for position scaling\n",
      "Mean position score range: [-0.994, 0.989]\n",
      "Mean epistemic variance: 0.000000\n",
      "Mean aleatoric variance: 0.080230\n",
      "Ensemble inference completed!\n"
     ]
    }
   ],
   "source": [
    "outputs_tw_10 = ensemble_inference(\n",
    "    models=twitter_ensemble_models,\n",
    "    dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='lr',\n",
    "    use_ground_truth_topic=False\n",
    ")\n",
    "\n",
    "true_topics_tw = outputs_tw_10.get('ground_truth_topics')\n",
    "if true_topics_tw is not None:\n",
    "    true_topics_tw = np.asarray(true_topics_tw).ravel()\n",
    "    topic_precision_tw, topic_recall_tw, topic_f1_tw, _ = precision_recall_fscore_support(\n",
    "        true_topics_tw,\n",
    "        outputs_tw_10['ensemble_pred_topics'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_topic_tw = confusion_matrix(true_topics_tw, outputs_tw_10['ensemble_pred_topics'])\n",
    "    accuracy_topic_tw = matrix_topic_tw.diagonal() / matrix_topic_tw.sum(axis=1)\n",
    "    outputs_tw_10['res_table_topic'] = pd.DataFrame({\n",
    "        'f1': np.round(topic_f1_tw, 2),\n",
    "        'precision': np.round(topic_precision_tw, 2),\n",
    "        'recall': np.round(topic_recall_tw, 2),\n",
    "        'accuracy': np.round(accuracy_topic_tw, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_tw_10['res_table_topic'] = None\n",
    "\n",
    "true_sentiments_tw = outputs_tw_10.get('ground_truth_sentiments')\n",
    "if true_sentiments_tw is not None:\n",
    "    true_sentiments_tw = np.asarray(true_sentiments_tw).ravel()\n",
    "    sent_precision_tw, sent_recall_tw, sent_f1_tw, _ = precision_recall_fscore_support(\n",
    "        true_sentiments_tw,\n",
    "        outputs_tw_10['ensemble_pred_sentiments'],\n",
    "        average=None\n",
    "    )\n",
    "    matrix_sentiment_tw = confusion_matrix(true_sentiments_tw, outputs_tw_10['ensemble_pred_sentiments'])\n",
    "    accuracy_sentiment_tw = matrix_sentiment_tw.diagonal() / matrix_sentiment_tw.sum(axis=1)\n",
    "    outputs_tw_10['res_table_sentiment'] = pd.DataFrame({\n",
    "        'f1': np.round(sent_f1_tw, 2),\n",
    "        'precision': np.round(sent_precision_tw, 2),\n",
    "        'recall': np.round(sent_recall_tw, 2),\n",
    "        'accuracy': np.round(accuracy_sentiment_tw, 2)\n",
    "    })\n",
    "else:\n",
    "    outputs_tw_10['res_table_sentiment'] = None\n",
    "\n",
    "outputs_tw_10['position_scores'] = outputs_tw_10['mean_position_scores']\n",
    "outputs_tw_10['pred_topics'] = outputs_tw_10['ensemble_pred_topics']\n",
    "outputs_tw_10['pred_sentiment'] = outputs_tw_10['ensemble_pred_sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_tw_10['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_tw_10['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_tw_10'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_tw_10, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10['res_table_sentiment'].to_csv('results/classification results/tw_10ft_sentiment.csv', index=False)\n",
    "outputs_tw_10['res_table_topic'].to_csv('results/classification results/tw_10ft_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_d2v = pd.read_csv('data/temps/manifesto.csv', encoding='utf-8', dtype={'cmp_code':'str', 'is_copy_of':'str'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clean_text_loop(manifesto_d2v, 'countryname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_d2v.loc[:,'text_cleaned'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_d2v.loc[:,'party_election'] = manifesto_d2v.party.astype(str).str.cat(manifesto_d2v[['election']].astype(str).values, sep='_')\n",
    "manifesto_d2v.loc[:,'country_party_election'] = manifesto_d2v.countryname.str.cat(manifesto_d2v[['party','election']].astype(str).values, sep='_')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - original approach by R&C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-level dataframes\n",
    "country_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_d2v['countryname'].unique()\n",
    "\n",
    "# Loop through each country and process separately\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_d2v[manifesto_d2v['countryname'] == country]\n",
    "    \n",
    "    # Build the corpus iterator for this country's data\n",
    "    outputs_stream = phraseIterator(country_data, 'text_cleaned')\n",
    "    bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "    trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "    \n",
    "    # Create the Doc2Vec model and build vocabulary\n",
    "    model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "    model.build_vocab(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                total_examples=model.corpus_count, epochs=20)\n",
    "    \n",
    "    # Generate embeddings and apply dimensionality reduction\n",
    "    embed_dict = d2v_reduct(model)\n",
    "    df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "    df_d2v.index.name = 'party_election'\n",
    "    df_d2v.reset_index(inplace=True)\n",
    "    pca = PCA(n_components=2, random_state=seed_val)\n",
    "    df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "    df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "    \n",
    "    # Split the 'party_election' label into separate columns\n",
    "    df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "    df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "    df_d2v['country'] = country  # Add country column for merging later\n",
    "    \n",
    "    # Append the country-level dataframe to the list\n",
    "    country_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_gen_party_election.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_d2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_germany = final_df_d2v[final_df_d2v.country == 'Germany'].copy()\n",
    "d2v_germany.loc[:,'party_name'] = d2v_germany['party'].astype(str).apply(party_deu)\n",
    "d2v_germany = d2v_germany[d2v_germany.party_name != 'Other'].reset_index(drop=True)\n",
    "d2v_germany.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in d2v_germany.groupby('party_name'):\n",
    "    ax.plot(group.election, group.d2v_d1, marker='o',  ms=4, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v.to_csv('data/py_outputs/r&c_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - relevant topics\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(manifesto_d2v['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-topic level dataframes\n",
    "country_topic_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_d2v['countryname'].unique()\n",
    "\n",
    "# Loop through each country\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_d2v[manifesto_d2v['countryname'] == country]\n",
    "    country_data = country_data[country_data['topic'].isin(['Environment - Growth', 'Political System', 'Economics',\n",
    "                                                            'European Integration','Labour and Social Welfare',\n",
    "                                                            'Immigration'])]\n",
    "    # Get the unique list of topics within this country\n",
    "    unique_topics = country_data['topic'].unique()\n",
    "    \n",
    "    # Loop through each topic in the country\n",
    "    for topic in unique_topics:\n",
    "        print(f\"Processing topic: {topic}\")\n",
    "\n",
    "        # Filter the dataset for the current country and topic\n",
    "        country_topic_data = country_data[country_data['topic'] == topic]\n",
    "\n",
    "        # Build the corpus iterator for this country's topic-specific data\n",
    "        outputs_stream = phraseIterator(country_topic_data, 'text_cleaned')\n",
    "        bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "        trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "\n",
    "        # Create the Doc2Vec model and build vocabulary\n",
    "        model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "        model.build_vocab(corpusIterator(country_topic_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "\n",
    "        # Train the model\n",
    "        model.train(corpusIterator(country_topic_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                    total_examples=model.corpus_count, epochs=20)\n",
    "\n",
    "        # Generate embeddings and apply dimensionality reduction\n",
    "        embed_dict = d2v_reduct(model)\n",
    "        df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "        df_d2v.index.name = 'party_election'\n",
    "        df_d2v.reset_index(inplace=True)\n",
    "        pca = PCA(n_components=2, random_state=seed_val)\n",
    "        df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "        df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "\n",
    "        # Split the 'party_election' label into separate columns\n",
    "        df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "        df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "        df_d2v['country'] = country  # Add country column\n",
    "        df_d2v['topic'] = topic  # Add topic column\n",
    "\n",
    "        # Append the country-topic-level dataframe to the list\n",
    "        country_topic_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-topic-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_topic_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_party_election_topic.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - Environment Protection\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_ep = manifesto_d2v[manifesto_d2v.cmp_code.isin(['501'])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_ep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-level dataframes\n",
    "country_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_ep['countryname'].unique()\n",
    "\n",
    "# Loop through each country and process separately\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_ep[manifesto_ep['countryname'] == country]\n",
    "    \n",
    "    # Build the corpus iterator for this country's data\n",
    "    outputs_stream = phraseIterator(country_data, 'text_cleaned')\n",
    "    bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "    trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "    \n",
    "    # Create the Doc2Vec model and build vocabulary\n",
    "    model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "    model.build_vocab(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                total_examples=model.corpus_count, epochs=20)\n",
    "    \n",
    "    # Generate embeddings and apply dimensionality reduction\n",
    "    embed_dict = d2v_reduct(model)\n",
    "    df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "    df_d2v.index.name = 'party_election'\n",
    "    df_d2v.reset_index(inplace=True)\n",
    "    pca = PCA(n_components=2, random_state=seed_val)\n",
    "    df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "    df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "    \n",
    "    # Split the 'party_election' label into separate columns\n",
    "    df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "    df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "    df_d2v['country'] = country  # Add country column for merging later\n",
    "    \n",
    "    # Append the country-level dataframe to the list\n",
    "    country_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_ep_party_election.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - Germany, growth vs anti growth\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_welfare = manifesto_d2v[manifesto_d2v.cmp_code.isin(['504', '505'])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_welfare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-level dataframes\n",
    "country_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_welfare['countryname'].unique()\n",
    "\n",
    "# Loop through each country and process separately\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_welfare[manifesto_welfare['countryname'] == country]\n",
    "    \n",
    "    # Build the corpus iterator for this country's data\n",
    "    outputs_stream = phraseIterator(country_data, 'text_cleaned')\n",
    "    bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "    trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "    \n",
    "    # Create the Doc2Vec model and build vocabulary\n",
    "    model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "    model.build_vocab(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                total_examples=model.corpus_count, epochs=20)\n",
    "    \n",
    "    # Generate embeddings and apply dimensionality reduction\n",
    "    embed_dict = d2v_reduct(model)\n",
    "    df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "    df_d2v.index.name = 'party_election'\n",
    "    df_d2v.reset_index(inplace=True)\n",
    "    pca = PCA(n_components=2, random_state=seed_val)\n",
    "    df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "    df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "    \n",
    "    # Split the 'party_election' label into separate columns\n",
    "    df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "    df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "    df_d2v['country'] = country  # Add country column for merging later\n",
    "    \n",
    "    # Append the country-level dataframe to the list\n",
    "    country_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_welfare_party_election.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale position scores for all countries (released dataset + model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain for the entire dataset with all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_org = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes.csv\"), encoding=\"utf-8\", dtype={2:'str',18:'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_other = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes_test.csv\"), encoding=\"utf-8\", dtype={2:'str',18:'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_org_cleaned = manifesto_org.dropna(axis=1, how='all')\n",
    "manifesto_other_cleaned = manifesto_other.dropna(axis=1, how='all')\n",
    "manifesto_full = pd.concat([manifesto_org_cleaned, manifesto_other_cleaned]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full = manifesto_full[(manifesto_full.cmp_code.notna()) & ~(manifesto_full.cmp_code == 'H')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full['sentiment'] = manifesto_full['cmp_code'].apply(sentiment_code)\n",
    "manifesto_full['topic'] = manifesto_full['cmp_code'].apply(topic_code)\n",
    "manifesto_full['election'] = manifesto_full['date'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full.groupby(['topic'])['sentiment'].value_counts().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(manifesto_full, \n",
    "                      ['countryname','election','party','cmp_code'], 'text', \n",
    "                      max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped = pd.DataFrame(results)\n",
    "manifesto_regrouped = manifesto_regrouped.explode('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = manifesto_regrouped['labels'].str.split(';', expand=True)\n",
    "manifesto_regrouped = pd.concat([manifesto_regrouped, df_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.columns = ['text', 'country_election_party_code', 'country','election', 'party', 'cmp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'sentiment'] = manifesto_regrouped['cmp_code'].apply(sentiment_code)\n",
    "manifesto_regrouped.loc[:,'topic'] = manifesto_regrouped['cmp_code'].apply(topic_code)\n",
    "manifesto_regrouped = manifesto_regrouped.drop_duplicates().reset_index(drop=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.to_csv('data/temps/manifesto_regrouped_full_processed.csv', encoding='utf-8', index=False)\n",
    "manifesto_full.to_csv('data/temps/manifesto_full_processed.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped = pd.read_csv('data/temps/coalitionagree_regrouped_processed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:, 'source'] = 'manifestos'\n",
    "coalition_regrouped.loc[:, 'source'] = 'coalition_contracts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.groupby(['topic'])['sentiment'].value_counts().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([manifesto_regrouped[['text','sentiment','topic', 'source']], coalition_regrouped[['text','sentiment','topic','source']]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[:,'topic_sentiment'] = final_df['topic'] + '_' + final_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = Dataset.from_pandas(final_df)\n",
    "final_dataset = final_dataset.class_encode_column('sentiment')\n",
    "final_dataset = final_dataset.class_encode_column('topic')\n",
    "final_dataset = final_dataset.class_encode_column('topic_sentiment')\n",
    "final_dataset = final_dataset.class_encode_column('source')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = final_dataset.train_test_split(test_size=0.1, stratify_by_column='topic_sentiment', seed=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_datasets = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test']\n",
    "})\n",
    "final_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = final_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text','topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16, shuffle=False, collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(final_df['topic']))\n",
    "num_sentiments = len(set(final_df['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, num_topics=12, num_sentiments=3,lora=False, use_shared_attention=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) ## Recommended for LoRA. Without LoRA, can use 2e-5 instead.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    train_loop(train_dataloader, model,optimizer, scheduler, device, criterion, criterion, sentiment_var='sentiment',\n",
    "               topic_var='topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/contextscale_full_released/model.safetensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale manifestos and coalition contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped = pd.read_csv('data/temps/coalitionagree_regrouped_processed.csv', encoding='utf-8')\n",
    "manifesto_regrouped = pd.read_csv('data/temps/manifesto_regrouped_full_processed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 12\n",
    "num_sentiments = 3\n",
    "scaling_model = ContextScalePrediction(roberta_model=model_name, num_topics=12, num_sentiments=3,lora=False, use_shared_attention=True).to(device)\n",
    "\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tensors = load_file('results/models/contextscale_full_released/model.safetensors')\n",
    "scaling_model.load_state_dict(loaded_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_regrouped[['text','topic','sentiment']].copy())\n",
    "coalition_dataset = Dataset.from_pandas(coalition_regrouped[['text','topic','sentiment']].copy())\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic') \n",
    "coalition_dataset = coalition_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment') \n",
    "coalition_dataset = coalition_dataset.class_encode_column('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_manifesto_dataset = manifesto_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])\n",
    "tokenized_manifesto_dataset.set_format(\"torch\")\n",
    "tokenized_coalition_dataset = coalition_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])\n",
    "tokenized_coalition_dataset.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_dataloader = DataLoader(tokenized_manifesto_dataset, batch_size=16, shuffle=False, collate_fn= data_collator)\n",
    "coalition_dataloader = DataLoader(tokenized_coalition_dataset, batch_size=16, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute position scores\n",
    "output_manifesto_final = scale_func(manifesto_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/topic_labels'\n",
    "with open(file_path, 'rb') as fp:\n",
    "    topic_labels = pickle.load(fp)\n",
    "name_topic_dict = dict([(x,y) for x,y in enumerate(topic_labels)])\n",
    "\n",
    "\n",
    "file_path = 'data/temps/sentiment_labels'\n",
    "with open(file_path, 'rb') as fp:\n",
    "    sentiment_labels = pickle.load(fp)\n",
    "name_sentiment_dict = dict([(x,y) for x,y in enumerate(sentiment_labels)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_manifesto_final.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'position_scores'] = output_manifesto_final['position_scores'].flatten()\n",
    "manifesto_regrouped.loc[:,'pred_sentiment'] = output_manifesto_final['pred_sentiment']\n",
    "manifesto_regrouped.loc[:,'pred_sentiment_name'] = manifesto_regrouped.pred_sentiment.map(name_sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.to_csv('results/datasets/manifesto_full_scaled.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute position scores\n",
    "output_coalition_final = scale_func(coalition_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.loc[:,'position_scores'] = output_coalition_final['position_scores'].flatten()\n",
    "coalition_regrouped.loc[:,'pred_sentiment'] = output_coalition_final['pred_sentiment']\n",
    "coalition_regrouped.loc[:,'pred_sentiment_name'] = coalition_regrouped.pred_sentiment.map(name_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.to_csv('results/datasets/coalition_full_scaled.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create released dataset (position scores by country-party-election)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  =['country','party', 'election','topic','cs_mean_score', 'cs_se_score']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for name, group in manifesto_regrouped.groupby(['country','party','election','topic']):\n",
    "    mean_score = group['position_scores'].mean()\n",
    "    se_score = group['position_scores'].std()/np.sqrt(len(group))\n",
    "    df_temp = pd.DataFrame([[str(group.iloc[0,group.columns.get_loc('country')]),\n",
    "                             str(group.iloc[0,group.columns.get_loc('party')]), \n",
    "                    str(group.iloc[0,group.columns.get_loc('election')]), \n",
    "                    str(group.iloc[0,group.columns.get_loc('topic')]),\n",
    "               mean_score, se_score]], columns = columns)\n",
    "    df = (df_temp if df.empty else pd.concat([df, df_temp], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/datasets/contextscale_manifesto_dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  =['country', 'year','topic','cs_mean_score', 'cs_se_score']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for name, group in coalition_regrouped.groupby(['country','year','topic']):\n",
    "    mean_score = group['position_scores'].mean()\n",
    "    se_score = group['position_scores'].std()/np.sqrt(len(group))\n",
    "    df_temp = pd.DataFrame([[str(group.iloc[0,group.columns.get_loc('country')]),\n",
    "                    str(group.iloc[0,group.columns.get_loc('year')]), \n",
    "                    str(group.iloc[0,group.columns.get_loc('topic')]),\n",
    "               mean_score, se_score]], columns = columns)\n",
    "    df = (df_temp if df.empty else pd.concat([df, df_temp], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/datasets/contextscale_coalition_dataset.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ai-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
