{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4k3dCezyXmXQ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dPi54JU9XmXR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, BertModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from utils.functions import group_texts, sentiment_code, topic_code,party_deu, clean_text_loop, copy_weights, sentiment_code_coalition, topic_code_coalition\n",
    "from utils.functions import train_loop, eval_loop, tokenize_function, cmp_scale, scale_func, d2v_reduct, check_weights_similar, compare_architectures, get_architecture_details, recode_tw\n",
    "from utils.models import ContextScalePrediction, corpusIterator, phraseIterator\n",
    "from safetensors.torch import load_file, save_file\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import nltk\n",
    "#nltk.download('stopwords') ## Remove comments and do it once if you haven't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mDclkfIWZcwv",
    "outputId": "769a0b89-1e46-4b79-c424-cb6022cd4971"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX PRO 6000 Blackwell Workstation Edition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "device = torch.device('cuda')\n",
    "torch.cuda.get_device_name(device=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULX0gK7mg6d3",
    "outputId": "bdbd3c77-e5c0-46f3-cb41-c78bdbbbd4ab"
   },
   "outputs": [],
   "source": [
    "## Pseudo-randomness for reproducibility\n",
    "seed_val = 1234\n",
    "torch.manual_seed(seed_val)\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small test of BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = 'I went to the river bank'\n",
    "sentence_b = 'I went to the bank by the river'\n",
    "tok_a = tokenizer(sentence_a, return_tensors='pt')\n",
    "tok_b = tokenizer(sentence_b, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs_a = model(**tok_a)\n",
    "    outputs_b = model(**tok_b)\n",
    "# Extract word embeddings from the last hidden layer\n",
    "last_hidden_states_a = outputs_a.last_hidden_state\n",
    "last_hidden_states_b = outputs_b.last_hidden_state\n",
    "\n",
    "# Extract the word embedding for the first token (CLS token)\n",
    "word_embedding_a = last_hidden_states_a[:, -2, :] ## 0 is the CLS token, river is the last token\n",
    "word_embedding_b = last_hidden_states_b[:, 5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(word_embedding_a.numpy(), word_embedding_b.numpy()).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "b41aechYXmXT"
   },
   "source": [
    "# Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qB4dt7BNuojT"
   },
   "outputs": [],
   "source": [
    "manifesto = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes.csv\"), encoding=\"utf-8\", dtype = {2: 'str', 18:'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto = manifesto[(manifesto.cmp_code.notna()) & ~(manifesto.cmp_code.isin(['H']))].reset_index(drop=True)\n",
    "len(manifesto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto['sentiment'] = manifesto['cmp_code'].apply(sentiment_code)\n",
    "manifesto['topic'] = manifesto['cmp_code'].apply(topic_code)\n",
    "manifesto['election'] = manifesto['date'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_result = manifesto.groupby(['topic', 'sentiment', 'cmp_code']).size().reset_index(name='count')\n",
    "grouped_result.to_csv('data/temps/categorization_table.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto[manifesto.topic==\"Military\"])/len(manifesto)*100 ## minority group: 1.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = manifesto['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev, mean\n",
    "## Before\n",
    "seq_len = [len(i.split()) for i in texts]\n",
    "seq_len_mean = mean(seq_len)\n",
    "seq_len_std = stdev(seq_len)\n",
    "seq_len_max = max(seq_len)\n",
    "seq_len_min = min(seq_len)\n",
    "print('Mean length (word) is: {}'.format(seq_len_mean))\n",
    "print('Std length (word) is: {}'.format(seq_len_std))\n",
    "print('Min length (word) is: {}'.format(seq_len_min))\n",
    "print('Max length (word) is: {}'.format(seq_len_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(manifesto, \n",
    "                      ['countryname','election','party','cmp_code'], 'text', \n",
    "                      max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped = pd.DataFrame(results)\n",
    "manifesto_regrouped = manifesto_regrouped.explode('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = manifesto_regrouped['labels'].str.split(';', expand=True)\n",
    "manifesto_regrouped = pd.concat([manifesto_regrouped, df_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.columns = ['text', 'idx', 'country','election', 'party', 'cmp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'sentiment'] = manifesto_regrouped['cmp_code'].apply(sentiment_code)\n",
    "manifesto_regrouped.loc[:,'topic'] = manifesto_regrouped['cmp_code'].apply(topic_code)\n",
    "manifesto_regrouped = manifesto_regrouped.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = manifesto_regrouped['text'].tolist()\n",
    "from statistics import stdev, mean\n",
    "## Before\n",
    "seq_len = [len(i.split()) for i in texts]\n",
    "seq_len_mean = mean(seq_len)\n",
    "seq_len_std = stdev(seq_len)\n",
    "seq_len_max = max(seq_len)\n",
    "seq_len_min = min(seq_len)\n",
    "print('Mean length (word) is: {}'.format(seq_len_mean))\n",
    "print('Std length (word) is: {}'.format(seq_len_std))\n",
    "print('Min length (word) is: {}'.format(seq_len_min))\n",
    "print('Max length (word) is: {}'.format(seq_len_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.to_csv('data/temps/manifesto_regrouped.csv', encoding='utf-8', index=False)\n",
    "manifesto.to_csv('data/temps/manifesto.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto = pd.read_csv('data/temps/manifesto.csv', encoding='utf-8', dtype={2:'str',18: 'str'})\n",
    "manifesto_regrouped = pd.read_csv('data/temps/manifesto_regrouped.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced = manifesto_regrouped[['topic','sentiment','text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base' \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced['topic_sentiment'] = manifesto_reduced['topic'] + '_' + manifesto_reduced['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679113b3a49b4e5090e7e85f086e988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/337412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c674fc88c92d4862bc368c5805b0a8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/337412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c00ce79b1eb4b6385c7194067ea4fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/337412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_reduced)\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic_sentiment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save class labels\n",
    "import pickle\n",
    "topic_labels = manifesto_dataset.features['topic'].names\n",
    "file_path = 'data/temps/topic_labels'\n",
    "with open(file_path, 'wb') as fp:\n",
    "    pickle.dump(topic_labels, fp)\n",
    "\n",
    "sentiment_labels = manifesto_dataset.features['sentiment'].names\n",
    "file_path = 'data/temps/sentiment_labels'\n",
    "with open(file_path, 'wb') as fp:\n",
    "    pickle.dump(sentiment_labels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = manifesto_dataset.train_test_split(test_size=0.1, stratify_by_column='topic_sentiment', seed=seed_val)\n",
    "train_eval = train_test['train'].train_test_split(test_size=0.3, stratify_by_column='topic_sentiment', seed=seed_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 212569\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 33742\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['topic', 'sentiment', 'text', 'topic_sentiment'],\n",
       "        num_rows: 91101\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_datasets = DatasetDict({\n",
    "    'train': train_eval['train'],\n",
    "    'test': train_test['test'],\n",
    "    'eval': train_eval['test']\n",
    "})\n",
    "manifesto_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf28f5671756464dbce5fbfca7d2b462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/212569 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a17dc9738214d9c937474d1cabee227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33742 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f97e437d80e4c12b8132d688dcd241d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['topic', 'sentiment', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = manifesto_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text', 'topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16, shuffle=False, collate_fn = data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_datasets['eval'], batch_size=16, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Ensemble Training and Uncertainty Estimation\n",
    "\n",
    "This section implements deep ensemble training with uncertainty estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new uncertainty module\n",
    "from utils.uncertainty import (\n",
    "    ensemble_inference,\n",
    "    load_ensemble_models,\n",
    "    save_ensemble_results,\n",
    "    create_ensemble_summary_dataframe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for ensemble training and uncertainty estimation\n",
    "ENSEMBLE_CONFIG = {\n",
    "    'num_models': 5,  # Number of ensemble members\n",
    "    'beta': 1.0,      # Beta parameter for exponential position score\n",
    "    'n_epochs': 5,    # Epochs per model\n",
    "    'lr': 2e-5,       # Learning rate\n",
    "    'save_dir': 'results/models/ensemble',\n",
    "    'model_prefix': 'model_ensemble'\n",
    "}\n",
    "\n",
    "print(\"Ensemble Configuration:\")\n",
    "for key, value in ENSEMBLE_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model factory function for ensemble training\n",
    "num_topics = len(set(manifesto_dataset['topic']))\n",
    "num_sentiments = len(set(manifesto_dataset['sentiment']))\n",
    "def create_model():\n",
    "    \"\"\"Factory function to create a new model instance for ensemble training.\"\"\"\n",
    "    return ContextScalePrediction(\n",
    "        roberta_model=model_name, \n",
    "        num_topics=num_topics, \n",
    "        num_sentiments=num_sentiments,\n",
    "        lora=False,\n",
    "        use_shared_attention=True  # Using shared attention architecture\n",
    "    )\n",
    "\n",
    "print(\"Model factory function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble inference on the test set\n",
    "\n",
    "Training is done using train.py script. Here we implement ensemble inference on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate checkpoint paths for the ensemble models trained with different splits\n",
    "checkpoint_paths_splits = [\n",
    "    os.path.join(ENSEMBLE_CONFIG['save_dir'], f\"{ENSEMBLE_CONFIG['model_prefix']}_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "print(\"Checkpoint paths for split-based ensemble:\")\n",
    "for i, path in enumerate(checkpoint_paths_splits):\n",
    "    print(f\"  Model {i}: {path}\")\n",
    "\n",
    "# Load the ensemble models\n",
    "ensemble_models = load_ensemble_models(\n",
    "    model_factory=create_model,\n",
    "    checkpoint_paths=checkpoint_paths_splits,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ensemble inference with uncertainty estimation\n",
    "print(\"Performing ensemble inference with uncertainty estimation...\")\n",
    "print(f\"Using beta = {ENSEMBLE_CONFIG['beta']} for exponential position score computation\")\n",
    "print(\"The ensemble will compute:\")\n",
    "print(\"  - Mean position scores across all 5 models\")\n",
    "print(\"  - Position score variance for each text sequence\")\n",
    "print(\"  - Epistemic uncertainty (model disagreement)\")\n",
    "print(\"  - Aleatoric uncertainty (inherent data uncertainty)\")\n",
    "\n",
    "ensemble_results = ensemble_inference(\n",
    "    models=ensemble_models,\n",
    "    dataloader=test_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=True\n",
    ")\n",
    "\n",
    "print(f\"\\nEnsemble inference completed!\")\n",
    "print(f\"Final position scores are the mean of {len(ensemble_models)} models\")\n",
    "print(f\"Position score variance included for each sequence\")\n",
    "\n",
    "save_ensemble_results(\n",
    "    ensemble_results,\n",
    "    'results/datasets/ensemble_manifesto_results.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge back to original test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load ensemble results with pickle\n",
    "file_path = 'results/datasets/ensemble_manifesto_results.pkl'\n",
    "with open(file_path, \"rb\") as file:\n",
    "    ensemble_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_summary_df = create_ensemble_summary_dataframe(ensemble_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge ensemble_summary_df with original test dataset for analysis\n",
    "test_dataset = manifesto_datasets['test'].to_pandas().reset_index(drop=True)\n",
    "merged_df = pd.concat([test_dataset, ensemble_summary_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to csv\n",
    "merged_df.to_csv('results/datasets/ensemble_test_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on the entire dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for ensemble training and uncertainty estimation\n",
    "ENSEMBLE_CONFIG = {\n",
    "    'num_models': 5,  # Number of ensemble members\n",
    "    'beta': 1.0,      # Beta parameter for exponential position score\n",
    "    'n_epochs': 5,    # Epochs per model\n",
    "    'lr': 2e-5,       # Learning rate\n",
    "    'save_dir': 'results/models/ensemble_scaling',\n",
    "    'model_prefix': 'model_ensemble'\n",
    "}\n",
    "\n",
    "print(\"Ensemble Configuration:\")\n",
    "for key, value in ENSEMBLE_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model factory function for ensemble training\n",
    "num_topics = len(set(manifesto_dataset['topic']))\n",
    "num_sentiments = len(set(manifesto_dataset['sentiment']))\n",
    "def create_model():\n",
    "    \"\"\"Factory function to create a new model instance for ensemble training.\"\"\"\n",
    "    return ContextScalePrediction(\n",
    "        roberta_model=model_name, \n",
    "        num_topics=num_topics, \n",
    "        num_sentiments=num_sentiments,\n",
    "        lora=False,\n",
    "        use_shared_attention=True  # Using shared attention architecture\n",
    "    )\n",
    "\n",
    "print(\"Model factory function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate checkpoint paths for the ensemble models trained with different splits\n",
    "checkpoint_paths_splits = [\n",
    "    os.path.join(ENSEMBLE_CONFIG['save_dir'], f\"{ENSEMBLE_CONFIG['model_prefix']}_{i}.safetensors\")\n",
    "    for i in range(5)\n",
    "]\n",
    "\n",
    "print(\"Checkpoint paths for split-based ensemble:\")\n",
    "for i, path in enumerate(checkpoint_paths_splits):\n",
    "    print(f\"  Model {i}: {path}\")\n",
    "\n",
    "# Load the ensemble models\n",
    "ensemble_models = load_ensemble_models(\n",
    "    model_factory=create_model,\n",
    "    checkpoint_paths=checkpoint_paths_splits,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = manifesto_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])\n",
    "full_dataset.set_format(\"torch\")\n",
    "full_dataloader = DataLoader(full_dataset, batch_size=64, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "full_ensemble_results = ensemble_inference(\n",
    "    models=ensemble_models,\n",
    "    dataloader=full_dataloader,\n",
    "    device=device,\n",
    "    beta=1.0,\n",
    "    topic_label='topic',\n",
    "    sentiment_label='sentiment',\n",
    "    use_ground_truth_topic=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation: Model architecture comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_base/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_base'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_base, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_base['res_table_sentiment'].to_csv('results/classification results/base_sentiment.csv', index=False)\n",
    "outputs_base['res_table_topic'].to_csv('results/classification results/base_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with simple flow of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_simple_flow=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_sf/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_sf'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_sf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sf['res_table_sentiment'].to_csv('results/classification results/sf_sentiment.csv', index=False)\n",
    "outputs_sf['res_table_topic'].to_csv('results/classification results/sf_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with shared attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_shared_attention=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_sa/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_sa'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_sa, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_sa['res_table_sentiment'].to_csv('results/classification results/sa_sentiment.csv', index=False)\n",
    "outputs_sa['res_table_topic'].to_csv('results/classification results/sa_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with dynamic gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_dynamic_gating=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_dg/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg = scale_func(test_dataloader, \n",
    "               model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_dg'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_dg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dg['res_table_sentiment'].to_csv('results/classification results/dg_sentiment.csv', index=False)\n",
    "outputs_dg['res_table_topic'].to_csv('results/classification results/dg_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on test languages unseen during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_test = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes_test.csv\"), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_test = manifesto_test[(manifesto_test.cmp_code.notna()) & ~(manifesto_test.cmp_code == 'H')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_test['sentiment'] = manifesto['cmp_code'].apply(sentiment_code)\n",
    "manifesto_test['topic'] = manifesto['cmp_code'].apply(topic_code)\n",
    "manifesto_test['election'] = manifesto['date'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(manifesto_test, \n",
    "                      ['countryname','election','party','cmp_code'], 'text', \n",
    "                      max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped = pd.DataFrame(results)\n",
    "manifesto_regrouped = manifesto_regrouped.explode('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = manifesto_regrouped['labels'].str.split(';', expand=True)\n",
    "manifesto_regrouped = pd.concat([manifesto_regrouped, df_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.columns = ['text', 'country_election_party_code', 'country','election', 'party', 'cmp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'sentiment'] = manifesto_regrouped['cmp_code'].apply(sentiment_code)\n",
    "manifesto_regrouped.loc[:,'topic'] = manifesto_regrouped['cmp_code'].apply(topic_code)\n",
    "manifesto_regrouped = manifesto_regrouped.drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced = manifesto_regrouped[['topic','sentiment','text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_reduced)\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = manifesto_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "pred_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "scaling_model = ContextScalePrediction(roberta_model=model_name, num_topics=num_topics, num_sentiments=num_sentiments,lora=False,\n",
    "                                       use_shared_attention=True).to(device)\n",
    "\n",
    "loaded_tensors = load_file('results/models/manifesto_ContextScalePrediction_main/model.safetensors')\n",
    "scaling_model.load_state_dict(loaded_tensors)\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl = scale_func(pred_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl['res_table_topic'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl['res_table_sentiment'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_dl'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_dl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl['res_table_sentiment'].to_csv('results/classification results/dl_sentiment.csv', index=False)\n",
    "outputs_dl['res_table_topic'].to_csv('results/classification results/dl_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model using only 10% of labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_reduced['topic_sentiment'] = manifesto_reduced['topic'] + '_' + manifesto_reduced['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_reduced)\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic_sentiment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = manifesto_dataset.train_test_split(test_size=0.9, stratify_by_column='topic_sentiment', seed=seed_val)\n",
    "train_eval = train_test['train'].train_test_split(test_size=0.3, stratify_by_column='topic_sentiment', seed=seed_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_datasets = DatasetDict({\n",
    "    'train': train_eval['train'],\n",
    "    'test': train_test['test'],\n",
    "    'eval': train_eval['test']\n",
    "})\n",
    "manifesto_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = manifesto_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text', 'topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16, shuffle=False, collate_fn = data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_datasets['eval'], batch_size=16, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_shared_attention=True).to(device)\n",
    "loaded_tensors = load_file('results/models/manifesto_ContextScalePrediction_main/model.safetensors')\n",
    "model.load_state_dict(loaded_tensors)\n",
    "scaling_model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sent = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    timing_log = train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sent, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "    eval_loop(eval_dataloader, model, device, criterion_sent, criterion_topic, sentiment_var='sentiment', topic_var='topic')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/manifesto_ContextScalePrediction_dl_10/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "scaling_model = ContextScalePrediction(roberta_model=model_name, num_topics=num_topics, num_sentiments=num_sentiments,lora=False,\n",
    "                                       use_shared_attention=True).to(device)\n",
    "\n",
    "loaded_tensors = load_file('results/models/manifesto_ContextScalePrediction_dl_10/model.safetensors')\n",
    "scaling_model.load_state_dict(loaded_tensors)\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10 = scale_func(test_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10['res_table_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10['res_table_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_dl_10'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_dl_10, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10['res_table_sentiment'].to_csv('results/classification results/dl_10_sentiment.csv', index=False)\n",
    "outputs_dl_10['res_table_topic'].to_csv('results/classification results/dl_10_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dl_10_all = scale_func(pred_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'position_scores'] = outputs_dl_10_all['position_scores'].flatten()\n",
    "manifesto_regrouped.loc[:,'pred_sentiment_index'] = outputs_dl_10_all['pred_sentiment']\n",
    "manifesto_regrouped.loc[:,'pred_sentiment'] = manifesto_regrouped.pred_sentiment_index.map(name_sentiment_dict)\n",
    "manifesto_regrouped.loc[:,'pred_topic_index'] = outputs_dl_10_all['pred_topics']\n",
    "manifesto_regrouped.loc[:,'pred_topic'] = manifesto_regrouped.pred_topic_index.map(name_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.to_csv('data/py_outputs/manifesto_dl_10_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COALITIONAGREE, same coding style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitionagree = pd.read_csv('data/r_outputs/coalitionagree_texts.csv', encoding='utf-8', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalitionagree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(coalitionagree, ['country','cabinet_year','category2','category3'], 'sentence', max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped = pd.DataFrame(results)\n",
    "coalition_regrouped = coalition_regrouped.explode('text').reset_index(drop=True)\n",
    "df_cols = coalition_regrouped['labels'].str.split(';', expand=True)\n",
    "coalition_regrouped = pd.concat([coalition_regrouped, df_cols], axis=1)\n",
    "coalition_regrouped.columns =['text','labels', 'country','year', 'cmp_short','cmp_long']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped['sentiment'] = coalition_regrouped.apply(lambda x: sentiment_code_coalition(x['cmp_short'], x['cmp_long']), axis=1)\n",
    "coalition_regrouped['topic'] = coalition_regrouped['cmp_short'].apply(topic_code_coalition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.groupby(['topic','sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.to_csv('data/temps/coalitionagree_regrouped_processed.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_reduced = coalition_regrouped[['sentiment', 'topic','text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_dataset = Dataset.from_pandas(cagree_reduced)\n",
    "cagree_dataset = cagree_dataset.class_encode_column('sentiment')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = cagree_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "scaling_model = ContextScalePrediction(roberta_model=model_name, num_topics=num_topics, num_sentiments=num_sentiments,lora=False,\n",
    "                                       use_shared_attention=True).to(device)\n",
    "\n",
    "loaded_tensors = load_file('results/models/manifesto_ContextScalePrediction_main/model.safetensors')\n",
    "scaling_model.load_state_dict(loaded_tensors)\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_test = scale_func(pred_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_test['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_test['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_ca_test'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_ca_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_test['res_table_sentiment'].to_csv('results/classification results/cagree_noft_sentiment.csv', index=False)\n",
    "outputs_ca_test['res_table_topic'].to_csv('results/classification results/cagree_noft_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10% supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_reduced.loc[:,'topic_sentiment'] = cagree_reduced.loc[:,'topic'] + '_' + cagree_reduced.loc[:,'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_dataset = Dataset.from_pandas(cagree_reduced)\n",
    "cagree_dataset = cagree_dataset.class_encode_column('sentiment')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = cagree_dataset.train_test_split(test_size=0.9, stratify_by_column='topic_sentiment', seed=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_datasets = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test'],\n",
    "})\n",
    "cagree_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = cagree_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text','topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16, shuffle=False, collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "num_topics = len(set(manifesto_reduced['topic']))\n",
    "num_sentiments = len(set(manifesto_reduced['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_shared_attention=True).to(device)\n",
    "loaded_tensors = load_file('results/models/manifesto_ContextScalePrediction_main/model.safetensors')\n",
    "model.load_state_dict(loaded_tensors)\n",
    "scaling_model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) ## Recommended for LoRA. Without LoRA, can use 2e-5 instead.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion_sentiment = nn.CrossEntropyLoss()\n",
    "criterion_topic =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    train_loop(train_dataloader, model,optimizer, scheduler, device, criterion_sentiment, criterion_topic, sentiment_var='sentiment',\n",
    "               topic_var='topic', timing_log=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/coalitionagree_ContextScalePrediction_10/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "num_topics = 12\n",
    "num_sentiments = 3\n",
    "scaling_model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_shared_attention=True).to(device)\n",
    "loaded_tensors = load_file('results/models/coalitionagree_ContextScalePrediction_10/model.safetensors')\n",
    "scaling_model.load_state_dict(loaded_tensors)\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10 = scale_func(test_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_ca_10'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_ca_10, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10['res_table_sentiment'].to_csv('results/classification results/cagree_10ft_sentiment.csv', index=False)\n",
    "outputs_ca_10['res_table_topic'].to_csv('results/classification results/cagree_10ft_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the entire corpus with 10% training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_dataset = Dataset.from_pandas(cagree_reduced)\n",
    "cagree_dataset = cagree_dataset.class_encode_column('sentiment')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = cagree_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text', 'topic_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=False, collate_fn = data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10_all = scale_func(pred_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10_all['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_10_all['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_ca_10_all'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_ca_10, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.loc[:,'position_scores'] = outputs_ca_10_all['position_scores'].flatten()\n",
    "coalition_regrouped.loc[:,'pred_sentiment_index'] = outputs_ca_10_all['pred_sentiment']\n",
    "coalition_regrouped.loc[:,'pred_sentiment'] = coalition_regrouped.pred_sentiment_index.map(name_sentiment_dict)\n",
    "coalition_regrouped.loc[:,'pred_topic_index'] = outputs_ca_10_all['pred_topics']\n",
    "coalition_regrouped.loc[:,'pred_topic'] = coalition_regrouped.pred_topic_index.map(name_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.to_csv('data/py_outputs/cagree_10ft_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the COALITIONAGREE corpus with full labels information (for official release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped = pd.read_csv('data/temps/coalitionagree_regrouped_processed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_reduced = coalition_regrouped[['sentiment', 'topic','text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagree_dataset = Dataset.from_pandas(cagree_reduced)\n",
    "cagree_dataset = cagree_dataset.class_encode_column('sentiment')\n",
    "cagree_dataset = cagree_dataset.class_encode_column('topic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "num_topics = 12\n",
    "num_sentiments = 3\n",
    "model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_shared_attention=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = cagree_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "tokenized_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "pred_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=False, collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) ## Recommended for LoRA. Without LoRA, can use 2e-5 instead.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion =  nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    train_loop(train_dataloader, model,optimizer, scheduler, device, criterion, criterion, sentiment_var='sentiment',\n",
    "               topic_var='topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/coalitionagree_ContextScalePrediction_full/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "num_topics = 12\n",
    "num_sentiments = 3\n",
    "scaling_model = ContextScalePrediction(roberta_model=model_name, \n",
    "                               num_topics=num_topics, \n",
    "                               num_sentiments=num_sentiments,\n",
    "                               lora=False,\n",
    "                               use_shared_attention=True).to(device)\n",
    "loaded_tensors = load_file('results/models/coalitionagree_ContextScalePrediction_full/model.safetensors')\n",
    "scaling_model.load_state_dict(loaded_tensors)\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_all = scale_func(pred_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_all['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_all['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_ca_all'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_ca_all, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ca_all['res_table_sentiment'].to_csv('results/classification results/cagree_all_sentiment.csv', index=False)\n",
    "outputs_ca_all['res_table_topic'].to_csv('results/classification results/cagree_all_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.loc[:,'position_scores'] = outputs_ca_all['position_scores'].flatten()\n",
    "coalition_regrouped.loc[:,'pred_sentiment_index'] = outputs_ca_all['pred_sentiment']\n",
    "coalition_regrouped.loc[:,'pred_sentiment'] = coalition_regrouped.pred_sentiment_index.map(name_sentiment_dict)\n",
    "coalition_regrouped.loc[:,'pred_topic_index'] = outputs_ca_all['pred_topics']\n",
    "coalition_regrouped.loc[:,'pred_topic'] = coalition_regrouped.pred_topic_index.map(name_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.to_csv('data/py_outputs/cagree_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting to twitter data (Sentiment is not Stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptation training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_trump = pd.read_csv('data/MOTN/MOTN_responses_groundtruth.csv', encoding='utf-8')\n",
    "tw_kav = pd.read_csv('data/MOTN/kavanaugh_tweets_groundtruth.csv', encoding='utf-8')\n",
    "tw_wm = pd.read_csv('data/MOTN/WM_tweets_groundtruth.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_kav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_wm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_trump = tw_trump[['edits_clean_text','trump_stance_auto']].copy()\n",
    "tw_trump = tw_trump.rename(columns={'edits_clean_text': 'text', 'trump_stance_auto': 'stance'})\n",
    "tw_trump['topic'] = 'trump'\n",
    "tw_kav = tw_kav[['text', 'stance']].copy()\n",
    "tw_kav['topic'] = 'kavanaugh'\n",
    "tw_wm = tw_wm[['text','stance']].copy()\n",
    "tw_wm['topic'] = 'women march'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df = pd.concat([tw_trump, tw_kav,tw_wm]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df.loc[:,'lr'] = tw_df.apply(lambda x: recode_tw(x['topic'], x['stance']), axis=1)\n",
    "tw_df.loc[:,'topic_lr'] = tw_df['topic'] + '_' + tw_df['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df.groupby(['topic','lr']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_dataset = Dataset.from_pandas(tw_df[['text','lr','topic', 'topic_lr']].copy())\n",
    "tw_dataset = tw_dataset.class_encode_column('lr')\n",
    "tw_dataset = tw_dataset.class_encode_column('topic')\n",
    "tw_dataset = tw_dataset.class_encode_column('topic_lr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = tw_dataset.train_test_split(test_size=0.9, stratify_by_column='topic_lr',seed=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_datasets = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test'],\n",
    "})\n",
    "tw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tw_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length':512}, \n",
    "                                            remove_columns=['text', 'topic_lr'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16, shuffle=False, collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "source_model = ContextScalePrediction(roberta_model=model_name, num_topics=12, num_sentiments=3,lora=False, use_shared_attention=True).to(device)\n",
    "loaded_tensors = load_file('results/models/manifesto_ContextScalePrediction_main/model.safetensors')\n",
    "source_model.load_state_dict(loaded_tensors)\n",
    "model=None\n",
    "scaling_model=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = ContextScalePrediction(roberta_model=model_name, num_topics=3, num_sentiments=2,lora=False, use_shared_attention=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture1 = get_architecture_details(target_model)\n",
    "architecture2 = get_architecture_details(source_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_architectures(architecture1, architecture2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_weights(source_model, target_model, patterns=('topic','sentiment'), freeze_copied=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_weights_similar(source_model, target_model, patterns=('topic','sentiment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(target_model.parameters(), lr=2e-5) ## Recommended for LoRA. Without LoRA, can use 2e-5 instead.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nullify existing models (if any)\n",
    "scaling_model=None\n",
    "source_model=None\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    train_loop(train_dataloader, target_model,optimizer, scheduler, device, criterion_sent=criterion, criterion_topic=criterion, sentiment_var='lr', topic_var='topic', timing_log=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = target_model.state_dict()\n",
    "save_file(state_dict, 'results/models/tw_ContextScalePrediction/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10 = scale_func(test_dataloader, \n",
    "               target_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='lr', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_tw_10'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_tw_10, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10['res_table_sentiment'].to_csv('results/classification results/tw_10ft_sentiment.csv', index=False)\n",
    "outputs_tw_10['res_table_topic'].to_csv('results/classification results/tw_10ft_topic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pre-trained models\n",
    "target_model = ContextScalePrediction(roberta_model=model_name, num_topics=3, num_sentiments=2,lora=False, use_shared_attention=True).to(device)\n",
    "loaded_tensors = load_file('results/models/tw_ContextScalePrediction/model.safetensors')\n",
    "target_model.load_state_dict(loaded_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tw_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text','topic_lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataloader = DataLoader(tokenized_dataset, batch_size=16, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10_all = scale_func(pred_dataloader, \n",
    "               target_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='lr', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10_all['res_table_sentiment']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tw_10_all['res_table_topic']['f1'].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/outputs_tw_10_all'\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(outputs_tw_10_all, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names = tw_dataset.features['lr'].names\n",
    "name_sentiment_dict = dict([(x,y) for x,y in enumerate(list_names)])\n",
    "list_names = tw_dataset.features['topic'].names\n",
    "name_topic_dict = dict([(x,y) for x,y in enumerate(list_names)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df.loc[:,'position_scores'] = outputs_tw_10_all['position_scores'].flatten()\n",
    "tw_df.loc[:,'pred_sentiment_index'] = outputs_tw_10_all['pred_sentiment']\n",
    "tw_df.loc[:,'pred_sentiment'] = tw_df.pred_sentiment_index.map(name_sentiment_dict)\n",
    "tw_df.loc[:,'pred_topic_index'] = outputs_tw_10_all['pred_topics']\n",
    "tw_df.loc[:,'pred_topic'] = tw_df.pred_topic_index.map(name_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df.to_csv('data/py_outputs/tw_10_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_d2v = pd.read_csv('data/temps/manifesto.csv', encoding='utf-8', dtype={'cmp_code':'str', 'is_copy_of':'str'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = clean_text_loop(manifesto_d2v, 'countryname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_d2v.loc[:,'text_cleaned'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_d2v.loc[:,'party_election'] = manifesto_d2v.party.astype(str).str.cat(manifesto_d2v[['election']].astype(str).values, sep='_')\n",
    "manifesto_d2v.loc[:,'country_party_election'] = manifesto_d2v.countryname.str.cat(manifesto_d2v[['party','election']].astype(str).values, sep='_')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - original approach by R&C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-level dataframes\n",
    "country_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_d2v['countryname'].unique()\n",
    "\n",
    "# Loop through each country and process separately\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_d2v[manifesto_d2v['countryname'] == country]\n",
    "    \n",
    "    # Build the corpus iterator for this country's data\n",
    "    outputs_stream = phraseIterator(country_data, 'text_cleaned')\n",
    "    bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "    trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "    \n",
    "    # Create the Doc2Vec model and build vocabulary\n",
    "    model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "    model.build_vocab(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                total_examples=model.corpus_count, epochs=20)\n",
    "    \n",
    "    # Generate embeddings and apply dimensionality reduction\n",
    "    embed_dict = d2v_reduct(model)\n",
    "    df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "    df_d2v.index.name = 'party_election'\n",
    "    df_d2v.reset_index(inplace=True)\n",
    "    pca = PCA(n_components=2, random_state=seed_val)\n",
    "    df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "    df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "    \n",
    "    # Split the 'party_election' label into separate columns\n",
    "    df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "    df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "    df_d2v['country'] = country  # Add country column for merging later\n",
    "    \n",
    "    # Append the country-level dataframe to the list\n",
    "    country_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_gen_party_election.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_d2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_germany = final_df_d2v[final_df_d2v.country == 'Germany'].copy()\n",
    "d2v_germany.loc[:,'party_name'] = d2v_germany['party'].astype(str).apply(party_deu)\n",
    "d2v_germany = d2v_germany[d2v_germany.party_name != 'Other'].reset_index(drop=True)\n",
    "d2v_germany.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in d2v_germany.groupby('party_name'):\n",
    "    ax.plot(group.election, group.d2v_d1, marker='o',  ms=4, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d2v.to_csv('data/py_outputs/r&c_gen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - relevant topics\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(manifesto_d2v['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-topic level dataframes\n",
    "country_topic_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_d2v['countryname'].unique()\n",
    "\n",
    "# Loop through each country\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_d2v[manifesto_d2v['countryname'] == country]\n",
    "    country_data = country_data[country_data['topic'].isin(['Environment - Growth', 'Political System', 'Economics',\n",
    "                                                            'European Integration','Labour and Social Welfare',\n",
    "                                                            'Immigration'])]\n",
    "    # Get the unique list of topics within this country\n",
    "    unique_topics = country_data['topic'].unique()\n",
    "    \n",
    "    # Loop through each topic in the country\n",
    "    for topic in unique_topics:\n",
    "        print(f\"Processing topic: {topic}\")\n",
    "\n",
    "        # Filter the dataset for the current country and topic\n",
    "        country_topic_data = country_data[country_data['topic'] == topic]\n",
    "\n",
    "        # Build the corpus iterator for this country's topic-specific data\n",
    "        outputs_stream = phraseIterator(country_topic_data, 'text_cleaned')\n",
    "        bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "        trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "\n",
    "        # Create the Doc2Vec model and build vocabulary\n",
    "        model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "        model.build_vocab(corpusIterator(country_topic_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "\n",
    "        # Train the model\n",
    "        model.train(corpusIterator(country_topic_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                    total_examples=model.corpus_count, epochs=20)\n",
    "\n",
    "        # Generate embeddings and apply dimensionality reduction\n",
    "        embed_dict = d2v_reduct(model)\n",
    "        df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "        df_d2v.index.name = 'party_election'\n",
    "        df_d2v.reset_index(inplace=True)\n",
    "        pca = PCA(n_components=2, random_state=seed_val)\n",
    "        df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "        df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "\n",
    "        # Split the 'party_election' label into separate columns\n",
    "        df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "        df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "        df_d2v['country'] = country  # Add country column\n",
    "        df_d2v['topic'] = topic  # Add topic column\n",
    "\n",
    "        # Append the country-topic-level dataframe to the list\n",
    "        country_topic_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-topic-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_topic_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_party_election_topic.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - Environment Protection\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_ep = manifesto_d2v[manifesto_d2v.cmp_code.isin(['501'])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_ep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-level dataframes\n",
    "country_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_ep['countryname'].unique()\n",
    "\n",
    "# Loop through each country and process separately\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_ep[manifesto_ep['countryname'] == country]\n",
    "    \n",
    "    # Build the corpus iterator for this country's data\n",
    "    outputs_stream = phraseIterator(country_data, 'text_cleaned')\n",
    "    bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "    trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "    \n",
    "    # Create the Doc2Vec model and build vocabulary\n",
    "    model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "    model.build_vocab(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                total_examples=model.corpus_count, epochs=20)\n",
    "    \n",
    "    # Generate embeddings and apply dimensionality reduction\n",
    "    embed_dict = d2v_reduct(model)\n",
    "    df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "    df_d2v.index.name = 'party_election'\n",
    "    df_d2v.reset_index(inplace=True)\n",
    "    pca = PCA(n_components=2, random_state=seed_val)\n",
    "    df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "    df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "    \n",
    "    # Split the 'party_election' label into separate columns\n",
    "    df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "    df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "    df_d2v['country'] = country  # Add country column for merging later\n",
    "    \n",
    "    # Append the country-level dataframe to the list\n",
    "    country_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_ep_party_election.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec scaling - Germany, growth vs anti growth\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_welfare = manifesto_d2v[manifesto_d2v.cmp_code.isin(['504', '505'])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_welfare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the country-level dataframes\n",
    "country_dfs = []\n",
    "\n",
    "# Get the unique list of countries from your data\n",
    "unique_countries = manifesto_welfare['countryname'].unique()\n",
    "\n",
    "# Loop through each country and process separately\n",
    "for country in unique_countries:\n",
    "    print(f\"Processing country: {country}\")\n",
    "    \n",
    "    # Filter the dataset for the current country\n",
    "    country_data = manifesto_welfare[manifesto_welfare['countryname'] == country]\n",
    "    \n",
    "    # Build the corpus iterator for this country's data\n",
    "    outputs_stream = phraseIterator(country_data, 'text_cleaned')\n",
    "    bigram = Phraser(Phrases(outputs_stream, min_count=1, threshold=5))\n",
    "    trigram = Phrases(bigram[outputs_stream], min_count=1, threshold=5)\n",
    "    \n",
    "    # Create the Doc2Vec model and build vocabulary\n",
    "    model = Doc2Vec(vector_size=500, window=6, min_count=1, workers=16, epochs=20, seed=seed_val)\n",
    "    model.build_vocab(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'))\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(corpusIterator(country_data, bigram=bigram, trigram=trigram, text='text_cleaned', labels='party_election'),\n",
    "                total_examples=model.corpus_count, epochs=20)\n",
    "    \n",
    "    # Generate embeddings and apply dimensionality reduction\n",
    "    embed_dict = d2v_reduct(model)\n",
    "    df_d2v = pd.DataFrame.from_dict(embed_dict).transpose()\n",
    "    df_d2v.index.name = 'party_election'\n",
    "    df_d2v.reset_index(inplace=True)\n",
    "    pca = PCA(n_components=2, random_state=seed_val)\n",
    "    df_d2v[['d2v_d1', 'd2v_d2']] = pca.fit_transform(df_d2v.iloc[:, 1:])\n",
    "    df_d2v = df_d2v[['party_election', 'd2v_d1', 'd2v_d2']]\n",
    "    \n",
    "    # Split the 'party_election' label into separate columns\n",
    "    df_d2v[['party', 'election']] = df_d2v['party_election'].str.split('_', expand=True)\n",
    "    df_d2v.loc[:, 'election'] = df_d2v['election'].astype(int)\n",
    "    df_d2v['country'] = country  # Add country column for merging later\n",
    "    \n",
    "    # Append the country-level dataframe to the list\n",
    "    country_dfs.append(df_d2v)\n",
    "\n",
    "# Merge all country-level datasets into a single dataframe\n",
    "final_df_d2v = pd.concat(country_dfs, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df_d2v.to_csv('data/py_outputs/r&c_welfare_party_election.csv', index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(final_df_d2v.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale position scores for all countries (released dataset + model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain for the entire dataset with all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_org = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes.csv\"), encoding=\"utf-8\", dtype={2:'str',18:'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_other = pd.read_csv(os.path.join(\"data\", \"r_outputs\",\"pulled_manifestoes_test.csv\"), encoding=\"utf-8\", dtype={2:'str',18:'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_org_cleaned = manifesto_org.dropna(axis=1, how='all')\n",
    "manifesto_other_cleaned = manifesto_other.dropna(axis=1, how='all')\n",
    "manifesto_full = pd.concat([manifesto_org_cleaned, manifesto_other_cleaned]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manifesto_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full = manifesto_full[(manifesto_full.cmp_code.notna()) & ~(manifesto_full.cmp_code == 'H')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full['sentiment'] = manifesto_full['cmp_code'].apply(sentiment_code)\n",
    "manifesto_full['topic'] = manifesto_full['cmp_code'].apply(topic_code)\n",
    "manifesto_full['election'] = manifesto_full['date'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_full.groupby(['topic'])['sentiment'].value_counts().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = group_texts(manifesto_full, \n",
    "                      ['countryname','election','party','cmp_code'], 'text', \n",
    "                      max_group_factor = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped = pd.DataFrame(results)\n",
    "manifesto_regrouped = manifesto_regrouped.explode('text').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = manifesto_regrouped['labels'].str.split(';', expand=True)\n",
    "manifesto_regrouped = pd.concat([manifesto_regrouped, df_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.columns = ['text', 'country_election_party_code', 'country','election', 'party', 'cmp_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'sentiment'] = manifesto_regrouped['cmp_code'].apply(sentiment_code)\n",
    "manifesto_regrouped.loc[:,'topic'] = manifesto_regrouped['cmp_code'].apply(topic_code)\n",
    "manifesto_regrouped = manifesto_regrouped.drop_duplicates().reset_index(drop=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.to_csv('data/temps/manifesto_regrouped_full_processed.csv', encoding='utf-8', index=False)\n",
    "manifesto_full.to_csv('data/temps/manifesto_full_processed.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped = pd.read_csv('data/temps/coalitionagree_regrouped_processed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:, 'source'] = 'manifestos'\n",
    "coalition_regrouped.loc[:, 'source'] = 'coalition_contracts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.groupby(['topic'])['sentiment'].value_counts().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([manifesto_regrouped[['text','sentiment','topic', 'source']], coalition_regrouped[['text','sentiment','topic','source']]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[:,'topic_sentiment'] = final_df['topic'] + '_' + final_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = Dataset.from_pandas(final_df)\n",
    "final_dataset = final_dataset.class_encode_column('sentiment')\n",
    "final_dataset = final_dataset.class_encode_column('topic')\n",
    "final_dataset = final_dataset.class_encode_column('topic_sentiment')\n",
    "final_dataset = final_dataset.class_encode_column('source')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = final_dataset.train_test_split(test_size=0.1, stratify_by_column='topic_sentiment', seed=seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_datasets = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test']\n",
    "})\n",
    "final_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = final_datasets.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text','topic_sentiment'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True, collate_fn = data_collator)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16, shuffle=False, collate_fn = data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(set(final_df['topic']))\n",
    "num_sentiments = len(set(final_df['sentiment']))\n",
    "model = ContextScalePrediction(roberta_model=model_name, num_topics=12, num_sentiments=3,lora=False, use_shared_attention=True).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "total_steps = len(train_dataloader)*n_epochs\n",
    "warmup = total_steps*0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) ## Recommended for LoRA. Without LoRA, can use 2e-5 instead.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=total_steps, num_warmup_steps=warmup)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    train_loop(train_dataloader, model,optimizer, scheduler, device, criterion, criterion, sentiment_var='sentiment',\n",
    "               topic_var='topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "save_file(state_dict, 'results/models/contextscale_full_released/model.safetensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale manifestos and coalition contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped = pd.read_csv('data/temps/coalitionagree_regrouped_processed.csv', encoding='utf-8')\n",
    "manifesto_regrouped = pd.read_csv('data/temps/manifesto_regrouped_full_processed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 12\n",
    "num_sentiments = 3\n",
    "scaling_model = ContextScalePrediction(roberta_model=model_name, num_topics=12, num_sentiments=3,lora=False, use_shared_attention=True).to(device)\n",
    "\n",
    "model=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tensors = load_file('results/models/contextscale_full_released/model.safetensors')\n",
    "scaling_model.load_state_dict(loaded_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_dataset = Dataset.from_pandas(manifesto_regrouped[['text','topic','sentiment']].copy())\n",
    "coalition_dataset = Dataset.from_pandas(coalition_regrouped[['text','topic','sentiment']].copy())\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('topic') \n",
    "coalition_dataset = coalition_dataset.class_encode_column('topic')\n",
    "manifesto_dataset = manifesto_dataset.class_encode_column('sentiment') \n",
    "coalition_dataset = coalition_dataset.class_encode_column('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_manifesto_dataset = manifesto_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])\n",
    "tokenized_manifesto_dataset.set_format(\"torch\")\n",
    "tokenized_coalition_dataset = coalition_dataset.map(tokenize_function, \n",
    "                                            fn_kwargs={'tokenizer': tokenizer, 'text_var': 'text', 'max_length': 512}, \n",
    "                                            remove_columns=['text'])\n",
    "tokenized_coalition_dataset.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_dataloader = DataLoader(tokenized_manifesto_dataset, batch_size=16, shuffle=False, collate_fn= data_collator)\n",
    "coalition_dataloader = DataLoader(tokenized_coalition_dataset, batch_size=16, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute position scores\n",
    "output_manifesto_final = scale_func(manifesto_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/temps/topic_labels'\n",
    "with open(file_path, 'rb') as fp:\n",
    "    topic_labels = pickle.load(fp)\n",
    "name_topic_dict = dict([(x,y) for x,y in enumerate(topic_labels)])\n",
    "\n",
    "\n",
    "file_path = 'data/temps/sentiment_labels'\n",
    "with open(file_path, 'rb') as fp:\n",
    "    sentiment_labels = pickle.load(fp)\n",
    "name_sentiment_dict = dict([(x,y) for x,y in enumerate(sentiment_labels)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_manifesto_final.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.loc[:,'position_scores'] = output_manifesto_final['position_scores'].flatten()\n",
    "manifesto_regrouped.loc[:,'pred_sentiment'] = output_manifesto_final['pred_sentiment']\n",
    "manifesto_regrouped.loc[:,'pred_sentiment_name'] = manifesto_regrouped.pred_sentiment.map(name_sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifesto_regrouped.to_csv('results/datasets/manifesto_full_scaled.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute position scores\n",
    "output_coalition_final = scale_func(coalition_dataloader, \n",
    "               scaling_model, \n",
    "               device, \n",
    "               topic_label='topic', \n",
    "               sentiment_label='sentiment', \n",
    "               timing_log=True,\n",
    "               use_ground_truth_topic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.loc[:,'position_scores'] = output_coalition_final['position_scores'].flatten()\n",
    "coalition_regrouped.loc[:,'pred_sentiment'] = output_coalition_final['pred_sentiment']\n",
    "coalition_regrouped.loc[:,'pred_sentiment_name'] = coalition_regrouped.pred_sentiment.map(name_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coalition_regrouped.to_csv('results/datasets/coalition_full_scaled.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create released dataset (position scores by country-party-election)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  =['country','party', 'election','topic','cs_mean_score', 'cs_se_score']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for name, group in manifesto_regrouped.groupby(['country','party','election','topic']):\n",
    "    mean_score = group['position_scores'].mean()\n",
    "    se_score = group['position_scores'].std()/np.sqrt(len(group))\n",
    "    df_temp = pd.DataFrame([[str(group.iloc[0,group.columns.get_loc('country')]),\n",
    "                             str(group.iloc[0,group.columns.get_loc('party')]), \n",
    "                    str(group.iloc[0,group.columns.get_loc('election')]), \n",
    "                    str(group.iloc[0,group.columns.get_loc('topic')]),\n",
    "               mean_score, se_score]], columns = columns)\n",
    "    df = (df_temp if df.empty else pd.concat([df, df_temp], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/datasets/contextscale_manifesto_dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  =['country', 'year','topic','cs_mean_score', 'cs_se_score']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for name, group in coalition_regrouped.groupby(['country','year','topic']):\n",
    "    mean_score = group['position_scores'].mean()\n",
    "    se_score = group['position_scores'].std()/np.sqrt(len(group))\n",
    "    df_temp = pd.DataFrame([[str(group.iloc[0,group.columns.get_loc('country')]),\n",
    "                    str(group.iloc[0,group.columns.get_loc('year')]), \n",
    "                    str(group.iloc[0,group.columns.get_loc('topic')]),\n",
    "               mean_score, se_score]], columns = columns)\n",
    "    df = (df_temp if df.empty else pd.concat([df, df_temp], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/datasets/contextscale_coalition_dataset.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ai-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
